{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "dXynjd219v2r",
        "8fn8VOLBEv-o"
      ],
      "mount_file_id": "1Qc8s-fsI2tQn3Y_P7-tPkuwN35ZmQQHo",
      "authorship_tag": "ABX9TyPbQiRdJaXvAQICEGJIsXn6",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yurifillippo/Analises-Exploratorias-e-Python/blob/master/Rede_Neural.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXynjd219v2r"
      },
      "source": [
        "# **Rede Neural**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kyurgfB5BbV"
      },
      "source": [
        "#Importar bibliotecas\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import np_utils\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HO1oIHI-f1a"
      },
      "source": [
        "#Importar dataset\n",
        "df = datasets.load_iris()\n",
        "previsores = df.data\n",
        "classe = df.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "989ogCHlBBM5",
        "outputId": "fe060e5b-f4c0-461c-ff38-1f7990215c95"
      },
      "source": [
        "#Transformar classe em formato Dummy (Cada entrada da classe em uma coluna)\n",
        "class_dummy = np_utils.to_categorical(classe)\n",
        "class_dummy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cuz8SQHZBkdZ"
      },
      "source": [
        "#Dividir dados entre treino e teste\n",
        "X_train, X_teste, y_train, y_teste = train_test_split(previsores, class_dummy, test_size = 0.3, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWoB464mB8GI"
      },
      "source": [
        "#Criar estrutura da Rede Neural\n",
        "modelo = Sequential()\n",
        "\n",
        "#Primeira camada oculta = aleatóriamente escolhido 5 neurônios e 4 neurônios de entrada(significa entradas que tem relevância com a classe)\n",
        "modelo.add(Dense(units = 5, input_dim = 4))\n",
        "\n",
        "#Segunda camada oculta = \n",
        "modelo.add(Dense(units =  4))\n",
        "\n",
        "#Terceira camada oculta\n",
        "##Função softmax pois, temos um problema de classificação com mais de duas classes(gera uma probabilidade em cada neurônio)\n",
        "modelo.add(Dense(units = 3 , activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8hgYsLdC9sR",
        "outputId": "87dceb8c-48a5-4733-9732-9baadc32aa77"
      },
      "source": [
        "#Visualizar estrutura da rede neural\n",
        "modelo.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_14 (Dense)             (None, 5)                 25        \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 4)                 24        \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 3)                 15        \n",
            "=================================================================\n",
            "Total params: 64\n",
            "Trainable params: 64\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2w0NBedmDFfR"
      },
      "source": [
        "#Configurar parâmetros da rede neural(adam = algoritimo para atualizar pesos e loss = cálculo de erros)\n",
        "modelo.compile(optimizer='adam', loss= 'categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vawGN_w7DsA6",
        "outputId": "8df3ce9b-471f-47fc-e95f-d603bc6ed641"
      },
      "source": [
        "#Treinar modelo \n",
        "modelo.fit(X_train, y_train, epochs=1000, validation_data=(X_teste, y_teste))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 1.3197 - accuracy: 0.1048 - val_loss: 1.2300 - val_accuracy: 0.1778\n",
            "Epoch 2/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.2575 - accuracy: 0.2000 - val_loss: 1.1706 - val_accuracy: 0.2222\n",
            "Epoch 3/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.2217 - accuracy: 0.2190 - val_loss: 1.1264 - val_accuracy: 0.3333\n",
            "Epoch 4/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.1922 - accuracy: 0.2476 - val_loss: 1.0943 - val_accuracy: 0.3333\n",
            "Epoch 5/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.1639 - accuracy: 0.2571 - val_loss: 1.0685 - val_accuracy: 0.3333\n",
            "Epoch 6/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.1348 - accuracy: 0.2762 - val_loss: 1.0441 - val_accuracy: 0.4000\n",
            "Epoch 7/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.1102 - accuracy: 0.3143 - val_loss: 1.0207 - val_accuracy: 0.4444\n",
            "Epoch 8/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.0877 - accuracy: 0.3238 - val_loss: 1.0010 - val_accuracy: 0.4667\n",
            "Epoch 9/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.0658 - accuracy: 0.3429 - val_loss: 0.9834 - val_accuracy: 0.4889\n",
            "Epoch 10/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.0466 - accuracy: 0.3619 - val_loss: 0.9633 - val_accuracy: 0.5556\n",
            "Epoch 11/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.0274 - accuracy: 0.4095 - val_loss: 0.9404 - val_accuracy: 0.6222\n",
            "Epoch 12/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.0109 - accuracy: 0.4381 - val_loss: 0.9209 - val_accuracy: 0.6444\n",
            "Epoch 13/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.9961 - accuracy: 0.4476 - val_loss: 0.9062 - val_accuracy: 0.6222\n",
            "Epoch 14/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.9817 - accuracy: 0.4571 - val_loss: 0.8940 - val_accuracy: 0.6222\n",
            "Epoch 15/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.9692 - accuracy: 0.4857 - val_loss: 0.8833 - val_accuracy: 0.6667\n",
            "Epoch 16/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.9554 - accuracy: 0.5143 - val_loss: 0.8739 - val_accuracy: 0.6667\n",
            "Epoch 17/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.9439 - accuracy: 0.5524 - val_loss: 0.8671 - val_accuracy: 0.6889\n",
            "Epoch 18/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.9324 - accuracy: 0.5619 - val_loss: 0.8561 - val_accuracy: 0.6889\n",
            "Epoch 19/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.9227 - accuracy: 0.5810 - val_loss: 0.8476 - val_accuracy: 0.6889\n",
            "Epoch 20/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.9128 - accuracy: 0.5714 - val_loss: 0.8424 - val_accuracy: 0.6889\n",
            "Epoch 21/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.9031 - accuracy: 0.5714 - val_loss: 0.8385 - val_accuracy: 0.6889\n",
            "Epoch 22/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.8940 - accuracy: 0.5714 - val_loss: 0.8350 - val_accuracy: 0.6444\n",
            "Epoch 23/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.8860 - accuracy: 0.5905 - val_loss: 0.8347 - val_accuracy: 0.6222\n",
            "Epoch 24/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.8803 - accuracy: 0.5905 - val_loss: 0.8355 - val_accuracy: 0.6222\n",
            "Epoch 25/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.8723 - accuracy: 0.5905 - val_loss: 0.8298 - val_accuracy: 0.6000\n",
            "Epoch 26/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.8633 - accuracy: 0.5905 - val_loss: 0.8168 - val_accuracy: 0.6222\n",
            "Epoch 27/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.8543 - accuracy: 0.6000 - val_loss: 0.8019 - val_accuracy: 0.6222\n",
            "Epoch 28/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.8462 - accuracy: 0.6000 - val_loss: 0.7908 - val_accuracy: 0.6222\n",
            "Epoch 29/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.8385 - accuracy: 0.5810 - val_loss: 0.7804 - val_accuracy: 0.6222\n",
            "Epoch 30/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.8316 - accuracy: 0.5619 - val_loss: 0.7668 - val_accuracy: 0.6222\n",
            "Epoch 31/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.8263 - accuracy: 0.5714 - val_loss: 0.7591 - val_accuracy: 0.6000\n",
            "Epoch 32/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.8203 - accuracy: 0.5714 - val_loss: 0.7560 - val_accuracy: 0.6444\n",
            "Epoch 33/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.8148 - accuracy: 0.5524 - val_loss: 0.7552 - val_accuracy: 0.6222\n",
            "Epoch 34/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.8079 - accuracy: 0.5810 - val_loss: 0.7498 - val_accuracy: 0.6222\n",
            "Epoch 35/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.8023 - accuracy: 0.5810 - val_loss: 0.7461 - val_accuracy: 0.6000\n",
            "Epoch 36/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7966 - accuracy: 0.5810 - val_loss: 0.7409 - val_accuracy: 0.6000\n",
            "Epoch 37/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7915 - accuracy: 0.5810 - val_loss: 0.7353 - val_accuracy: 0.6000\n",
            "Epoch 38/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7878 - accuracy: 0.5810 - val_loss: 0.7246 - val_accuracy: 0.6444\n",
            "Epoch 39/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7818 - accuracy: 0.5619 - val_loss: 0.7208 - val_accuracy: 0.6444\n",
            "Epoch 40/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7766 - accuracy: 0.5619 - val_loss: 0.7157 - val_accuracy: 0.6444\n",
            "Epoch 41/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7716 - accuracy: 0.5714 - val_loss: 0.7160 - val_accuracy: 0.6222\n",
            "Epoch 42/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7663 - accuracy: 0.5714 - val_loss: 0.7186 - val_accuracy: 0.6222\n",
            "Epoch 43/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7615 - accuracy: 0.5714 - val_loss: 0.7189 - val_accuracy: 0.6000\n",
            "Epoch 44/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7564 - accuracy: 0.5714 - val_loss: 0.7157 - val_accuracy: 0.6000\n",
            "Epoch 45/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7532 - accuracy: 0.5810 - val_loss: 0.7136 - val_accuracy: 0.5778\n",
            "Epoch 46/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7474 - accuracy: 0.5810 - val_loss: 0.7015 - val_accuracy: 0.6000\n",
            "Epoch 47/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7423 - accuracy: 0.5810 - val_loss: 0.6926 - val_accuracy: 0.6222\n",
            "Epoch 48/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7383 - accuracy: 0.5714 - val_loss: 0.6858 - val_accuracy: 0.6222\n",
            "Epoch 49/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7339 - accuracy: 0.5714 - val_loss: 0.6800 - val_accuracy: 0.6222\n",
            "Epoch 50/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7304 - accuracy: 0.5714 - val_loss: 0.6737 - val_accuracy: 0.6000\n",
            "Epoch 51/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7262 - accuracy: 0.5810 - val_loss: 0.6714 - val_accuracy: 0.6222\n",
            "Epoch 52/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7214 - accuracy: 0.5714 - val_loss: 0.6721 - val_accuracy: 0.6222\n",
            "Epoch 53/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7167 - accuracy: 0.5810 - val_loss: 0.6783 - val_accuracy: 0.6000\n",
            "Epoch 54/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7128 - accuracy: 0.5810 - val_loss: 0.6841 - val_accuracy: 0.5778\n",
            "Epoch 55/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.7088 - accuracy: 0.6190 - val_loss: 0.6821 - val_accuracy: 0.5778\n",
            "Epoch 56/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7047 - accuracy: 0.6190 - val_loss: 0.6766 - val_accuracy: 0.5778\n",
            "Epoch 57/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7009 - accuracy: 0.6190 - val_loss: 0.6743 - val_accuracy: 0.6000\n",
            "Epoch 58/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.6964 - accuracy: 0.6190 - val_loss: 0.6706 - val_accuracy: 0.6000\n",
            "Epoch 59/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.6922 - accuracy: 0.6095 - val_loss: 0.6684 - val_accuracy: 0.6000\n",
            "Epoch 60/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.6885 - accuracy: 0.6286 - val_loss: 0.6643 - val_accuracy: 0.6000\n",
            "Epoch 61/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6844 - accuracy: 0.6190 - val_loss: 0.6567 - val_accuracy: 0.6000\n",
            "Epoch 62/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.6801 - accuracy: 0.6190 - val_loss: 0.6508 - val_accuracy: 0.5778\n",
            "Epoch 63/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.6768 - accuracy: 0.5905 - val_loss: 0.6435 - val_accuracy: 0.6000\n",
            "Epoch 64/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.6736 - accuracy: 0.5905 - val_loss: 0.6410 - val_accuracy: 0.6000\n",
            "Epoch 65/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.6695 - accuracy: 0.6095 - val_loss: 0.6432 - val_accuracy: 0.6000\n",
            "Epoch 66/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.6669 - accuracy: 0.6286 - val_loss: 0.6462 - val_accuracy: 0.6000\n",
            "Epoch 67/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.6623 - accuracy: 0.6286 - val_loss: 0.6430 - val_accuracy: 0.6000\n",
            "Epoch 68/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.6583 - accuracy: 0.6286 - val_loss: 0.6357 - val_accuracy: 0.6000\n",
            "Epoch 69/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6550 - accuracy: 0.6286 - val_loss: 0.6304 - val_accuracy: 0.6000\n",
            "Epoch 70/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.6521 - accuracy: 0.6286 - val_loss: 0.6237 - val_accuracy: 0.6000\n",
            "Epoch 71/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6489 - accuracy: 0.6190 - val_loss: 0.6197 - val_accuracy: 0.6000\n",
            "Epoch 72/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.6451 - accuracy: 0.6286 - val_loss: 0.6206 - val_accuracy: 0.6000\n",
            "Epoch 73/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.6415 - accuracy: 0.6286 - val_loss: 0.6208 - val_accuracy: 0.6000\n",
            "Epoch 74/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6377 - accuracy: 0.6286 - val_loss: 0.6191 - val_accuracy: 0.6000\n",
            "Epoch 75/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.6347 - accuracy: 0.6286 - val_loss: 0.6175 - val_accuracy: 0.6000\n",
            "Epoch 76/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.6312 - accuracy: 0.6286 - val_loss: 0.6110 - val_accuracy: 0.6000\n",
            "Epoch 77/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.6283 - accuracy: 0.6286 - val_loss: 0.6065 - val_accuracy: 0.6000\n",
            "Epoch 78/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.6249 - accuracy: 0.6286 - val_loss: 0.6041 - val_accuracy: 0.6000\n",
            "Epoch 79/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.6226 - accuracy: 0.6286 - val_loss: 0.6025 - val_accuracy: 0.6000\n",
            "Epoch 80/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.6189 - accuracy: 0.6286 - val_loss: 0.5964 - val_accuracy: 0.6000\n",
            "Epoch 81/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.6157 - accuracy: 0.6286 - val_loss: 0.5941 - val_accuracy: 0.6000\n",
            "Epoch 82/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6126 - accuracy: 0.6381 - val_loss: 0.5897 - val_accuracy: 0.6000\n",
            "Epoch 83/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6098 - accuracy: 0.6381 - val_loss: 0.5875 - val_accuracy: 0.6000\n",
            "Epoch 84/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6066 - accuracy: 0.6381 - val_loss: 0.5864 - val_accuracy: 0.6000\n",
            "Epoch 85/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.6036 - accuracy: 0.6286 - val_loss: 0.5852 - val_accuracy: 0.6000\n",
            "Epoch 86/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.6006 - accuracy: 0.6476 - val_loss: 0.5889 - val_accuracy: 0.6000\n",
            "Epoch 87/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5974 - accuracy: 0.6476 - val_loss: 0.5944 - val_accuracy: 0.5778\n",
            "Epoch 88/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5949 - accuracy: 0.6571 - val_loss: 0.5948 - val_accuracy: 0.5778\n",
            "Epoch 89/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5931 - accuracy: 0.6571 - val_loss: 0.5955 - val_accuracy: 0.5778\n",
            "Epoch 90/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5902 - accuracy: 0.6667 - val_loss: 0.5909 - val_accuracy: 0.5778\n",
            "Epoch 91/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5857 - accuracy: 0.6667 - val_loss: 0.5821 - val_accuracy: 0.5778\n",
            "Epoch 92/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.5831 - accuracy: 0.6476 - val_loss: 0.5739 - val_accuracy: 0.6000\n",
            "Epoch 93/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5800 - accuracy: 0.6476 - val_loss: 0.5696 - val_accuracy: 0.6000\n",
            "Epoch 94/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.5773 - accuracy: 0.6476 - val_loss: 0.5670 - val_accuracy: 0.6000\n",
            "Epoch 95/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.5744 - accuracy: 0.6476 - val_loss: 0.5648 - val_accuracy: 0.6000\n",
            "Epoch 96/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5719 - accuracy: 0.6476 - val_loss: 0.5623 - val_accuracy: 0.6000\n",
            "Epoch 97/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5687 - accuracy: 0.6476 - val_loss: 0.5569 - val_accuracy: 0.6000\n",
            "Epoch 98/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5672 - accuracy: 0.6571 - val_loss: 0.5505 - val_accuracy: 0.6000\n",
            "Epoch 99/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5650 - accuracy: 0.6571 - val_loss: 0.5489 - val_accuracy: 0.6000\n",
            "Epoch 100/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5611 - accuracy: 0.6571 - val_loss: 0.5526 - val_accuracy: 0.6000\n",
            "Epoch 101/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.5579 - accuracy: 0.6571 - val_loss: 0.5570 - val_accuracy: 0.6000\n",
            "Epoch 102/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5554 - accuracy: 0.6762 - val_loss: 0.5581 - val_accuracy: 0.6000\n",
            "Epoch 103/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5527 - accuracy: 0.6762 - val_loss: 0.5551 - val_accuracy: 0.6000\n",
            "Epoch 104/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5499 - accuracy: 0.6762 - val_loss: 0.5490 - val_accuracy: 0.6000\n",
            "Epoch 105/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5477 - accuracy: 0.6667 - val_loss: 0.5453 - val_accuracy: 0.6222\n",
            "Epoch 106/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5452 - accuracy: 0.6762 - val_loss: 0.5432 - val_accuracy: 0.6222\n",
            "Epoch 107/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5439 - accuracy: 0.6571 - val_loss: 0.5374 - val_accuracy: 0.6222\n",
            "Epoch 108/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5403 - accuracy: 0.6571 - val_loss: 0.5361 - val_accuracy: 0.6222\n",
            "Epoch 109/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.5380 - accuracy: 0.6571 - val_loss: 0.5339 - val_accuracy: 0.6222\n",
            "Epoch 110/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5352 - accuracy: 0.6667 - val_loss: 0.5366 - val_accuracy: 0.6222\n",
            "Epoch 111/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5324 - accuracy: 0.6857 - val_loss: 0.5414 - val_accuracy: 0.6222\n",
            "Epoch 112/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5305 - accuracy: 0.6762 - val_loss: 0.5473 - val_accuracy: 0.6222\n",
            "Epoch 113/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5293 - accuracy: 0.6762 - val_loss: 0.5520 - val_accuracy: 0.6222\n",
            "Epoch 114/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.5279 - accuracy: 0.6952 - val_loss: 0.5509 - val_accuracy: 0.6222\n",
            "Epoch 115/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.5248 - accuracy: 0.6952 - val_loss: 0.5437 - val_accuracy: 0.6222\n",
            "Epoch 116/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.5221 - accuracy: 0.6857 - val_loss: 0.5330 - val_accuracy: 0.6222\n",
            "Epoch 117/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5177 - accuracy: 0.6762 - val_loss: 0.5258 - val_accuracy: 0.6222\n",
            "Epoch 118/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5153 - accuracy: 0.6857 - val_loss: 0.5179 - val_accuracy: 0.6444\n",
            "Epoch 119/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5134 - accuracy: 0.6857 - val_loss: 0.5122 - val_accuracy: 0.6222\n",
            "Epoch 120/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5118 - accuracy: 0.6952 - val_loss: 0.5093 - val_accuracy: 0.6222\n",
            "Epoch 121/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.5095 - accuracy: 0.6952 - val_loss: 0.5096 - val_accuracy: 0.6444\n",
            "Epoch 122/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.5066 - accuracy: 0.6952 - val_loss: 0.5106 - val_accuracy: 0.6444\n",
            "Epoch 123/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.5043 - accuracy: 0.6857 - val_loss: 0.5107 - val_accuracy: 0.6444\n",
            "Epoch 124/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5017 - accuracy: 0.6857 - val_loss: 0.5070 - val_accuracy: 0.6444\n",
            "Epoch 125/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4995 - accuracy: 0.6952 - val_loss: 0.5034 - val_accuracy: 0.6444\n",
            "Epoch 126/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4974 - accuracy: 0.6952 - val_loss: 0.5002 - val_accuracy: 0.6444\n",
            "Epoch 127/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4953 - accuracy: 0.6952 - val_loss: 0.4987 - val_accuracy: 0.6444\n",
            "Epoch 128/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4932 - accuracy: 0.7143 - val_loss: 0.4964 - val_accuracy: 0.6444\n",
            "Epoch 129/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4910 - accuracy: 0.7143 - val_loss: 0.4942 - val_accuracy: 0.6444\n",
            "Epoch 130/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.4888 - accuracy: 0.7238 - val_loss: 0.4950 - val_accuracy: 0.6444\n",
            "Epoch 131/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4861 - accuracy: 0.7143 - val_loss: 0.4937 - val_accuracy: 0.6444\n",
            "Epoch 132/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4845 - accuracy: 0.7238 - val_loss: 0.4937 - val_accuracy: 0.6444\n",
            "Epoch 133/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4812 - accuracy: 0.7333 - val_loss: 0.4884 - val_accuracy: 0.6444\n",
            "Epoch 134/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4795 - accuracy: 0.7333 - val_loss: 0.4853 - val_accuracy: 0.6444\n",
            "Epoch 135/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4776 - accuracy: 0.7429 - val_loss: 0.4823 - val_accuracy: 0.6667\n",
            "Epoch 136/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4752 - accuracy: 0.7810 - val_loss: 0.4828 - val_accuracy: 0.6444\n",
            "Epoch 137/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4732 - accuracy: 0.7429 - val_loss: 0.4848 - val_accuracy: 0.6444\n",
            "Epoch 138/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4702 - accuracy: 0.7429 - val_loss: 0.4848 - val_accuracy: 0.6444\n",
            "Epoch 139/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4683 - accuracy: 0.7429 - val_loss: 0.4852 - val_accuracy: 0.6444\n",
            "Epoch 140/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.4659 - accuracy: 0.7429 - val_loss: 0.4840 - val_accuracy: 0.6444\n",
            "Epoch 141/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4639 - accuracy: 0.7429 - val_loss: 0.4845 - val_accuracy: 0.6444\n",
            "Epoch 142/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4616 - accuracy: 0.7429 - val_loss: 0.4845 - val_accuracy: 0.6222\n",
            "Epoch 143/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7429 - val_loss: 0.4845 - val_accuracy: 0.6222\n",
            "Epoch 144/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4578 - accuracy: 0.7429 - val_loss: 0.4820 - val_accuracy: 0.6222\n",
            "Epoch 145/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4549 - accuracy: 0.7429 - val_loss: 0.4759 - val_accuracy: 0.6444\n",
            "Epoch 146/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4526 - accuracy: 0.7524 - val_loss: 0.4712 - val_accuracy: 0.6667\n",
            "Epoch 147/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4508 - accuracy: 0.7714 - val_loss: 0.4680 - val_accuracy: 0.6667\n",
            "Epoch 148/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4487 - accuracy: 0.7810 - val_loss: 0.4684 - val_accuracy: 0.6667\n",
            "Epoch 149/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4468 - accuracy: 0.7714 - val_loss: 0.4685 - val_accuracy: 0.6667\n",
            "Epoch 150/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4446 - accuracy: 0.7619 - val_loss: 0.4676 - val_accuracy: 0.6667\n",
            "Epoch 151/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4422 - accuracy: 0.7714 - val_loss: 0.4638 - val_accuracy: 0.7111\n",
            "Epoch 152/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4406 - accuracy: 0.8095 - val_loss: 0.4596 - val_accuracy: 0.7111\n",
            "Epoch 153/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4380 - accuracy: 0.8190 - val_loss: 0.4602 - val_accuracy: 0.7111\n",
            "Epoch 154/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4357 - accuracy: 0.7905 - val_loss: 0.4619 - val_accuracy: 0.6889\n",
            "Epoch 155/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4340 - accuracy: 0.7810 - val_loss: 0.4644 - val_accuracy: 0.6667\n",
            "Epoch 156/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.4327 - accuracy: 0.7619 - val_loss: 0.4664 - val_accuracy: 0.6667\n",
            "Epoch 157/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4304 - accuracy: 0.7619 - val_loss: 0.4634 - val_accuracy: 0.6667\n",
            "Epoch 158/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4281 - accuracy: 0.7619 - val_loss: 0.4608 - val_accuracy: 0.6667\n",
            "Epoch 159/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4257 - accuracy: 0.7810 - val_loss: 0.4551 - val_accuracy: 0.7111\n",
            "Epoch 160/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4234 - accuracy: 0.8286 - val_loss: 0.4507 - val_accuracy: 0.7111\n",
            "Epoch 161/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4215 - accuracy: 0.8571 - val_loss: 0.4460 - val_accuracy: 0.7111\n",
            "Epoch 162/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4189 - accuracy: 0.8571 - val_loss: 0.4439 - val_accuracy: 0.7333\n",
            "Epoch 163/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4169 - accuracy: 0.8571 - val_loss: 0.4400 - val_accuracy: 0.7556\n",
            "Epoch 164/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4147 - accuracy: 0.8571 - val_loss: 0.4380 - val_accuracy: 0.7556\n",
            "Epoch 165/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4127 - accuracy: 0.8571 - val_loss: 0.4364 - val_accuracy: 0.7556\n",
            "Epoch 166/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8571 - val_loss: 0.4384 - val_accuracy: 0.7556\n",
            "Epoch 167/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4085 - accuracy: 0.8571 - val_loss: 0.4376 - val_accuracy: 0.7556\n",
            "Epoch 168/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4062 - accuracy: 0.8571 - val_loss: 0.4384 - val_accuracy: 0.7111\n",
            "Epoch 169/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4045 - accuracy: 0.8571 - val_loss: 0.4380 - val_accuracy: 0.7111\n",
            "Epoch 170/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4024 - accuracy: 0.8571 - val_loss: 0.4355 - val_accuracy: 0.7333\n",
            "Epoch 171/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4002 - accuracy: 0.8571 - val_loss: 0.4345 - val_accuracy: 0.7333\n",
            "Epoch 172/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3985 - accuracy: 0.8571 - val_loss: 0.4340 - val_accuracy: 0.7333\n",
            "Epoch 173/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3960 - accuracy: 0.8571 - val_loss: 0.4304 - val_accuracy: 0.7556\n",
            "Epoch 174/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3937 - accuracy: 0.8667 - val_loss: 0.4266 - val_accuracy: 0.7556\n",
            "Epoch 175/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3922 - accuracy: 0.8667 - val_loss: 0.4222 - val_accuracy: 0.7556\n",
            "Epoch 176/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3893 - accuracy: 0.8762 - val_loss: 0.4185 - val_accuracy: 0.7778\n",
            "Epoch 177/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3886 - accuracy: 0.8762 - val_loss: 0.4132 - val_accuracy: 0.7778\n",
            "Epoch 178/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3850 - accuracy: 0.8857 - val_loss: 0.4158 - val_accuracy: 0.7778\n",
            "Epoch 179/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3832 - accuracy: 0.8762 - val_loss: 0.4178 - val_accuracy: 0.7778\n",
            "Epoch 180/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3817 - accuracy: 0.8667 - val_loss: 0.4190 - val_accuracy: 0.7556\n",
            "Epoch 181/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3790 - accuracy: 0.8762 - val_loss: 0.4169 - val_accuracy: 0.7556\n",
            "Epoch 182/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3768 - accuracy: 0.8762 - val_loss: 0.4132 - val_accuracy: 0.7778\n",
            "Epoch 183/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3748 - accuracy: 0.8762 - val_loss: 0.4094 - val_accuracy: 0.7778\n",
            "Epoch 184/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3733 - accuracy: 0.8762 - val_loss: 0.4087 - val_accuracy: 0.7778\n",
            "Epoch 185/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3702 - accuracy: 0.8762 - val_loss: 0.4019 - val_accuracy: 0.7778\n",
            "Epoch 186/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3680 - accuracy: 0.8857 - val_loss: 0.3961 - val_accuracy: 0.8000\n",
            "Epoch 187/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.3658 - accuracy: 0.8952 - val_loss: 0.3917 - val_accuracy: 0.8222\n",
            "Epoch 188/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3645 - accuracy: 0.8952 - val_loss: 0.3869 - val_accuracy: 0.8222\n",
            "Epoch 189/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3627 - accuracy: 0.9238 - val_loss: 0.3858 - val_accuracy: 0.8222\n",
            "Epoch 190/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3598 - accuracy: 0.8952 - val_loss: 0.3894 - val_accuracy: 0.8000\n",
            "Epoch 191/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3572 - accuracy: 0.8952 - val_loss: 0.3906 - val_accuracy: 0.8000\n",
            "Epoch 192/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3548 - accuracy: 0.8952 - val_loss: 0.3910 - val_accuracy: 0.8000\n",
            "Epoch 193/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3530 - accuracy: 0.8952 - val_loss: 0.3917 - val_accuracy: 0.8000\n",
            "Epoch 194/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3507 - accuracy: 0.8952 - val_loss: 0.3892 - val_accuracy: 0.8000\n",
            "Epoch 195/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3484 - accuracy: 0.8952 - val_loss: 0.3842 - val_accuracy: 0.8000\n",
            "Epoch 196/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3463 - accuracy: 0.8952 - val_loss: 0.3817 - val_accuracy: 0.8000\n",
            "Epoch 197/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3443 - accuracy: 0.8952 - val_loss: 0.3746 - val_accuracy: 0.8444\n",
            "Epoch 198/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3417 - accuracy: 0.9238 - val_loss: 0.3725 - val_accuracy: 0.8444\n",
            "Epoch 199/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3395 - accuracy: 0.9238 - val_loss: 0.3706 - val_accuracy: 0.8444\n",
            "Epoch 200/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3373 - accuracy: 0.9333 - val_loss: 0.3677 - val_accuracy: 0.8444\n",
            "Epoch 201/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3351 - accuracy: 0.9333 - val_loss: 0.3663 - val_accuracy: 0.8444\n",
            "Epoch 202/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3327 - accuracy: 0.9333 - val_loss: 0.3660 - val_accuracy: 0.8444\n",
            "Epoch 203/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3304 - accuracy: 0.9333 - val_loss: 0.3646 - val_accuracy: 0.8444\n",
            "Epoch 204/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3282 - accuracy: 0.9333 - val_loss: 0.3655 - val_accuracy: 0.8444\n",
            "Epoch 205/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3267 - accuracy: 0.9143 - val_loss: 0.3657 - val_accuracy: 0.8444\n",
            "Epoch 206/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3242 - accuracy: 0.9333 - val_loss: 0.3587 - val_accuracy: 0.8444\n",
            "Epoch 207/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3219 - accuracy: 0.9333 - val_loss: 0.3554 - val_accuracy: 0.8444\n",
            "Epoch 208/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3192 - accuracy: 0.9333 - val_loss: 0.3550 - val_accuracy: 0.8444\n",
            "Epoch 209/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3178 - accuracy: 0.9333 - val_loss: 0.3576 - val_accuracy: 0.8444\n",
            "Epoch 210/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3148 - accuracy: 0.9333 - val_loss: 0.3539 - val_accuracy: 0.8444\n",
            "Epoch 211/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3133 - accuracy: 0.9333 - val_loss: 0.3502 - val_accuracy: 0.8444\n",
            "Epoch 212/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3102 - accuracy: 0.9333 - val_loss: 0.3530 - val_accuracy: 0.8444\n",
            "Epoch 213/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3082 - accuracy: 0.9333 - val_loss: 0.3540 - val_accuracy: 0.8444\n",
            "Epoch 214/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3067 - accuracy: 0.9333 - val_loss: 0.3544 - val_accuracy: 0.8444\n",
            "Epoch 215/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3043 - accuracy: 0.9333 - val_loss: 0.3482 - val_accuracy: 0.8444\n",
            "Epoch 216/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3017 - accuracy: 0.9333 - val_loss: 0.3437 - val_accuracy: 0.8444\n",
            "Epoch 217/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3003 - accuracy: 0.9429 - val_loss: 0.3403 - val_accuracy: 0.8444\n",
            "Epoch 218/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2972 - accuracy: 0.9429 - val_loss: 0.3416 - val_accuracy: 0.8444\n",
            "Epoch 219/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2966 - accuracy: 0.9333 - val_loss: 0.3465 - val_accuracy: 0.8444\n",
            "Epoch 220/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2937 - accuracy: 0.9333 - val_loss: 0.3463 - val_accuracy: 0.8444\n",
            "Epoch 221/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2919 - accuracy: 0.9333 - val_loss: 0.3423 - val_accuracy: 0.8444\n",
            "Epoch 222/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2891 - accuracy: 0.9333 - val_loss: 0.3395 - val_accuracy: 0.8444\n",
            "Epoch 223/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2869 - accuracy: 0.9429 - val_loss: 0.3343 - val_accuracy: 0.8444\n",
            "Epoch 224/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2843 - accuracy: 0.9429 - val_loss: 0.3325 - val_accuracy: 0.8444\n",
            "Epoch 225/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2823 - accuracy: 0.9429 - val_loss: 0.3303 - val_accuracy: 0.8444\n",
            "Epoch 226/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2793 - accuracy: 0.9429 - val_loss: 0.3228 - val_accuracy: 0.8889\n",
            "Epoch 227/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2774 - accuracy: 0.9524 - val_loss: 0.3175 - val_accuracy: 0.9111\n",
            "Epoch 228/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2751 - accuracy: 0.9619 - val_loss: 0.3156 - val_accuracy: 0.9111\n",
            "Epoch 229/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2728 - accuracy: 0.9619 - val_loss: 0.3153 - val_accuracy: 0.9111\n",
            "Epoch 230/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2702 - accuracy: 0.9619 - val_loss: 0.3182 - val_accuracy: 0.8889\n",
            "Epoch 231/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2680 - accuracy: 0.9429 - val_loss: 0.3209 - val_accuracy: 0.8667\n",
            "Epoch 232/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2666 - accuracy: 0.9429 - val_loss: 0.3230 - val_accuracy: 0.8444\n",
            "Epoch 233/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2651 - accuracy: 0.9429 - val_loss: 0.3223 - val_accuracy: 0.8444\n",
            "Epoch 234/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2630 - accuracy: 0.9429 - val_loss: 0.3205 - val_accuracy: 0.8444\n",
            "Epoch 235/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2612 - accuracy: 0.9429 - val_loss: 0.3204 - val_accuracy: 0.8444\n",
            "Epoch 236/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2589 - accuracy: 0.9429 - val_loss: 0.3160 - val_accuracy: 0.8444\n",
            "Epoch 237/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2563 - accuracy: 0.9429 - val_loss: 0.3112 - val_accuracy: 0.8889\n",
            "Epoch 238/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2538 - accuracy: 0.9429 - val_loss: 0.3051 - val_accuracy: 0.9111\n",
            "Epoch 239/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2514 - accuracy: 0.9619 - val_loss: 0.2984 - val_accuracy: 0.9111\n",
            "Epoch 240/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2488 - accuracy: 0.9714 - val_loss: 0.2953 - val_accuracy: 0.9111\n",
            "Epoch 241/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2470 - accuracy: 0.9810 - val_loss: 0.2912 - val_accuracy: 0.9333\n",
            "Epoch 242/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2455 - accuracy: 0.9714 - val_loss: 0.2918 - val_accuracy: 0.9111\n",
            "Epoch 243/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2426 - accuracy: 0.9810 - val_loss: 0.2881 - val_accuracy: 0.9333\n",
            "Epoch 244/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2404 - accuracy: 0.9810 - val_loss: 0.2886 - val_accuracy: 0.9111\n",
            "Epoch 245/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2383 - accuracy: 0.9714 - val_loss: 0.2899 - val_accuracy: 0.9111\n",
            "Epoch 246/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2365 - accuracy: 0.9714 - val_loss: 0.2910 - val_accuracy: 0.9111\n",
            "Epoch 247/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2354 - accuracy: 0.9619 - val_loss: 0.2918 - val_accuracy: 0.9111\n",
            "Epoch 248/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2321 - accuracy: 0.9714 - val_loss: 0.2825 - val_accuracy: 0.9333\n",
            "Epoch 249/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2308 - accuracy: 0.9810 - val_loss: 0.2726 - val_accuracy: 0.9333\n",
            "Epoch 250/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2291 - accuracy: 0.9905 - val_loss: 0.2695 - val_accuracy: 0.9333\n",
            "Epoch 251/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2267 - accuracy: 0.9905 - val_loss: 0.2736 - val_accuracy: 0.9333\n",
            "Epoch 252/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2241 - accuracy: 0.9810 - val_loss: 0.2772 - val_accuracy: 0.9333\n",
            "Epoch 253/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2229 - accuracy: 0.9714 - val_loss: 0.2788 - val_accuracy: 0.9111\n",
            "Epoch 254/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2210 - accuracy: 0.9810 - val_loss: 0.2739 - val_accuracy: 0.9333\n",
            "Epoch 255/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2187 - accuracy: 0.9810 - val_loss: 0.2726 - val_accuracy: 0.9333\n",
            "Epoch 256/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2168 - accuracy: 0.9810 - val_loss: 0.2722 - val_accuracy: 0.9333\n",
            "Epoch 257/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2155 - accuracy: 0.9810 - val_loss: 0.2712 - val_accuracy: 0.9333\n",
            "Epoch 258/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2130 - accuracy: 0.9810 - val_loss: 0.2655 - val_accuracy: 0.9333\n",
            "Epoch 259/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2111 - accuracy: 0.9810 - val_loss: 0.2582 - val_accuracy: 0.9333\n",
            "Epoch 260/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2089 - accuracy: 0.9810 - val_loss: 0.2510 - val_accuracy: 0.9333\n",
            "Epoch 261/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2091 - accuracy: 0.9905 - val_loss: 0.2451 - val_accuracy: 0.9333\n",
            "Epoch 262/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2083 - accuracy: 0.9905 - val_loss: 0.2454 - val_accuracy: 0.9333\n",
            "Epoch 263/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2045 - accuracy: 0.9905 - val_loss: 0.2555 - val_accuracy: 0.9333\n",
            "Epoch 264/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2024 - accuracy: 0.9810 - val_loss: 0.2684 - val_accuracy: 0.9111\n",
            "Epoch 265/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2014 - accuracy: 0.9714 - val_loss: 0.2703 - val_accuracy: 0.9111\n",
            "Epoch 266/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2005 - accuracy: 0.9619 - val_loss: 0.2678 - val_accuracy: 0.9111\n",
            "Epoch 267/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1983 - accuracy: 0.9714 - val_loss: 0.2616 - val_accuracy: 0.9111\n",
            "Epoch 268/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1953 - accuracy: 0.9810 - val_loss: 0.2524 - val_accuracy: 0.9333\n",
            "Epoch 269/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1932 - accuracy: 0.9810 - val_loss: 0.2463 - val_accuracy: 0.9333\n",
            "Epoch 270/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1916 - accuracy: 0.9810 - val_loss: 0.2435 - val_accuracy: 0.9333\n",
            "Epoch 271/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1906 - accuracy: 0.9810 - val_loss: 0.2370 - val_accuracy: 0.9333\n",
            "Epoch 272/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1890 - accuracy: 0.9905 - val_loss: 0.2356 - val_accuracy: 0.9333\n",
            "Epoch 273/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1873 - accuracy: 0.9810 - val_loss: 0.2341 - val_accuracy: 0.9333\n",
            "Epoch 274/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1856 - accuracy: 0.9905 - val_loss: 0.2310 - val_accuracy: 0.9333\n",
            "Epoch 275/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1844 - accuracy: 0.9905 - val_loss: 0.2300 - val_accuracy: 0.9333\n",
            "Epoch 276/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1823 - accuracy: 0.9905 - val_loss: 0.2333 - val_accuracy: 0.9333\n",
            "Epoch 277/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1819 - accuracy: 0.9810 - val_loss: 0.2404 - val_accuracy: 0.9333\n",
            "Epoch 278/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1790 - accuracy: 0.9810 - val_loss: 0.2369 - val_accuracy: 0.9333\n",
            "Epoch 279/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1773 - accuracy: 0.9810 - val_loss: 0.2363 - val_accuracy: 0.9333\n",
            "Epoch 280/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1758 - accuracy: 0.9810 - val_loss: 0.2320 - val_accuracy: 0.9333\n",
            "Epoch 281/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1743 - accuracy: 0.9810 - val_loss: 0.2320 - val_accuracy: 0.9333\n",
            "Epoch 282/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1728 - accuracy: 0.9810 - val_loss: 0.2304 - val_accuracy: 0.9333\n",
            "Epoch 283/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1712 - accuracy: 0.9810 - val_loss: 0.2307 - val_accuracy: 0.9333\n",
            "Epoch 284/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1702 - accuracy: 0.9810 - val_loss: 0.2334 - val_accuracy: 0.9333\n",
            "Epoch 285/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1690 - accuracy: 0.9810 - val_loss: 0.2313 - val_accuracy: 0.9333\n",
            "Epoch 286/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1674 - accuracy: 0.9810 - val_loss: 0.2310 - val_accuracy: 0.9333\n",
            "Epoch 287/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1659 - accuracy: 0.9810 - val_loss: 0.2280 - val_accuracy: 0.9333\n",
            "Epoch 288/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1645 - accuracy: 0.9810 - val_loss: 0.2270 - val_accuracy: 0.9333\n",
            "Epoch 289/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1631 - accuracy: 0.9810 - val_loss: 0.2270 - val_accuracy: 0.9333\n",
            "Epoch 290/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1619 - accuracy: 0.9810 - val_loss: 0.2261 - val_accuracy: 0.9333\n",
            "Epoch 291/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1607 - accuracy: 0.9810 - val_loss: 0.2228 - val_accuracy: 0.9333\n",
            "Epoch 292/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1590 - accuracy: 0.9810 - val_loss: 0.2208 - val_accuracy: 0.9333\n",
            "Epoch 293/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1582 - accuracy: 0.9810 - val_loss: 0.2179 - val_accuracy: 0.9333\n",
            "Epoch 294/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1563 - accuracy: 0.9810 - val_loss: 0.2189 - val_accuracy: 0.9333\n",
            "Epoch 295/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1552 - accuracy: 0.9810 - val_loss: 0.2176 - val_accuracy: 0.9333\n",
            "Epoch 296/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1540 - accuracy: 0.9810 - val_loss: 0.2163 - val_accuracy: 0.9333\n",
            "Epoch 297/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1526 - accuracy: 0.9810 - val_loss: 0.2127 - val_accuracy: 0.9333\n",
            "Epoch 298/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1513 - accuracy: 0.9810 - val_loss: 0.2120 - val_accuracy: 0.9333\n",
            "Epoch 299/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1505 - accuracy: 0.9810 - val_loss: 0.2084 - val_accuracy: 0.9333\n",
            "Epoch 300/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1487 - accuracy: 0.9810 - val_loss: 0.2079 - val_accuracy: 0.9333\n",
            "Epoch 301/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1475 - accuracy: 0.9810 - val_loss: 0.2088 - val_accuracy: 0.9333\n",
            "Epoch 302/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1463 - accuracy: 0.9810 - val_loss: 0.2113 - val_accuracy: 0.9333\n",
            "Epoch 303/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1457 - accuracy: 0.9810 - val_loss: 0.2108 - val_accuracy: 0.9333\n",
            "Epoch 304/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1444 - accuracy: 0.9810 - val_loss: 0.2112 - val_accuracy: 0.9333\n",
            "Epoch 305/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1436 - accuracy: 0.9810 - val_loss: 0.2087 - val_accuracy: 0.9333\n",
            "Epoch 306/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1424 - accuracy: 0.9810 - val_loss: 0.2070 - val_accuracy: 0.9333\n",
            "Epoch 307/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1411 - accuracy: 0.9810 - val_loss: 0.2034 - val_accuracy: 0.9333\n",
            "Epoch 308/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1399 - accuracy: 0.9810 - val_loss: 0.2018 - val_accuracy: 0.9333\n",
            "Epoch 309/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1390 - accuracy: 0.9810 - val_loss: 0.2027 - val_accuracy: 0.9333\n",
            "Epoch 310/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1378 - accuracy: 0.9810 - val_loss: 0.1988 - val_accuracy: 0.9333\n",
            "Epoch 311/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1367 - accuracy: 0.9810 - val_loss: 0.1981 - val_accuracy: 0.9333\n",
            "Epoch 312/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1361 - accuracy: 0.9810 - val_loss: 0.2019 - val_accuracy: 0.9333\n",
            "Epoch 313/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1348 - accuracy: 0.9810 - val_loss: 0.2033 - val_accuracy: 0.9333\n",
            "Epoch 314/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1346 - accuracy: 0.9810 - val_loss: 0.2062 - val_accuracy: 0.9333\n",
            "Epoch 315/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1338 - accuracy: 0.9810 - val_loss: 0.2048 - val_accuracy: 0.9333\n",
            "Epoch 316/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1323 - accuracy: 0.9810 - val_loss: 0.1993 - val_accuracy: 0.9333\n",
            "Epoch 317/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1312 - accuracy: 0.9810 - val_loss: 0.1919 - val_accuracy: 0.9333\n",
            "Epoch 318/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1296 - accuracy: 0.9810 - val_loss: 0.1904 - val_accuracy: 0.9333\n",
            "Epoch 319/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1290 - accuracy: 0.9810 - val_loss: 0.1928 - val_accuracy: 0.9333\n",
            "Epoch 320/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1280 - accuracy: 0.9810 - val_loss: 0.1930 - val_accuracy: 0.9333\n",
            "Epoch 321/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1271 - accuracy: 0.9810 - val_loss: 0.1904 - val_accuracy: 0.9333\n",
            "Epoch 322/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1259 - accuracy: 0.9810 - val_loss: 0.1891 - val_accuracy: 0.9333\n",
            "Epoch 323/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1250 - accuracy: 0.9810 - val_loss: 0.1893 - val_accuracy: 0.9333\n",
            "Epoch 324/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1243 - accuracy: 0.9810 - val_loss: 0.1894 - val_accuracy: 0.9333\n",
            "Epoch 325/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1236 - accuracy: 0.9810 - val_loss: 0.1880 - val_accuracy: 0.9333\n",
            "Epoch 326/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1225 - accuracy: 0.9810 - val_loss: 0.1908 - val_accuracy: 0.9333\n",
            "Epoch 327/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1219 - accuracy: 0.9810 - val_loss: 0.1893 - val_accuracy: 0.9333\n",
            "Epoch 328/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1209 - accuracy: 0.9810 - val_loss: 0.1867 - val_accuracy: 0.9333\n",
            "Epoch 329/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1198 - accuracy: 0.9810 - val_loss: 0.1819 - val_accuracy: 0.9556\n",
            "Epoch 330/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1182 - accuracy: 0.9810 - val_loss: 0.1739 - val_accuracy: 0.9556\n",
            "Epoch 331/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1210 - accuracy: 0.9905 - val_loss: 0.1681 - val_accuracy: 0.9556\n",
            "Epoch 332/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1196 - accuracy: 0.9905 - val_loss: 0.1718 - val_accuracy: 0.9556\n",
            "Epoch 333/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1167 - accuracy: 0.9905 - val_loss: 0.1790 - val_accuracy: 0.9556\n",
            "Epoch 334/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1168 - accuracy: 0.9810 - val_loss: 0.1873 - val_accuracy: 0.9333\n",
            "Epoch 335/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1164 - accuracy: 0.9810 - val_loss: 0.1841 - val_accuracy: 0.9333\n",
            "Epoch 336/1000\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.1147 - accuracy: 0.9810 - val_loss: 0.1849 - val_accuracy: 0.9333\n",
            "Epoch 337/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1141 - accuracy: 0.9810 - val_loss: 0.1820 - val_accuracy: 0.9333\n",
            "Epoch 338/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1135 - accuracy: 0.9810 - val_loss: 0.1738 - val_accuracy: 0.9556\n",
            "Epoch 339/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1120 - accuracy: 0.9810 - val_loss: 0.1726 - val_accuracy: 0.9556\n",
            "Epoch 340/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1113 - accuracy: 0.9810 - val_loss: 0.1735 - val_accuracy: 0.9556\n",
            "Epoch 341/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1108 - accuracy: 0.9810 - val_loss: 0.1739 - val_accuracy: 0.9556\n",
            "Epoch 342/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1103 - accuracy: 0.9810 - val_loss: 0.1687 - val_accuracy: 0.9556\n",
            "Epoch 343/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.1093 - accuracy: 0.9810 - val_loss: 0.1699 - val_accuracy: 0.9556\n",
            "Epoch 344/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1085 - accuracy: 0.9810 - val_loss: 0.1742 - val_accuracy: 0.9556\n",
            "Epoch 345/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1086 - accuracy: 0.9810 - val_loss: 0.1789 - val_accuracy: 0.9333\n",
            "Epoch 346/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1076 - accuracy: 0.9810 - val_loss: 0.1777 - val_accuracy: 0.9333\n",
            "Epoch 347/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1066 - accuracy: 0.9810 - val_loss: 0.1726 - val_accuracy: 0.9556\n",
            "Epoch 348/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1054 - accuracy: 0.9810 - val_loss: 0.1668 - val_accuracy: 0.9556\n",
            "Epoch 349/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1051 - accuracy: 0.9810 - val_loss: 0.1643 - val_accuracy: 0.9556\n",
            "Epoch 350/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1046 - accuracy: 0.9810 - val_loss: 0.1642 - val_accuracy: 0.9556\n",
            "Epoch 351/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1044 - accuracy: 0.9810 - val_loss: 0.1684 - val_accuracy: 0.9556\n",
            "Epoch 352/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1031 - accuracy: 0.9810 - val_loss: 0.1678 - val_accuracy: 0.9556\n",
            "Epoch 353/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1025 - accuracy: 0.9810 - val_loss: 0.1674 - val_accuracy: 0.9556\n",
            "Epoch 354/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1019 - accuracy: 0.9810 - val_loss: 0.1675 - val_accuracy: 0.9556\n",
            "Epoch 355/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.1013 - accuracy: 0.9810 - val_loss: 0.1677 - val_accuracy: 0.9556\n",
            "Epoch 356/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1012 - accuracy: 0.9810 - val_loss: 0.1705 - val_accuracy: 0.9556\n",
            "Epoch 357/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1004 - accuracy: 0.9810 - val_loss: 0.1694 - val_accuracy: 0.9556\n",
            "Epoch 358/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0998 - accuracy: 0.9810 - val_loss: 0.1686 - val_accuracy: 0.9556\n",
            "Epoch 359/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0993 - accuracy: 0.9810 - val_loss: 0.1667 - val_accuracy: 0.9556\n",
            "Epoch 360/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0986 - accuracy: 0.9810 - val_loss: 0.1668 - val_accuracy: 0.9556\n",
            "Epoch 361/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0979 - accuracy: 0.9810 - val_loss: 0.1676 - val_accuracy: 0.9556\n",
            "Epoch 362/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0982 - accuracy: 0.9810 - val_loss: 0.1668 - val_accuracy: 0.9556\n",
            "Epoch 363/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0971 - accuracy: 0.9810 - val_loss: 0.1560 - val_accuracy: 0.9556\n",
            "Epoch 364/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0977 - accuracy: 0.9810 - val_loss: 0.1489 - val_accuracy: 0.9556\n",
            "Epoch 365/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0994 - accuracy: 0.9905 - val_loss: 0.1472 - val_accuracy: 0.9556\n",
            "Epoch 366/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0984 - accuracy: 0.9905 - val_loss: 0.1507 - val_accuracy: 0.9556\n",
            "Epoch 367/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0956 - accuracy: 0.9905 - val_loss: 0.1541 - val_accuracy: 0.9556\n",
            "Epoch 368/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0944 - accuracy: 0.9810 - val_loss: 0.1611 - val_accuracy: 0.9556\n",
            "Epoch 369/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0944 - accuracy: 0.9810 - val_loss: 0.1666 - val_accuracy: 0.9556\n",
            "Epoch 370/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0939 - accuracy: 0.9810 - val_loss: 0.1657 - val_accuracy: 0.9556\n",
            "Epoch 371/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0938 - accuracy: 0.9810 - val_loss: 0.1657 - val_accuracy: 0.9556\n",
            "Epoch 372/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0934 - accuracy: 0.9810 - val_loss: 0.1600 - val_accuracy: 0.9556\n",
            "Epoch 373/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0925 - accuracy: 0.9810 - val_loss: 0.1608 - val_accuracy: 0.9556\n",
            "Epoch 374/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0912 - accuracy: 0.9810 - val_loss: 0.1544 - val_accuracy: 0.9556\n",
            "Epoch 375/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0912 - accuracy: 0.9810 - val_loss: 0.1514 - val_accuracy: 0.9556\n",
            "Epoch 376/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0903 - accuracy: 0.9810 - val_loss: 0.1541 - val_accuracy: 0.9556\n",
            "Epoch 377/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0905 - accuracy: 0.9810 - val_loss: 0.1591 - val_accuracy: 0.9556\n",
            "Epoch 378/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0896 - accuracy: 0.9810 - val_loss: 0.1581 - val_accuracy: 0.9556\n",
            "Epoch 379/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0890 - accuracy: 0.9810 - val_loss: 0.1580 - val_accuracy: 0.9556\n",
            "Epoch 380/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0886 - accuracy: 0.9810 - val_loss: 0.1593 - val_accuracy: 0.9556\n",
            "Epoch 381/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0883 - accuracy: 0.9810 - val_loss: 0.1585 - val_accuracy: 0.9556\n",
            "Epoch 382/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0886 - accuracy: 0.9810 - val_loss: 0.1595 - val_accuracy: 0.9556\n",
            "Epoch 383/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0873 - accuracy: 0.9810 - val_loss: 0.1545 - val_accuracy: 0.9556\n",
            "Epoch 384/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0870 - accuracy: 0.9810 - val_loss: 0.1489 - val_accuracy: 0.9556\n",
            "Epoch 385/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0864 - accuracy: 0.9810 - val_loss: 0.1477 - val_accuracy: 0.9556\n",
            "Epoch 386/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0863 - accuracy: 0.9810 - val_loss: 0.1480 - val_accuracy: 0.9556\n",
            "Epoch 387/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0860 - accuracy: 0.9810 - val_loss: 0.1470 - val_accuracy: 0.9556\n",
            "Epoch 388/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0853 - accuracy: 0.9810 - val_loss: 0.1489 - val_accuracy: 0.9556\n",
            "Epoch 389/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0840 - accuracy: 0.9810 - val_loss: 0.1561 - val_accuracy: 0.9556\n",
            "Epoch 390/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0856 - accuracy: 0.9810 - val_loss: 0.1628 - val_accuracy: 0.9556\n",
            "Epoch 391/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0852 - accuracy: 0.9810 - val_loss: 0.1591 - val_accuracy: 0.9556\n",
            "Epoch 392/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0837 - accuracy: 0.9810 - val_loss: 0.1523 - val_accuracy: 0.9556\n",
            "Epoch 393/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0828 - accuracy: 0.9810 - val_loss: 0.1441 - val_accuracy: 0.9556\n",
            "Epoch 394/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0843 - accuracy: 0.9810 - val_loss: 0.1416 - val_accuracy: 0.9556\n",
            "Epoch 395/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0825 - accuracy: 0.9905 - val_loss: 0.1465 - val_accuracy: 0.9556\n",
            "Epoch 396/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0816 - accuracy: 0.9810 - val_loss: 0.1528 - val_accuracy: 0.9556\n",
            "Epoch 397/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0821 - accuracy: 0.9810 - val_loss: 0.1559 - val_accuracy: 0.9556\n",
            "Epoch 398/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0827 - accuracy: 0.9810 - val_loss: 0.1541 - val_accuracy: 0.9556\n",
            "Epoch 399/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0810 - accuracy: 0.9810 - val_loss: 0.1461 - val_accuracy: 0.9556\n",
            "Epoch 400/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0804 - accuracy: 0.9810 - val_loss: 0.1440 - val_accuracy: 0.9556\n",
            "Epoch 401/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0799 - accuracy: 0.9810 - val_loss: 0.1467 - val_accuracy: 0.9556\n",
            "Epoch 402/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0793 - accuracy: 0.9810 - val_loss: 0.1524 - val_accuracy: 0.9556\n",
            "Epoch 403/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0797 - accuracy: 0.9810 - val_loss: 0.1560 - val_accuracy: 0.9556\n",
            "Epoch 404/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0800 - accuracy: 0.9810 - val_loss: 0.1550 - val_accuracy: 0.9556\n",
            "Epoch 405/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0797 - accuracy: 0.9810 - val_loss: 0.1496 - val_accuracy: 0.9556\n",
            "Epoch 406/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0784 - accuracy: 0.9810 - val_loss: 0.1460 - val_accuracy: 0.9556\n",
            "Epoch 407/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0782 - accuracy: 0.9810 - val_loss: 0.1430 - val_accuracy: 0.9556\n",
            "Epoch 408/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0783 - accuracy: 0.9810 - val_loss: 0.1408 - val_accuracy: 0.9556\n",
            "Epoch 409/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0775 - accuracy: 0.9810 - val_loss: 0.1393 - val_accuracy: 0.9556\n",
            "Epoch 410/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0774 - accuracy: 0.9810 - val_loss: 0.1399 - val_accuracy: 0.9556\n",
            "Epoch 411/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0775 - accuracy: 0.9810 - val_loss: 0.1421 - val_accuracy: 0.9556\n",
            "Epoch 412/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0764 - accuracy: 0.9810 - val_loss: 0.1408 - val_accuracy: 0.9556\n",
            "Epoch 413/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0762 - accuracy: 0.9810 - val_loss: 0.1405 - val_accuracy: 0.9556\n",
            "Epoch 414/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0761 - accuracy: 0.9810 - val_loss: 0.1421 - val_accuracy: 0.9556\n",
            "Epoch 415/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0755 - accuracy: 0.9810 - val_loss: 0.1417 - val_accuracy: 0.9556\n",
            "Epoch 416/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0752 - accuracy: 0.9810 - val_loss: 0.1425 - val_accuracy: 0.9556\n",
            "Epoch 417/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0751 - accuracy: 0.9810 - val_loss: 0.1434 - val_accuracy: 0.9556\n",
            "Epoch 418/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0747 - accuracy: 0.9810 - val_loss: 0.1405 - val_accuracy: 0.9556\n",
            "Epoch 419/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0743 - accuracy: 0.9810 - val_loss: 0.1384 - val_accuracy: 0.9556\n",
            "Epoch 420/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0743 - accuracy: 0.9810 - val_loss: 0.1361 - val_accuracy: 0.9556\n",
            "Epoch 421/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0744 - accuracy: 0.9810 - val_loss: 0.1363 - val_accuracy: 0.9556\n",
            "Epoch 422/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0738 - accuracy: 0.9810 - val_loss: 0.1343 - val_accuracy: 0.9556\n",
            "Epoch 423/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0740 - accuracy: 0.9810 - val_loss: 0.1353 - val_accuracy: 0.9556\n",
            "Epoch 424/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0733 - accuracy: 0.9810 - val_loss: 0.1399 - val_accuracy: 0.9556\n",
            "Epoch 425/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0727 - accuracy: 0.9810 - val_loss: 0.1386 - val_accuracy: 0.9556\n",
            "Epoch 426/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0726 - accuracy: 0.9810 - val_loss: 0.1391 - val_accuracy: 0.9556\n",
            "Epoch 427/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0725 - accuracy: 0.9810 - val_loss: 0.1417 - val_accuracy: 0.9556\n",
            "Epoch 428/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0719 - accuracy: 0.9810 - val_loss: 0.1433 - val_accuracy: 0.9556\n",
            "Epoch 429/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0720 - accuracy: 0.9810 - val_loss: 0.1448 - val_accuracy: 0.9556\n",
            "Epoch 430/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0717 - accuracy: 0.9810 - val_loss: 0.1419 - val_accuracy: 0.9556\n",
            "Epoch 431/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0722 - accuracy: 0.9810 - val_loss: 0.1347 - val_accuracy: 0.9556\n",
            "Epoch 432/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0712 - accuracy: 0.9810 - val_loss: 0.1352 - val_accuracy: 0.9556\n",
            "Epoch 433/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0711 - accuracy: 0.9810 - val_loss: 0.1346 - val_accuracy: 0.9556\n",
            "Epoch 434/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0709 - accuracy: 0.9810 - val_loss: 0.1397 - val_accuracy: 0.9556\n",
            "Epoch 435/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0703 - accuracy: 0.9810 - val_loss: 0.1441 - val_accuracy: 0.9556\n",
            "Epoch 436/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0703 - accuracy: 0.9810 - val_loss: 0.1437 - val_accuracy: 0.9556\n",
            "Epoch 437/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0700 - accuracy: 0.9810 - val_loss: 0.1414 - val_accuracy: 0.9556\n",
            "Epoch 438/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0695 - accuracy: 0.9810 - val_loss: 0.1369 - val_accuracy: 0.9556\n",
            "Epoch 439/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0697 - accuracy: 0.9810 - val_loss: 0.1288 - val_accuracy: 0.9778\n",
            "Epoch 440/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0713 - accuracy: 0.9905 - val_loss: 0.1259 - val_accuracy: 0.9778\n",
            "Epoch 441/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0711 - accuracy: 0.9905 - val_loss: 0.1291 - val_accuracy: 0.9556\n",
            "Epoch 442/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0680 - accuracy: 0.9810 - val_loss: 0.1406 - val_accuracy: 0.9556\n",
            "Epoch 443/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0683 - accuracy: 0.9810 - val_loss: 0.1541 - val_accuracy: 0.9556\n",
            "Epoch 444/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0717 - accuracy: 0.9810 - val_loss: 0.1586 - val_accuracy: 0.9556\n",
            "Epoch 445/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0713 - accuracy: 0.9810 - val_loss: 0.1463 - val_accuracy: 0.9556\n",
            "Epoch 446/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0680 - accuracy: 0.9810 - val_loss: 0.1359 - val_accuracy: 0.9556\n",
            "Epoch 447/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0668 - accuracy: 0.9810 - val_loss: 0.1296 - val_accuracy: 0.9556\n",
            "Epoch 448/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0677 - accuracy: 0.9810 - val_loss: 0.1283 - val_accuracy: 0.9556\n",
            "Epoch 449/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0679 - accuracy: 0.9905 - val_loss: 0.1291 - val_accuracy: 0.9556\n",
            "Epoch 450/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0673 - accuracy: 0.9810 - val_loss: 0.1355 - val_accuracy: 0.9556\n",
            "Epoch 451/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0667 - accuracy: 0.9810 - val_loss: 0.1381 - val_accuracy: 0.9556\n",
            "Epoch 452/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0671 - accuracy: 0.9810 - val_loss: 0.1350 - val_accuracy: 0.9556\n",
            "Epoch 453/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0663 - accuracy: 0.9810 - val_loss: 0.1343 - val_accuracy: 0.9556\n",
            "Epoch 454/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0665 - accuracy: 0.9810 - val_loss: 0.1372 - val_accuracy: 0.9556\n",
            "Epoch 455/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0665 - accuracy: 0.9810 - val_loss: 0.1324 - val_accuracy: 0.9556\n",
            "Epoch 456/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0653 - accuracy: 0.9810 - val_loss: 0.1349 - val_accuracy: 0.9556\n",
            "Epoch 457/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0659 - accuracy: 0.9810 - val_loss: 0.1399 - val_accuracy: 0.9556\n",
            "Epoch 458/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0656 - accuracy: 0.9810 - val_loss: 0.1404 - val_accuracy: 0.9556\n",
            "Epoch 459/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0661 - accuracy: 0.9810 - val_loss: 0.1432 - val_accuracy: 0.9556\n",
            "Epoch 460/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0657 - accuracy: 0.9810 - val_loss: 0.1411 - val_accuracy: 0.9556\n",
            "Epoch 461/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0650 - accuracy: 0.9810 - val_loss: 0.1363 - val_accuracy: 0.9556\n",
            "Epoch 462/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0644 - accuracy: 0.9810 - val_loss: 0.1330 - val_accuracy: 0.9556\n",
            "Epoch 463/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0639 - accuracy: 0.9810 - val_loss: 0.1300 - val_accuracy: 0.9556\n",
            "Epoch 464/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0640 - accuracy: 0.9810 - val_loss: 0.1304 - val_accuracy: 0.9556\n",
            "Epoch 465/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0640 - accuracy: 0.9810 - val_loss: 0.1292 - val_accuracy: 0.9556\n",
            "Epoch 466/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0636 - accuracy: 0.9810 - val_loss: 0.1278 - val_accuracy: 0.9556\n",
            "Epoch 467/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0640 - accuracy: 0.9810 - val_loss: 0.1278 - val_accuracy: 0.9556\n",
            "Epoch 468/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0635 - accuracy: 0.9810 - val_loss: 0.1292 - val_accuracy: 0.9556\n",
            "Epoch 469/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0635 - accuracy: 0.9810 - val_loss: 0.1320 - val_accuracy: 0.9556\n",
            "Epoch 470/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0627 - accuracy: 0.9810 - val_loss: 0.1294 - val_accuracy: 0.9556\n",
            "Epoch 471/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0635 - accuracy: 0.9810 - val_loss: 0.1250 - val_accuracy: 0.9778\n",
            "Epoch 472/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0633 - accuracy: 0.9905 - val_loss: 0.1253 - val_accuracy: 0.9778\n",
            "Epoch 473/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0628 - accuracy: 0.9905 - val_loss: 0.1277 - val_accuracy: 0.9556\n",
            "Epoch 474/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0622 - accuracy: 0.9810 - val_loss: 0.1317 - val_accuracy: 0.9556\n",
            "Epoch 475/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0623 - accuracy: 0.9810 - val_loss: 0.1329 - val_accuracy: 0.9556\n",
            "Epoch 476/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0624 - accuracy: 0.9810 - val_loss: 0.1402 - val_accuracy: 0.9556\n",
            "Epoch 477/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0626 - accuracy: 0.9810 - val_loss: 0.1384 - val_accuracy: 0.9556\n",
            "Epoch 478/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0623 - accuracy: 0.9810 - val_loss: 0.1336 - val_accuracy: 0.9556\n",
            "Epoch 479/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0619 - accuracy: 0.9810 - val_loss: 0.1304 - val_accuracy: 0.9556\n",
            "Epoch 480/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0613 - accuracy: 0.9810 - val_loss: 0.1295 - val_accuracy: 0.9556\n",
            "Epoch 481/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.9810 - val_loss: 0.1285 - val_accuracy: 0.9556\n",
            "Epoch 482/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0617 - accuracy: 0.9810 - val_loss: 0.1245 - val_accuracy: 0.9778\n",
            "Epoch 483/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0612 - accuracy: 0.9810 - val_loss: 0.1259 - val_accuracy: 0.9556\n",
            "Epoch 484/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0612 - accuracy: 0.9810 - val_loss: 0.1283 - val_accuracy: 0.9556\n",
            "Epoch 485/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0604 - accuracy: 0.9810 - val_loss: 0.1285 - val_accuracy: 0.9556\n",
            "Epoch 486/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0603 - accuracy: 0.9810 - val_loss: 0.1293 - val_accuracy: 0.9556\n",
            "Epoch 487/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0601 - accuracy: 0.9810 - val_loss: 0.1338 - val_accuracy: 0.9556\n",
            "Epoch 488/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0607 - accuracy: 0.9810 - val_loss: 0.1409 - val_accuracy: 0.9556\n",
            "Epoch 489/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0610 - accuracy: 0.9810 - val_loss: 0.1410 - val_accuracy: 0.9556\n",
            "Epoch 490/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0611 - accuracy: 0.9810 - val_loss: 0.1360 - val_accuracy: 0.9556\n",
            "Epoch 491/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0599 - accuracy: 0.9810 - val_loss: 0.1338 - val_accuracy: 0.9556\n",
            "Epoch 492/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0598 - accuracy: 0.9810 - val_loss: 0.1310 - val_accuracy: 0.9556\n",
            "Epoch 493/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0596 - accuracy: 0.9810 - val_loss: 0.1225 - val_accuracy: 0.9778\n",
            "Epoch 494/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0597 - accuracy: 0.9905 - val_loss: 0.1223 - val_accuracy: 0.9778\n",
            "Epoch 495/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0593 - accuracy: 0.9905 - val_loss: 0.1249 - val_accuracy: 0.9556\n",
            "Epoch 496/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0590 - accuracy: 0.9810 - val_loss: 0.1299 - val_accuracy: 0.9556\n",
            "Epoch 497/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0586 - accuracy: 0.9810 - val_loss: 0.1290 - val_accuracy: 0.9556\n",
            "Epoch 498/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0585 - accuracy: 0.9810 - val_loss: 0.1288 - val_accuracy: 0.9556\n",
            "Epoch 499/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0582 - accuracy: 0.9810 - val_loss: 0.1299 - val_accuracy: 0.9556\n",
            "Epoch 500/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0581 - accuracy: 0.9810 - val_loss: 0.1291 - val_accuracy: 0.9556\n",
            "Epoch 501/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0581 - accuracy: 0.9810 - val_loss: 0.1269 - val_accuracy: 0.9556\n",
            "Epoch 502/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0588 - accuracy: 0.9905 - val_loss: 0.1207 - val_accuracy: 0.9778\n",
            "Epoch 503/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0586 - accuracy: 0.9905 - val_loss: 0.1226 - val_accuracy: 0.9778\n",
            "Epoch 504/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0580 - accuracy: 0.9810 - val_loss: 0.1262 - val_accuracy: 0.9556\n",
            "Epoch 505/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0572 - accuracy: 0.9810 - val_loss: 0.1281 - val_accuracy: 0.9556\n",
            "Epoch 506/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0571 - accuracy: 0.9810 - val_loss: 0.1315 - val_accuracy: 0.9556\n",
            "Epoch 507/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0573 - accuracy: 0.9810 - val_loss: 0.1321 - val_accuracy: 0.9556\n",
            "Epoch 508/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0572 - accuracy: 0.9810 - val_loss: 0.1307 - val_accuracy: 0.9556\n",
            "Epoch 509/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0574 - accuracy: 0.9810 - val_loss: 0.1307 - val_accuracy: 0.9556\n",
            "Epoch 510/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0569 - accuracy: 0.9810 - val_loss: 0.1282 - val_accuracy: 0.9556\n",
            "Epoch 511/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0560 - accuracy: 0.9810 - val_loss: 0.1213 - val_accuracy: 0.9778\n",
            "Epoch 512/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0578 - accuracy: 0.9905 - val_loss: 0.1181 - val_accuracy: 0.9778\n",
            "Epoch 513/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0585 - accuracy: 0.9905 - val_loss: 0.1188 - val_accuracy: 0.9778\n",
            "Epoch 514/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0579 - accuracy: 0.9905 - val_loss: 0.1198 - val_accuracy: 0.9778\n",
            "Epoch 515/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0570 - accuracy: 0.9905 - val_loss: 0.1197 - val_accuracy: 0.9778\n",
            "Epoch 516/1000\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0568 - accuracy: 0.9905 - val_loss: 0.1217 - val_accuracy: 0.9778\n",
            "Epoch 517/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0583 - accuracy: 0.9810 - val_loss: 0.1294 - val_accuracy: 0.9556\n",
            "Epoch 518/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0558 - accuracy: 0.9810 - val_loss: 0.1261 - val_accuracy: 0.9556\n",
            "Epoch 519/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0565 - accuracy: 0.9810 - val_loss: 0.1246 - val_accuracy: 0.9556\n",
            "Epoch 520/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0548 - accuracy: 0.9810 - val_loss: 0.1298 - val_accuracy: 0.9556\n",
            "Epoch 521/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0554 - accuracy: 0.9810 - val_loss: 0.1330 - val_accuracy: 0.9556\n",
            "Epoch 522/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0560 - accuracy: 0.9810 - val_loss: 0.1311 - val_accuracy: 0.9556\n",
            "Epoch 523/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0556 - accuracy: 0.9810 - val_loss: 0.1309 - val_accuracy: 0.9556\n",
            "Epoch 524/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0555 - accuracy: 0.9810 - val_loss: 0.1308 - val_accuracy: 0.9556\n",
            "Epoch 525/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0552 - accuracy: 0.9810 - val_loss: 0.1300 - val_accuracy: 0.9556\n",
            "Epoch 526/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0549 - accuracy: 0.9810 - val_loss: 0.1287 - val_accuracy: 0.9556\n",
            "Epoch 527/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0547 - accuracy: 0.9810 - val_loss: 0.1265 - val_accuracy: 0.9556\n",
            "Epoch 528/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0546 - accuracy: 0.9810 - val_loss: 0.1232 - val_accuracy: 0.9778\n",
            "Epoch 529/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0544 - accuracy: 0.9810 - val_loss: 0.1232 - val_accuracy: 0.9778\n",
            "Epoch 530/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0542 - accuracy: 0.9810 - val_loss: 0.1250 - val_accuracy: 0.9556\n",
            "Epoch 531/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0541 - accuracy: 0.9810 - val_loss: 0.1291 - val_accuracy: 0.9556\n",
            "Epoch 532/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0545 - accuracy: 0.9810 - val_loss: 0.1309 - val_accuracy: 0.9556\n",
            "Epoch 533/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0545 - accuracy: 0.9810 - val_loss: 0.1276 - val_accuracy: 0.9556\n",
            "Epoch 534/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0539 - accuracy: 0.9810 - val_loss: 0.1259 - val_accuracy: 0.9556\n",
            "Epoch 535/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0544 - accuracy: 0.9810 - val_loss: 0.1206 - val_accuracy: 0.9778\n",
            "Epoch 536/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0540 - accuracy: 0.9810 - val_loss: 0.1225 - val_accuracy: 0.9778\n",
            "Epoch 537/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0536 - accuracy: 0.9810 - val_loss: 0.1281 - val_accuracy: 0.9556\n",
            "Epoch 538/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0539 - accuracy: 0.9810 - val_loss: 0.1271 - val_accuracy: 0.9556\n",
            "Epoch 539/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0529 - accuracy: 0.9810 - val_loss: 0.1196 - val_accuracy: 0.9778\n",
            "Epoch 540/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0540 - accuracy: 0.9905 - val_loss: 0.1167 - val_accuracy: 0.9778\n",
            "Epoch 541/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0548 - accuracy: 0.9905 - val_loss: 0.1169 - val_accuracy: 0.9778\n",
            "Epoch 542/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0540 - accuracy: 0.9905 - val_loss: 0.1199 - val_accuracy: 0.9778\n",
            "Epoch 543/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0547 - accuracy: 0.9810 - val_loss: 0.1249 - val_accuracy: 0.9556\n",
            "Epoch 544/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0526 - accuracy: 0.9810 - val_loss: 0.1227 - val_accuracy: 0.9778\n",
            "Epoch 545/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0531 - accuracy: 0.9810 - val_loss: 0.1206 - val_accuracy: 0.9778\n",
            "Epoch 546/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0529 - accuracy: 0.9810 - val_loss: 0.1198 - val_accuracy: 0.9778\n",
            "Epoch 547/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0530 - accuracy: 0.9810 - val_loss: 0.1173 - val_accuracy: 0.9778\n",
            "Epoch 548/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0538 - accuracy: 0.9905 - val_loss: 0.1164 - val_accuracy: 0.9778\n",
            "Epoch 549/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0534 - accuracy: 0.9905 - val_loss: 0.1211 - val_accuracy: 0.9778\n",
            "Epoch 550/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0531 - accuracy: 0.9810 - val_loss: 0.1270 - val_accuracy: 0.9556\n",
            "Epoch 551/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0523 - accuracy: 0.9810 - val_loss: 0.1293 - val_accuracy: 0.9556\n",
            "Epoch 552/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0530 - accuracy: 0.9810 - val_loss: 0.1321 - val_accuracy: 0.9556\n",
            "Epoch 553/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0526 - accuracy: 0.9810 - val_loss: 0.1288 - val_accuracy: 0.9556\n",
            "Epoch 554/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0524 - accuracy: 0.9810 - val_loss: 0.1252 - val_accuracy: 0.9556\n",
            "Epoch 555/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0524 - accuracy: 0.9810 - val_loss: 0.1284 - val_accuracy: 0.9556\n",
            "Epoch 556/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0522 - accuracy: 0.9810 - val_loss: 0.1307 - val_accuracy: 0.9556\n",
            "Epoch 557/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0522 - accuracy: 0.9810 - val_loss: 0.1301 - val_accuracy: 0.9556\n",
            "Epoch 558/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0521 - accuracy: 0.9810 - val_loss: 0.1266 - val_accuracy: 0.9556\n",
            "Epoch 559/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0515 - accuracy: 0.9810 - val_loss: 0.1233 - val_accuracy: 0.9778\n",
            "Epoch 560/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0516 - accuracy: 0.9810 - val_loss: 0.1234 - val_accuracy: 0.9778\n",
            "Epoch 561/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0519 - accuracy: 0.9810 - val_loss: 0.1285 - val_accuracy: 0.9556\n",
            "Epoch 562/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0517 - accuracy: 0.9810 - val_loss: 0.1290 - val_accuracy: 0.9556\n",
            "Epoch 563/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0513 - accuracy: 0.9810 - val_loss: 0.1239 - val_accuracy: 0.9556\n",
            "Epoch 564/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0509 - accuracy: 0.9810 - val_loss: 0.1209 - val_accuracy: 0.9778\n",
            "Epoch 565/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0509 - accuracy: 0.9810 - val_loss: 0.1211 - val_accuracy: 0.9778\n",
            "Epoch 566/1000\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0507 - accuracy: 0.9810 - val_loss: 0.1232 - val_accuracy: 0.9778\n",
            "Epoch 567/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0506 - accuracy: 0.9810 - val_loss: 0.1266 - val_accuracy: 0.9556\n",
            "Epoch 568/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0509 - accuracy: 0.9810 - val_loss: 0.1294 - val_accuracy: 0.9556\n",
            "Epoch 569/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0509 - accuracy: 0.9810 - val_loss: 0.1316 - val_accuracy: 0.9556\n",
            "Epoch 570/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0526 - accuracy: 0.9810 - val_loss: 0.1341 - val_accuracy: 0.9556\n",
            "Epoch 571/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0520 - accuracy: 0.9810 - val_loss: 0.1259 - val_accuracy: 0.9556\n",
            "Epoch 572/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0500 - accuracy: 0.9810 - val_loss: 0.1218 - val_accuracy: 0.9778\n",
            "Epoch 573/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0499 - accuracy: 0.9810 - val_loss: 0.1194 - val_accuracy: 0.9778\n",
            "Epoch 574/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0504 - accuracy: 0.9810 - val_loss: 0.1174 - val_accuracy: 0.9778\n",
            "Epoch 575/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0505 - accuracy: 0.9905 - val_loss: 0.1182 - val_accuracy: 0.9778\n",
            "Epoch 576/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0496 - accuracy: 0.9810 - val_loss: 0.1224 - val_accuracy: 0.9778\n",
            "Epoch 577/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0514 - accuracy: 0.9810 - val_loss: 0.1322 - val_accuracy: 0.9556\n",
            "Epoch 578/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0508 - accuracy: 0.9810 - val_loss: 0.1309 - val_accuracy: 0.9556\n",
            "Epoch 579/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0503 - accuracy: 0.9810 - val_loss: 0.1270 - val_accuracy: 0.9556\n",
            "Epoch 580/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0500 - accuracy: 0.9810 - val_loss: 0.1232 - val_accuracy: 0.9778\n",
            "Epoch 581/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0495 - accuracy: 0.9810 - val_loss: 0.1236 - val_accuracy: 0.9778\n",
            "Epoch 582/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0496 - accuracy: 0.9810 - val_loss: 0.1237 - val_accuracy: 0.9778\n",
            "Epoch 583/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0509 - accuracy: 0.9810 - val_loss: 0.1308 - val_accuracy: 0.9556\n",
            "Epoch 584/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0512 - accuracy: 0.9810 - val_loss: 0.1307 - val_accuracy: 0.9556\n",
            "Epoch 585/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0520 - accuracy: 0.9810 - val_loss: 0.1191 - val_accuracy: 0.9778\n",
            "Epoch 586/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0502 - accuracy: 0.9810 - val_loss: 0.1163 - val_accuracy: 0.9778\n",
            "Epoch 587/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0496 - accuracy: 0.9905 - val_loss: 0.1179 - val_accuracy: 0.9778\n",
            "Epoch 588/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0490 - accuracy: 0.9810 - val_loss: 0.1204 - val_accuracy: 0.9778\n",
            "Epoch 589/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0496 - accuracy: 0.9810 - val_loss: 0.1260 - val_accuracy: 0.9556\n",
            "Epoch 590/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0495 - accuracy: 0.9810 - val_loss: 0.1277 - val_accuracy: 0.9556\n",
            "Epoch 591/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0482 - accuracy: 0.9810 - val_loss: 0.1211 - val_accuracy: 0.9778\n",
            "Epoch 592/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0486 - accuracy: 0.9810 - val_loss: 0.1162 - val_accuracy: 0.9778\n",
            "Epoch 593/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0494 - accuracy: 0.9905 - val_loss: 0.1143 - val_accuracy: 0.9778\n",
            "Epoch 594/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0512 - accuracy: 0.9905 - val_loss: 0.1132 - val_accuracy: 0.9778\n",
            "Epoch 595/1000\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0502 - accuracy: 0.9905 - val_loss: 0.1168 - val_accuracy: 0.9778\n",
            "Epoch 596/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0488 - accuracy: 0.9905 - val_loss: 0.1225 - val_accuracy: 0.9778\n",
            "Epoch 597/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0487 - accuracy: 0.9810 - val_loss: 0.1249 - val_accuracy: 0.9556\n",
            "Epoch 598/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0482 - accuracy: 0.9810 - val_loss: 0.1229 - val_accuracy: 0.9778\n",
            "Epoch 599/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0481 - accuracy: 0.9810 - val_loss: 0.1223 - val_accuracy: 0.9778\n",
            "Epoch 600/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0487 - accuracy: 0.9810 - val_loss: 0.1249 - val_accuracy: 0.9556\n",
            "Epoch 601/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0480 - accuracy: 0.9810 - val_loss: 0.1235 - val_accuracy: 0.9778\n",
            "Epoch 602/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0479 - accuracy: 0.9810 - val_loss: 0.1211 - val_accuracy: 0.9778\n",
            "Epoch 603/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0498 - accuracy: 0.9810 - val_loss: 0.1155 - val_accuracy: 0.9778\n",
            "Epoch 604/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0486 - accuracy: 0.9905 - val_loss: 0.1178 - val_accuracy: 0.9778\n",
            "Epoch 605/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0477 - accuracy: 0.9810 - val_loss: 0.1195 - val_accuracy: 0.9778\n",
            "Epoch 606/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0474 - accuracy: 0.9810 - val_loss: 0.1224 - val_accuracy: 0.9778\n",
            "Epoch 607/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0479 - accuracy: 0.9810 - val_loss: 0.1257 - val_accuracy: 0.9556\n",
            "Epoch 608/1000\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.0477 - accuracy: 0.9810 - val_loss: 0.1242 - val_accuracy: 0.9778\n",
            "Epoch 609/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0476 - accuracy: 0.9810 - val_loss: 0.1192 - val_accuracy: 0.9778\n",
            "Epoch 610/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0476 - accuracy: 0.9810 - val_loss: 0.1208 - val_accuracy: 0.9778\n",
            "Epoch 611/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0483 - accuracy: 0.9810 - val_loss: 0.1251 - val_accuracy: 0.9556\n",
            "Epoch 612/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0470 - accuracy: 0.9810 - val_loss: 0.1213 - val_accuracy: 0.9778\n",
            "Epoch 613/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0472 - accuracy: 0.9810 - val_loss: 0.1200 - val_accuracy: 0.9778\n",
            "Epoch 614/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0470 - accuracy: 0.9810 - val_loss: 0.1189 - val_accuracy: 0.9778\n",
            "Epoch 615/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0474 - accuracy: 0.9810 - val_loss: 0.1171 - val_accuracy: 0.9778\n",
            "Epoch 616/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0470 - accuracy: 0.9905 - val_loss: 0.1144 - val_accuracy: 0.9778\n",
            "Epoch 617/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0487 - accuracy: 0.9905 - val_loss: 0.1140 - val_accuracy: 0.9778\n",
            "Epoch 618/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0481 - accuracy: 0.9905 - val_loss: 0.1175 - val_accuracy: 0.9778\n",
            "Epoch 619/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0464 - accuracy: 0.9810 - val_loss: 0.1222 - val_accuracy: 0.9778\n",
            "Epoch 620/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0471 - accuracy: 0.9810 - val_loss: 0.1297 - val_accuracy: 0.9556\n",
            "Epoch 621/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0484 - accuracy: 0.9810 - val_loss: 0.1346 - val_accuracy: 0.9556\n",
            "Epoch 622/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0488 - accuracy: 0.9810 - val_loss: 0.1320 - val_accuracy: 0.9556\n",
            "Epoch 623/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0474 - accuracy: 0.9810 - val_loss: 0.1210 - val_accuracy: 0.9778\n",
            "Epoch 624/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0490 - accuracy: 0.9810 - val_loss: 0.1155 - val_accuracy: 0.9778\n",
            "Epoch 625/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0473 - accuracy: 0.9905 - val_loss: 0.1177 - val_accuracy: 0.9778\n",
            "Epoch 626/1000\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.0465 - accuracy: 0.9810 - val_loss: 0.1195 - val_accuracy: 0.9778\n",
            "Epoch 627/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0467 - accuracy: 0.9810 - val_loss: 0.1257 - val_accuracy: 0.9556\n",
            "Epoch 628/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0468 - accuracy: 0.9810 - val_loss: 0.1254 - val_accuracy: 0.9556\n",
            "Epoch 629/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0472 - accuracy: 0.9810 - val_loss: 0.1216 - val_accuracy: 0.9778\n",
            "Epoch 630/1000\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.0459 - accuracy: 0.9810 - val_loss: 0.1223 - val_accuracy: 0.9778\n",
            "Epoch 631/1000\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.0461 - accuracy: 0.9810 - val_loss: 0.1217 - val_accuracy: 0.9778\n",
            "Epoch 632/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0453 - accuracy: 0.9810 - val_loss: 0.1157 - val_accuracy: 0.9778\n",
            "Epoch 633/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0494 - accuracy: 0.9905 - val_loss: 0.1108 - val_accuracy: 0.9556\n",
            "Epoch 634/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0529 - accuracy: 0.9810 - val_loss: 0.1107 - val_accuracy: 0.9556\n",
            "Epoch 635/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0515 - accuracy: 0.9905 - val_loss: 0.1132 - val_accuracy: 0.9778\n",
            "Epoch 636/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0469 - accuracy: 0.9905 - val_loss: 0.1257 - val_accuracy: 0.9556\n",
            "Epoch 637/1000\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.0452 - accuracy: 0.9810 - val_loss: 0.1350 - val_accuracy: 0.9556\n",
            "Epoch 638/1000\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.0245 - accuracy: 1.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-f49a5215b102>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Treinar modelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodelo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_teste\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_teste\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_I-7dOmESo7"
      },
      "source": [
        "#Realizar previsoes e lógica para, trazer True quando resultado > 0.5 e false para <\n",
        "previsoes = modelo.predict(X_teste)\n",
        "previsoes = (previsoes > 0.5)\n",
        "previsoes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4rC3bOZElqo"
      },
      "source": [
        "#Como é um problema com 3 tipos de saídas buscamos a previsao que possui maior valor\n",
        "y_teste_matrix = [np.argmax(t) for t in y_teste]\n",
        "y_prev_matrix = [np.argmax(t) for t in previsoes]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQWbfxFDF_64"
      },
      "source": [
        "#Gerar matriz de confusão\n",
        "conf = confusion_matrix(y_teste_matrix, y_prev_matrix)\n",
        "conf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fn8VOLBEv-o"
      },
      "source": [
        "# **Deep Learning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKhjyKO-J9Yo"
      },
      "source": [
        "pip install tensorflow -q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFdwqJLjE3v3"
      },
      "source": [
        "#Importar bibliotecas\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5-hBE4CF5Dn"
      },
      "source": [
        "#Importar dados e dividir automaticamente entre treino e teste\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfqX6rwEKGJu",
        "outputId": "f576dc2d-fd6d-4621-acdf-1053728c57b0"
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "mwCOv-cFGLiH",
        "outputId": "dab764b1-1525-49ab-c3d0-cf06eae386d9"
      },
      "source": [
        "#Ver imagem do dataset\n",
        "plt.imshow(X_train[610], cmap = 'gray');\n",
        "plt.title(y_train[610])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, '5')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAOAElEQVR4nO3dfahc9Z3H8c/H6CUYnxLDJjHN2gfEovuH1RCFlRop7aogseJDZd1kQY1Is7Ra8GmF+sfCyrK2LLsYuPWh6eqmVpuswlZXqw1ZRapJyMaoGzWSUENMDIqNwhqN3/3jHt1rvPOb65wzc8Z83y8Y7sz5zpnzdfCTc+b8zszPESEAB79D2m4AwGAQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB0Tsr3G9v/afre6bWm7J9RD2FGyLCKOqG4ntt0M6iHsQBKEHSV/b3uP7adtL2y7GdRjro3HRGyfLulFSfskfU/Sv0g6JSK2ttoYekbYMSm2H5X0HxHxz233gt5wGI/JCkluuwn0jrDjM2wfY/svbE+1fajtv5T0TUmPtt0bendo2w1gKB0m6e8kfV3Sfkn/I+mCiHi51a5QC5/ZgSQ4jAeSIOxAEoQdSIKwA0kM9Gy8bc4GAn0WERNeD1Frz277HNtbbL9q+8Y6rwWgv3oeerM9RdLLkr4t6XVJz0m6LCJeLKzDnh3os37s2RdIejUiXouIfZJ+KWlRjdcD0Ed1wj5X0h/GPX69WvYptpfaXmd7XY1tAaip7yfoImJU0qjEYTzQpjp79h2S5o17/KVqGYAhVCfsz0k6wfZXbI9o7AcOHm6mLQBN6/kwPiI+tL1M0n9KmiLp7oh4obHOADRqoN964zM70H99uagGwBcHYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiCJnudnlyTb2yTtlbRf0ocRMb+JpgA0r1bYK2dHxJ4GXgdAH3EYDyRRN+wh6THb620vnegJtpfaXmd7Xc1tAajBEdH7yvbciNhh+08kPS7pbyJibeH5vW8MwKREhCdaXmvPHhE7qr+7Ja2WtKDO6wHon57Dbnua7SM/vi/pO5I2N9UYgGbVORs/S9Jq2x+/zr9FxKONdAWgcbU+s3/ujfGZHei7vnxmB/DFQdiBJAg7kARhB5Ig7EASTXwRBkPsrLPOKtYPP/zwAXXyWeeff36xPn9++UuU3erVsPCE6o5Cvf/++8X6hRdeWKw/8sgjtbbfC/bsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AE33prwNSpU4v1G264oVifMWNGsX7ccccV6wsXLuxYO/roo4vrTpkypVjvpjSWLdUfzy7ZsmVLsf7OO+90rNXta/bs2cX6U089VawvXry41vZL+NYbkBxhB5Ig7EAShB1IgrADSRB2IAnCDiTB99kbcMYZZxTr119/fbHebZy+n2PZ+/fvL9Zfe+21Yr1bbzNnzuxYO+aYY4rrXnTRRcX6Y489Vqy/9957xXodl156abG+b9++vm27V+zZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJvs8+AFdffXWxfscddxTr3cayt2/f3rF27733FtddvXp1sb5hw4ZivZvjjz++Y+3KK68srnvnnXcW66X/7sx6/j677btt77a9edyyGbYft/1K9Xd6k80CaN5kDuN/LumcA5bdKOmJiDhB0hPVYwBDrGvYI2KtpLcOWLxI0orq/gpJFzTcF4CG9Xpt/KyI2Fndf0PSrE5PtL1U0tIetwOgIbW/CBMRUTrxFhGjkkalvCfogGHQ69DbLttzJKn6u7u5lgD0Q69hf1jSkur+EkkPNdMOgH7pOs5ue6WkhZJmStol6ceS/l3SryT9qaTtki6JiANP4k30WgflYfwtt9xSrF933XXFerffdl+/fn2xfvHFF3esMRadT6dx9q6f2SPisg6lb9XqCMBAcbkskARhB5Ig7EAShB1IgrADSfAV10m69tprO9Zuv/32Wq/9wAMPFOvdfrYYGI8pm4HkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcbZKyeddFKx/vTTT3esjYyMFNft9pPJDz74YLH+wQcfFOvAeIyzA8kRdiAJwg4kQdiBJAg7kARhB5Ig7EAStWeEOVgsW7asWD/qqKM61latWlVcd+XKlT31BDSJPTuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJME4e+XII4/sed3TTz+9WH/mmWd6fm1Jsif8evIn3nzzzY61ffv2Fddds2ZNLy19oltvpWsMSn2jeV337Lbvtr3b9uZxy261vcP2xup2Xn/bBFDXZA7jfy7pnAmW/zQiTqluv2m2LQBN6xr2iFgr6a0B9AKgj+qcoFtme1N1mD+905NsL7W9zva6GtsCUFOvYV8u6WuSTpG0U1LHmQ0jYjQi5kfE/B63BaABPYU9InZFxP6I+EjSzyQtaLYtAE3rKey254x7+F1Jmzs9F8Bw6Pq78bZXSlooaaakXZJ+XD0+RVJI2ibp6ojY2XVjQ/y78eeee26xXpqD/cQTT2y6nU/pNpY9yN/+P1C33t5+++2OtdHR0eK63ea937NnT7GeVaffje96UU1EXDbB4rtqdwRgoLhcFkiCsANJEHYgCcIOJEHYgSSYshm1XH755cX6qaee2rF21VVXFdedNm1asX7FFVcU6/fcc0+xfrBiymYgOcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJxdrTmmmuuKdZvu+22Yn1kZKRYnzdvXsfawfz1WMbZgeQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtkxtLpNdb1gQXluksWLF3es3XfffT319EXAODuQHGEHkiDsQBKEHUiCsANJEHYgCcIOJNE17Lbn2f6d7Rdtv2D7B9XyGbYft/1K9Xd6/9sF0KvJ7Nk/lPSjiDhJ0hmSvm/7JEk3SnoiIk6Q9ET1GMCQ6hr2iNgZERuq+3slvSRprqRFklZUT1sh6YJ+NQmgvs/1md32lyV9Q9LvJc2KiJ1V6Q1JsxrtDECjDp3sE20fIenXkn4YEX+0///y24iITte9214qaWndRgHUM6k9u+3DNBb0+yJiVbV4l+05VX2OpN0TrRsRoxExPyLmN9EwgN5M5my8Jd0l6aWI+Mm40sOSllT3l0h6qPn2ADRlMofxfy7pryQ9b3tjtexmSbdJ+pXtKyRtl3RJf1oE0ISuYY+IpyRN+P1YSd9qth0A/cIVdEAShB1IgrADSRB2IAnCDiRB2IEk+ClptGb27NnF+qZNm4r1mTNnFuuHHJJzX8ZPSQPJEXYgCcIOJEHYgSQIO5AEYQeSIOxAEpP+WSqgaWeffXaxfuyxxxbry5cvb7Kdgx57diAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgnF29NXUqVM71m666abiuvv37y/W77///p56yoo9O5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4k0XWc3fY8Sb+QNEtSSBqNiH+yfaukqyS9WT315oj4Tb8axXAaGRkp1p988smOtZNPPrm47po1a4r1tWvXFuv4tMlcVPOhpB9FxAbbR0pab/vxqvbTiPjH/rUHoCldwx4ROyXtrO7vtf2SpLn9bgxAsz7XZ3bbX5b0DUm/rxYts73J9t22p3dYZ6ntdbbX1eoUQC2TDrvtIyT9WtIPI+KPkpZL+pqkUzS25799ovUiYjQi5kfE/Ab6BdCjSYXd9mEaC/p9EbFKkiJiV0Tsj4iPJP1M0oL+tQmgrq5ht21Jd0l6KSJ+Mm75nHFP+66kzc23B6ApXadstn2mpP+S9Lykj6rFN0u6TGOH8CFpm6Srq5N5pddiyuaDzLPPPlusn3baaR1re/fu7XldSdq6dWuxnlWnKZsnczb+KUkTrcyYOvAFwhV0QBKEHUiCsANJEHYgCcIOJEHYgSS6jrM3ujHG2YG+6zTOzp4dSIKwA0kQdiAJwg4kQdiBJAg7kARhB5IY9JTNeyRtH/d4ZrVsGA1rb8Pal0RvvWqyt+M7FQZ6Uc1nNm6vG9bfphvW3oa1L4neejWo3jiMB5Ig7EASbYd9tOXtlwxrb8Pal0RvvRpIb61+ZgcwOG3v2QEMCGEHkmgl7LbPsb3F9qu2b2yjh05sb7P9vO2Nbc9PV82ht9v25nHLZth+3PYr1d8J59hrqbdbbe+o3ruNts9rqbd5tn9n+0XbL9j+QbW81feu0NdA3reBf2a3PUXSy5K+Lel1Sc9JuiwiXhxoIx3Y3iZpfkS0fgGG7W9KelfSLyLiz6pl/yDprYi4rfqHcnpE3DAkvd0q6d22p/GuZiuaM36acUkXSPprtfjeFfq6RAN439rYsy+Q9GpEvBYR+yT9UtKiFvoYehGxVtJbByxeJGlFdX+Fxv5nGbgOvQ2FiNgZERuq+3slfTzNeKvvXaGvgWgj7HMl/WHc49c1XPO9h6THbK+3vbTtZiYwa9w0W29ImtVmMxPoOo33IB0wzfjQvHe9TH9eFyfoPuvMiDhV0rmSvl8drg6lGPsMNkxjp5OaxntQJphm/BNtvne9Tn9eVxth3yFp3rjHX6qWDYWI2FH93S1ptYZvKupdH8+gW/3d3XI/nximabwnmmZcQ/DetTn9eRthf07SCba/YntE0vckPdxCH59he1p14kS2p0n6joZvKuqHJS2p7i+R9FCLvXzKsEzj3WmacbX83rU+/XlEDPwm6TyNnZHfKulv2+ihQ19flfTf1e2FtnuTtFJjh3UfaOzcxhWSjpX0hKRXJP1W0owh6u1fNTa19yaNBWtOS72dqbFD9E2SNla389p+7wp9DeR943JZIAlO0AFJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEv8HXqh0du9bZNkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVdm8p-PKiZf"
      },
      "source": [
        "#Mudar dimensão, original está 28x28 e precisamos de 784\n",
        "X_train = X_train.reshape(len(X_train), np.prod(X_train.shape[1:]))\n",
        "X_test = X_test.reshape(len(X_test), np.prod(X_test.shape[1:]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aP3pL4odL6Qv"
      },
      "source": [
        "#Transformar dados para tipo float\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rsnj-MmPMP8F"
      },
      "source": [
        "#Normalizar dados, 255 é o valor máximo de um pixel\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SExglyVvUPFS",
        "outputId": "3325d0b1-51a6-41f9-ab52-0f3815d31994"
      },
      "source": [
        "X_train[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.2       , 0.62352943, 0.99215686,\n",
              "       0.62352943, 0.19607843, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.1882353 ,\n",
              "       0.93333334, 0.9882353 , 0.9882353 , 0.9882353 , 0.92941177,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.21176471, 0.8901961 , 0.99215686, 0.9882353 ,\n",
              "       0.9372549 , 0.9137255 , 0.9882353 , 0.22352941, 0.02352941,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.03921569, 0.23529412, 0.8784314 ,\n",
              "       0.9882353 , 0.99215686, 0.9882353 , 0.7921569 , 0.32941177,\n",
              "       0.9882353 , 0.99215686, 0.47843137, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.6392157 , 0.9882353 , 0.9882353 , 0.9882353 , 0.99215686,\n",
              "       0.9882353 , 0.9882353 , 0.3764706 , 0.7411765 , 0.99215686,\n",
              "       0.654902  , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.2       , 0.93333334, 0.99215686,\n",
              "       0.99215686, 0.74509805, 0.44705883, 0.99215686, 0.89411765,\n",
              "       0.18431373, 0.30980393, 1.        , 0.65882355, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.1882353 ,\n",
              "       0.93333334, 0.9882353 , 0.9882353 , 0.7019608 , 0.04705882,\n",
              "       0.29411766, 0.4745098 , 0.08235294, 0.        , 0.        ,\n",
              "       0.99215686, 0.9529412 , 0.19607843, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.14901961, 0.64705884, 0.99215686, 0.9137255 ,\n",
              "       0.8156863 , 0.32941177, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.99215686, 0.9882353 ,\n",
              "       0.64705884, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.02745098, 0.69803923,\n",
              "       0.9882353 , 0.9411765 , 0.2784314 , 0.07450981, 0.10980392,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.99215686, 0.9882353 , 0.7647059 , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.22352941, 0.9882353 , 0.9882353 , 0.24705882,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.99215686,\n",
              "       0.9882353 , 0.7647059 , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.7764706 ,\n",
              "       0.99215686, 0.74509805, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 1.        , 0.99215686, 0.76862746,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.29803923, 0.9647059 , 0.9882353 , 0.4392157 ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.99215686, 0.9882353 , 0.5803922 , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.33333334,\n",
              "       0.9882353 , 0.9019608 , 0.09803922, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.02745098, 0.5294118 , 0.99215686, 0.7294118 ,\n",
              "       0.04705882, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.33333334, 0.9882353 , 0.8745098 ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.02745098, 0.5137255 ,\n",
              "       0.9882353 , 0.88235295, 0.2784314 , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.33333334, 0.9882353 , 0.5686275 , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.1882353 , 0.64705884, 0.9882353 , 0.6784314 , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.3372549 , 0.99215686,\n",
              "       0.88235295, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.44705883, 0.93333334, 0.99215686,\n",
              "       0.63529414, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.33333334, 0.9882353 , 0.9764706 , 0.57254905,\n",
              "       0.1882353 , 0.11372549, 0.33333334, 0.69803923, 0.88235295,\n",
              "       0.99215686, 0.8745098 , 0.654902  , 0.21960784, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.33333334,\n",
              "       0.9882353 , 0.9882353 , 0.9882353 , 0.8980392 , 0.84313726,\n",
              "       0.9882353 , 0.9882353 , 0.9882353 , 0.76862746, 0.50980395,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.10980392, 0.78039217, 0.9882353 ,\n",
              "       0.9882353 , 0.99215686, 0.9882353 , 0.9882353 , 0.9137255 ,\n",
              "       0.5686275 , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.09803922, 0.5019608 , 0.9882353 , 0.99215686,\n",
              "       0.9882353 , 0.5529412 , 0.14509805, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OH16vv4CNJjl"
      },
      "source": [
        "#Transformar classe para o formato Dummy\n",
        "y_train = np_utils.to_categorical(y_train, 10)\n",
        "y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZIBvhVmNsBl"
      },
      "source": [
        "#Estrutura de rede neural 784 - 64 - 64 - 64 - 10\n",
        "#Dropout é utilizado para zerar uma porcentagem dos neurônios e evitar overfiting\n",
        "model = Sequential()\n",
        "model.add(Dense(units=64, activation='relu', input_dim = 784 ))\n",
        "model.add(Dropout(.2))\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "model.add(Dropout(.2))\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "model.add(Dropout(.2))\n",
        "#Camada de saída - utilizar softmax para obter porcentagem da probabilidade do resultado correto\n",
        "model.add(Dense(units=10, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDnB61TWPLkG",
        "outputId": "d15325d1-1fb5-4142-9db2-2ef10e123624"
      },
      "source": [
        "#Visualizar estrutura da Rede Neural\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_25 (Dense)             (None, 64)                50240     \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 59,210\n",
            "Trainable params: 59,210\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VKEhnMwRS59",
        "outputId": "ecb1cddf-dcf4-4777-8529-b79e539dd389"
      },
      "source": [
        "#Configuração dos parâmetros da rede neural e treinamento (utilizando base de dados de validação)\n",
        "model.compile(optimizer ='adam', loss = \"categorical_crossentropy\", metrics = ['accuracy'])\n",
        "hist = model.fit(X_train, y_train, epochs = 30, validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4477 - accuracy: 0.8638 - val_loss: 0.1595 - val_accuracy: 0.9526\n",
            "Epoch 2/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2315 - accuracy: 0.9325 - val_loss: 0.1447 - val_accuracy: 0.9554\n",
            "Epoch 3/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1913 - accuracy: 0.9450 - val_loss: 0.1170 - val_accuracy: 0.9657\n",
            "Epoch 4/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1668 - accuracy: 0.9505 - val_loss: 0.1104 - val_accuracy: 0.9667\n",
            "Epoch 5/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1559 - accuracy: 0.9551 - val_loss: 0.0996 - val_accuracy: 0.9712\n",
            "Epoch 6/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1438 - accuracy: 0.9562 - val_loss: 0.1016 - val_accuracy: 0.9703\n",
            "Epoch 7/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1334 - accuracy: 0.9600 - val_loss: 0.1128 - val_accuracy: 0.9677\n",
            "Epoch 8/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1303 - accuracy: 0.9611 - val_loss: 0.0966 - val_accuracy: 0.9726\n",
            "Epoch 9/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1227 - accuracy: 0.9636 - val_loss: 0.1027 - val_accuracy: 0.9708\n",
            "Epoch 10/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1159 - accuracy: 0.9654 - val_loss: 0.0926 - val_accuracy: 0.9736\n",
            "Epoch 11/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1128 - accuracy: 0.9660 - val_loss: 0.1015 - val_accuracy: 0.9727\n",
            "Epoch 12/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1108 - accuracy: 0.9668 - val_loss: 0.0973 - val_accuracy: 0.9716\n",
            "Epoch 13/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1064 - accuracy: 0.9682 - val_loss: 0.1035 - val_accuracy: 0.9711\n",
            "Epoch 14/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1017 - accuracy: 0.9694 - val_loss: 0.1060 - val_accuracy: 0.9717\n",
            "Epoch 15/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0997 - accuracy: 0.9702 - val_loss: 0.0968 - val_accuracy: 0.9725\n",
            "Epoch 16/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0990 - accuracy: 0.9706 - val_loss: 0.0976 - val_accuracy: 0.9714\n",
            "Epoch 17/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0965 - accuracy: 0.9711 - val_loss: 0.0985 - val_accuracy: 0.9736\n",
            "Epoch 18/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0933 - accuracy: 0.9722 - val_loss: 0.0967 - val_accuracy: 0.9738\n",
            "Epoch 19/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0919 - accuracy: 0.9716 - val_loss: 0.0983 - val_accuracy: 0.9727\n",
            "Epoch 20/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0900 - accuracy: 0.9724 - val_loss: 0.0968 - val_accuracy: 0.9735\n",
            "Epoch 21/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0912 - accuracy: 0.9728 - val_loss: 0.0996 - val_accuracy: 0.9750\n",
            "Epoch 22/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0851 - accuracy: 0.9737 - val_loss: 0.0979 - val_accuracy: 0.9739\n",
            "Epoch 23/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0861 - accuracy: 0.9744 - val_loss: 0.1055 - val_accuracy: 0.9737\n",
            "Epoch 24/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0833 - accuracy: 0.9751 - val_loss: 0.1007 - val_accuracy: 0.9740\n",
            "Epoch 25/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0843 - accuracy: 0.9741 - val_loss: 0.0923 - val_accuracy: 0.9752\n",
            "Epoch 26/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0818 - accuracy: 0.9756 - val_loss: 0.0924 - val_accuracy: 0.9765\n",
            "Epoch 27/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0790 - accuracy: 0.9758 - val_loss: 0.1002 - val_accuracy: 0.9740\n",
            "Epoch 28/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0803 - accuracy: 0.9752 - val_loss: 0.1006 - val_accuracy: 0.9734\n",
            "Epoch 29/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0803 - accuracy: 0.9754 - val_loss: 0.1008 - val_accuracy: 0.9742\n",
            "Epoch 30/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0767 - accuracy: 0.9769 - val_loss: 0.1039 - val_accuracy: 0.9740\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "p08exiaKdD3R",
        "outputId": "68e3c9e9-ddf7-40c3-9ea0-52f75d19dcd5"
      },
      "source": [
        "#Gráfico para visualizar erros e acurácia\n",
        "hist.history.keys()\n",
        "#Evolução do erro (azul)\n",
        "plt.plot(hist.history['val_loss'])\n",
        "#Performance da rede\n",
        "plt.plot(hist.history['val_accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fb1be9c55f8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eH4qPC1xdtBZ"
      },
      "source": [
        "#Realizar previsão\n",
        "prev = model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lrksyd-eF5A",
        "outputId": "c0adc4b7-4ca5-4fbe-8dfa-f31f5c6e308d"
      },
      "source": [
        "#Matriz de confusão (convertendo de array para matriz)\n",
        "y_test_matriz = [np.argmax(t) for t in y_test]\n",
        "y_pred_matriz = [np.argmax(t) for t in prev]\n",
        "\n",
        "#Gerar matriz\n",
        "confusao = confusion_matrix(y_test_matriz,y_pred_matriz)\n",
        "confusao"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 969,    1,    1,    1,    0,    1,    2,    2,    2,    1],\n",
              "       [   0, 1123,    4,    1,    0,    1,    3,    1,    2,    0],\n",
              "       [   1,    2, 1015,    2,    5,    0,    1,    3,    3,    0],\n",
              "       [   0,    0,    4,  987,    1,    8,    0,    3,    5,    2],\n",
              "       [   0,    0,    6,    0,  960,    0,    0,    2,    2,   12],\n",
              "       [   2,    0,    0,    8,    1,  871,    4,    0,    4,    2],\n",
              "       [   5,    3,    1,    1,    8,    6,  931,    0,    3,    0],\n",
              "       [   2,    6,   11,    7,    2,    0,    0,  991,    0,    9],\n",
              "       [   7,    3,   12,    8,    4,    6,    3,    2,  924,    5],\n",
              "       [   1,    5,    1,    6,   14,    6,    1,    3,    3,  969]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoSZuOmAexww",
        "outputId": "8e78d953-c844-4ee4-d17f-613541a43696"
      },
      "source": [
        "#Realizar previsão de um novo registro\n",
        "y_train[20]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQ67Zj48fItx",
        "outputId": "596a84f7-c8c5-4590-cabc-ed2f26040d43"
      },
      "source": [
        "#Criar novo df\n",
        "df_novo = X_train[20]\n",
        "#Transformar de matriz para vetor\n",
        "df_novo = np.expand_dims(df_novo, axis = 0)\n",
        "#Realizar previsão\n",
        "previsao = model.predict(df_novo)\n",
        "#Avaliar modelo\n",
        "previsao = [np.argmax(previsao) for t in previsao]\n",
        "previsao"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRGADaiHZjoM"
      },
      "source": [
        "# **Deep Learning ||**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZ7tnRsgbC6w"
      },
      "source": [
        "#Instalar biblioteca\n",
        "pip install tensorflow -q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3u03IBxaKTg"
      },
      "source": [
        "#Instalar bibliotecas\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import make_column_transformer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "id": "gQch1B5EbLOi",
        "outputId": "345ee80a-60e5-46cf-cad5-922ee0c7465b"
      },
      "source": [
        "#Definir dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/Data Science com Python Udemy/34.Prática em Python/dados/Credit2.csv', sep=';')\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>checking_status</th>\n",
              "      <th>credit_history</th>\n",
              "      <th>duration</th>\n",
              "      <th>credit_amount</th>\n",
              "      <th>installment_commitment</th>\n",
              "      <th>residence_since</th>\n",
              "      <th>age</th>\n",
              "      <th>existing_credits</th>\n",
              "      <th>num_dependents</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>&lt;0</td>\n",
              "      <td>critical/other existing credit</td>\n",
              "      <td>6</td>\n",
              "      <td>1169</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>67</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0&lt;=X&lt;200</td>\n",
              "      <td>existing paid</td>\n",
              "      <td>48</td>\n",
              "      <td>5951</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>bad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>no checking</td>\n",
              "      <td>critical/other existing credit</td>\n",
              "      <td>12</td>\n",
              "      <td>2096</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>49</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>&lt;0</td>\n",
              "      <td>existing paid</td>\n",
              "      <td>42</td>\n",
              "      <td>7882</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>&lt;0</td>\n",
              "      <td>delayed previously</td>\n",
              "      <td>24</td>\n",
              "      <td>4870</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>53</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>bad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>996</td>\n",
              "      <td>no checking</td>\n",
              "      <td>existing paid</td>\n",
              "      <td>12</td>\n",
              "      <td>1736</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>31</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>997</td>\n",
              "      <td>&lt;0</td>\n",
              "      <td>existing paid</td>\n",
              "      <td>30</td>\n",
              "      <td>3857</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>998</td>\n",
              "      <td>no checking</td>\n",
              "      <td>existing paid</td>\n",
              "      <td>12</td>\n",
              "      <td>804</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>999</td>\n",
              "      <td>&lt;0</td>\n",
              "      <td>existing paid</td>\n",
              "      <td>45</td>\n",
              "      <td>1845</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>bad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>1000</td>\n",
              "      <td>0&lt;=X&lt;200</td>\n",
              "      <td>critical/other existing credit</td>\n",
              "      <td>45</td>\n",
              "      <td>4576</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>27</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       ID checking_status  ... num_dependents  class\n",
              "0       1              <0  ...              1   good\n",
              "1       2        0<=X<200  ...              1    bad\n",
              "2       3     no checking  ...              2   good\n",
              "3       4              <0  ...              2   good\n",
              "4       5              <0  ...              2    bad\n",
              "..    ...             ...  ...            ...    ...\n",
              "995   996     no checking  ...              1   good\n",
              "996   997              <0  ...              1   good\n",
              "997   998     no checking  ...              1   good\n",
              "998   999              <0  ...              1    bad\n",
              "999  1000        0<=X<200  ...              1   good\n",
              "\n",
              "[1000 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PfQVkpZblGL"
      },
      "source": [
        "df = df.drop(['ID'], axis=1)\n",
        "#Transformar DataFrame em array\n",
        "X = df.iloc[:,0:9].values\n",
        "y = df['class'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x76_9NMIdC-7"
      },
      "source": [
        "#Label encoder na variável cheking_status > até 3 tipos de entradas\n",
        "LbEncoder = LabelEncoder()\n",
        "X[:,0] = LbEncoder.fit_transform(X[:,0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "id": "7qHctE0i8TCf",
        "outputId": "a647d1b2-ce72-4adb-93de-31f869d60781"
      },
      "source": [
        "X = pd.DataFrame(X)\n",
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>critical/other existing credit</td>\n",
              "      <td>6</td>\n",
              "      <td>1169</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>67</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>existing paid</td>\n",
              "      <td>48</td>\n",
              "      <td>5951</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>critical/other existing credit</td>\n",
              "      <td>12</td>\n",
              "      <td>2096</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>49</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>existing paid</td>\n",
              "      <td>42</td>\n",
              "      <td>7882</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>delayed previously</td>\n",
              "      <td>24</td>\n",
              "      <td>4870</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>53</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>3</td>\n",
              "      <td>existing paid</td>\n",
              "      <td>12</td>\n",
              "      <td>1736</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>31</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>1</td>\n",
              "      <td>existing paid</td>\n",
              "      <td>30</td>\n",
              "      <td>3857</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>3</td>\n",
              "      <td>existing paid</td>\n",
              "      <td>12</td>\n",
              "      <td>804</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>1</td>\n",
              "      <td>existing paid</td>\n",
              "      <td>45</td>\n",
              "      <td>1845</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>0</td>\n",
              "      <td>critical/other existing credit</td>\n",
              "      <td>45</td>\n",
              "      <td>4576</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>27</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     0                               1   2     3  4  5   6  7  8\n",
              "0    1  critical/other existing credit   6  1169  4  4  67  2  1\n",
              "1    0                   existing paid  48  5951  2  2  22  1  1\n",
              "2    3  critical/other existing credit  12  2096  2  3  49  1  2\n",
              "3    1                   existing paid  42  7882  2  4  45  1  2\n",
              "4    1              delayed previously  24  4870  3  4  53  2  2\n",
              "..  ..                             ...  ..   ... .. ..  .. .. ..\n",
              "995  3                   existing paid  12  1736  3  4  31  1  1\n",
              "996  1                   existing paid  30  3857  4  4  40  1  1\n",
              "997  3                   existing paid  12   804  4  4  38  1  1\n",
              "998  1                   existing paid  45  1845  4  4  23  1  1\n",
              "999  0  critical/other existing credit  45  4576  3  4  27  1  1\n",
              "\n",
              "[1000 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tk_872veNEk"
      },
      "source": [
        "#OneHotEncoder na variável credit_history >> mais de 3 tipos de entradas\n",
        "onehot = make_column_transformer((OneHotEncoder(categories='auto', sparse=False), [1]), remainder = 'passthrough')\n",
        "X = onehot.fit_transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWzX0NcvfPj6"
      },
      "source": [
        "#EXcluir uma das variáveis criada no OneHotEncoder para evitar dummy variable\n",
        "X = X[:,1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "id": "UgMe9TX89fiH",
        "outputId": "109797e3-e747-4e71-fda5-221404f0df6a"
      },
      "source": [
        "X = pd.DataFrame(X)\n",
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1169</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>67</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>5951</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>12</td>\n",
              "      <td>2096</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>49</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>42</td>\n",
              "      <td>7882</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>4870</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>53</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>12</td>\n",
              "      <td>1736</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>31</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>3857</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>12</td>\n",
              "      <td>804</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>45</td>\n",
              "      <td>1845</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>45</td>\n",
              "      <td>4576</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>27</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    0  1  2  3  4   5     6  7  8   9  10 11\n",
              "0    1  0  0  0  1   6  1169  4  4  67  2  1\n",
              "1    0  0  1  0  0  48  5951  2  2  22  1  1\n",
              "2    1  0  0  0  3  12  2096  2  3  49  1  2\n",
              "3    0  0  1  0  1  42  7882  2  4  45  1  2\n",
              "4    0  1  0  0  1  24  4870  3  4  53  2  2\n",
              "..  .. .. .. .. ..  ..   ... .. ..  .. .. ..\n",
              "995  0  0  1  0  3  12  1736  3  4  31  1  1\n",
              "996  0  0  1  0  1  30  3857  4  4  40  1  1\n",
              "997  0  0  1  0  3  12   804  4  4  38  1  1\n",
              "998  0  0  1  0  1  45  1845  4  4  23  1  1\n",
              "999  1  0  0  0  0  45  4576  3  4  27  1  1\n",
              "\n",
              "[1000 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XF_jVZV1gZti"
      },
      "source": [
        "#Label Encoder com a Classe\n",
        "LbEncoder = LabelEncoder()\n",
        "y = LbEncoder.fit_transform(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJHFC_lbgxla",
        "outputId": "81e40885-0b3c-45d5-b705-c857e4ccd601"
      },
      "source": [
        "#Dividir dados entre treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y , test_size = 0.2, random_state = 0)\n",
        "print(len(X_train),len(X_test),len(y_train),len(y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "800 200 800 200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZ8q1B3Mh7Xa"
      },
      "source": [
        "#Padronizar os dados (deixar em escala entre 0 e 1) utilizando StandardScaler\n",
        "sc = StandardScaler()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdeoWPsmhIOx"
      },
      "source": [
        "#Padronizar os dados (deixar em escala entre 0 e 1) utilizando StandardScaler\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJUoAIs5jEcK",
        "outputId": "4df47c7b-fe1c-43f4-ad61-994ec90b8455"
      },
      "source": [
        "#Criar rede neural\n",
        "classifier = Sequential()\n",
        "classifier.add(Dense(units=6, kernel_initializer='uniform', activation='relu', input_dim=12))\n",
        "classifier.add(Dense(units=6, kernel_initializer='uniform', activation='relu'))\n",
        "classifier.add(Dense(units=1, kernel_initializer='uniform', activation='relu'))\n",
        "\n",
        "#Definir parâmetros\n",
        "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "#Treinar rede neural\n",
        "classifier.fit(X_train, y_train, batch_size = 10, epochs = 1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "80/80 [==============================] - 0s 889us/step - loss: 3.4023 - accuracy: 0.3025\n",
            "Epoch 2/1000\n",
            "80/80 [==============================] - 0s 885us/step - loss: 2.2585 - accuracy: 0.3025\n",
            "Epoch 3/1000\n",
            "80/80 [==============================] - 0s 829us/step - loss: 1.3988 - accuracy: 0.3025\n",
            "Epoch 4/1000\n",
            "80/80 [==============================] - 0s 872us/step - loss: 0.9034 - accuracy: 0.3525\n",
            "Epoch 5/1000\n",
            "80/80 [==============================] - 0s 964us/step - loss: 0.6346 - accuracy: 0.6275\n",
            "Epoch 6/1000\n",
            "80/80 [==============================] - 0s 894us/step - loss: 0.5350 - accuracy: 0.7212\n",
            "Epoch 7/1000\n",
            "80/80 [==============================] - 0s 849us/step - loss: 0.5170 - accuracy: 0.7387\n",
            "Epoch 8/1000\n",
            "80/80 [==============================] - 0s 897us/step - loss: 0.5255 - accuracy: 0.7425\n",
            "Epoch 9/1000\n",
            "80/80 [==============================] - 0s 849us/step - loss: 0.5222 - accuracy: 0.7387\n",
            "Epoch 10/1000\n",
            "80/80 [==============================] - 0s 901us/step - loss: 0.5198 - accuracy: 0.7437\n",
            "Epoch 11/1000\n",
            "80/80 [==============================] - 0s 909us/step - loss: 0.5232 - accuracy: 0.7387\n",
            "Epoch 12/1000\n",
            "80/80 [==============================] - 0s 872us/step - loss: 0.5063 - accuracy: 0.7412\n",
            "Epoch 13/1000\n",
            "80/80 [==============================] - 0s 903us/step - loss: 0.5024 - accuracy: 0.7487\n",
            "Epoch 14/1000\n",
            "80/80 [==============================] - 0s 843us/step - loss: 0.5163 - accuracy: 0.7513\n",
            "Epoch 15/1000\n",
            "80/80 [==============================] - 0s 879us/step - loss: 0.5009 - accuracy: 0.7487\n",
            "Epoch 16/1000\n",
            "80/80 [==============================] - 0s 836us/step - loss: 0.5142 - accuracy: 0.7487\n",
            "Epoch 17/1000\n",
            "80/80 [==============================] - 0s 855us/step - loss: 0.5030 - accuracy: 0.7387\n",
            "Epoch 18/1000\n",
            "80/80 [==============================] - 0s 955us/step - loss: 0.5116 - accuracy: 0.7387\n",
            "Epoch 19/1000\n",
            "80/80 [==============================] - 0s 855us/step - loss: 0.4986 - accuracy: 0.7475\n",
            "Epoch 20/1000\n",
            "80/80 [==============================] - 0s 843us/step - loss: 0.4959 - accuracy: 0.7487\n",
            "Epoch 21/1000\n",
            "80/80 [==============================] - 0s 888us/step - loss: 0.4948 - accuracy: 0.7563\n",
            "Epoch 22/1000\n",
            "80/80 [==============================] - 0s 927us/step - loss: 0.4968 - accuracy: 0.7638\n",
            "Epoch 23/1000\n",
            "80/80 [==============================] - 0s 838us/step - loss: 0.5090 - accuracy: 0.7500\n",
            "Epoch 24/1000\n",
            "80/80 [==============================] - 0s 917us/step - loss: 0.4962 - accuracy: 0.7500\n",
            "Epoch 25/1000\n",
            "80/80 [==============================] - 0s 861us/step - loss: 0.4998 - accuracy: 0.7538\n",
            "Epoch 26/1000\n",
            "80/80 [==============================] - 0s 867us/step - loss: 0.4923 - accuracy: 0.7613\n",
            "Epoch 27/1000\n",
            "80/80 [==============================] - 0s 859us/step - loss: 0.4948 - accuracy: 0.7462\n",
            "Epoch 28/1000\n",
            "80/80 [==============================] - 0s 885us/step - loss: 0.4918 - accuracy: 0.7563\n",
            "Epoch 29/1000\n",
            "80/80 [==============================] - 0s 847us/step - loss: 0.4919 - accuracy: 0.7563\n",
            "Epoch 30/1000\n",
            "80/80 [==============================] - 0s 857us/step - loss: 0.4908 - accuracy: 0.7563\n",
            "Epoch 31/1000\n",
            "80/80 [==============================] - 0s 868us/step - loss: 0.5069 - accuracy: 0.7625\n",
            "Epoch 32/1000\n",
            "80/80 [==============================] - 0s 873us/step - loss: 0.4939 - accuracy: 0.7525\n",
            "Epoch 33/1000\n",
            "80/80 [==============================] - 0s 866us/step - loss: 0.5095 - accuracy: 0.7550\n",
            "Epoch 34/1000\n",
            "80/80 [==============================] - 0s 892us/step - loss: 0.4915 - accuracy: 0.7538\n",
            "Epoch 35/1000\n",
            "80/80 [==============================] - 0s 907us/step - loss: 0.4937 - accuracy: 0.7550\n",
            "Epoch 36/1000\n",
            "80/80 [==============================] - 0s 850us/step - loss: 0.4935 - accuracy: 0.7513\n",
            "Epoch 37/1000\n",
            "80/80 [==============================] - 0s 846us/step - loss: 0.4911 - accuracy: 0.7487\n",
            "Epoch 38/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4922 - accuracy: 0.7613\n",
            "Epoch 39/1000\n",
            "80/80 [==============================] - 0s 919us/step - loss: 0.4894 - accuracy: 0.7475\n",
            "Epoch 40/1000\n",
            "80/80 [==============================] - 0s 834us/step - loss: 0.4887 - accuracy: 0.7487\n",
            "Epoch 41/1000\n",
            "80/80 [==============================] - 0s 905us/step - loss: 0.4884 - accuracy: 0.7550\n",
            "Epoch 42/1000\n",
            "80/80 [==============================] - 0s 860us/step - loss: 0.4913 - accuracy: 0.7575\n",
            "Epoch 43/1000\n",
            "80/80 [==============================] - 0s 850us/step - loss: 0.4875 - accuracy: 0.7588\n",
            "Epoch 44/1000\n",
            "80/80 [==============================] - 0s 857us/step - loss: 0.4858 - accuracy: 0.7563\n",
            "Epoch 45/1000\n",
            "80/80 [==============================] - 0s 893us/step - loss: 0.4870 - accuracy: 0.7563\n",
            "Epoch 46/1000\n",
            "80/80 [==============================] - 0s 879us/step - loss: 0.4872 - accuracy: 0.7588\n",
            "Epoch 47/1000\n",
            "80/80 [==============================] - 0s 848us/step - loss: 0.4860 - accuracy: 0.7588\n",
            "Epoch 48/1000\n",
            "80/80 [==============================] - 0s 917us/step - loss: 0.4866 - accuracy: 0.7563\n",
            "Epoch 49/1000\n",
            "80/80 [==============================] - 0s 856us/step - loss: 0.4878 - accuracy: 0.7525\n",
            "Epoch 50/1000\n",
            "80/80 [==============================] - 0s 943us/step - loss: 0.4889 - accuracy: 0.7613\n",
            "Epoch 51/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4850 - accuracy: 0.7625\n",
            "Epoch 52/1000\n",
            "80/80 [==============================] - 0s 874us/step - loss: 0.5024 - accuracy: 0.7487\n",
            "Epoch 53/1000\n",
            "80/80 [==============================] - 0s 964us/step - loss: 0.5194 - accuracy: 0.7563\n",
            "Epoch 54/1000\n",
            "80/80 [==============================] - 0s 863us/step - loss: 0.4918 - accuracy: 0.7588\n",
            "Epoch 55/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4845 - accuracy: 0.7613\n",
            "Epoch 56/1000\n",
            "80/80 [==============================] - 0s 961us/step - loss: 0.4837 - accuracy: 0.7513\n",
            "Epoch 57/1000\n",
            "80/80 [==============================] - 0s 975us/step - loss: 0.4840 - accuracy: 0.7525\n",
            "Epoch 58/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4828 - accuracy: 0.7588\n",
            "Epoch 59/1000\n",
            "80/80 [==============================] - 0s 992us/step - loss: 0.4815 - accuracy: 0.7550\n",
            "Epoch 60/1000\n",
            "80/80 [==============================] - 0s 995us/step - loss: 0.4812 - accuracy: 0.7588\n",
            "Epoch 61/1000\n",
            "80/80 [==============================] - 0s 993us/step - loss: 0.4808 - accuracy: 0.7538\n",
            "Epoch 62/1000\n",
            "80/80 [==============================] - 0s 951us/step - loss: 0.4805 - accuracy: 0.7525\n",
            "Epoch 63/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4808 - accuracy: 0.7538\n",
            "Epoch 64/1000\n",
            "80/80 [==============================] - 0s 884us/step - loss: 0.4807 - accuracy: 0.7538\n",
            "Epoch 65/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4805 - accuracy: 0.7550\n",
            "Epoch 66/1000\n",
            "80/80 [==============================] - 0s 898us/step - loss: 0.4793 - accuracy: 0.7500\n",
            "Epoch 67/1000\n",
            "80/80 [==============================] - 0s 885us/step - loss: 0.4810 - accuracy: 0.7575\n",
            "Epoch 68/1000\n",
            "80/80 [==============================] - 0s 873us/step - loss: 0.4847 - accuracy: 0.7625\n",
            "Epoch 69/1000\n",
            "80/80 [==============================] - 0s 833us/step - loss: 0.4832 - accuracy: 0.7588\n",
            "Epoch 70/1000\n",
            "80/80 [==============================] - 0s 917us/step - loss: 0.4787 - accuracy: 0.7563\n",
            "Epoch 71/1000\n",
            "80/80 [==============================] - 0s 861us/step - loss: 0.4797 - accuracy: 0.7600\n",
            "Epoch 72/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4816 - accuracy: 0.7563\n",
            "Epoch 73/1000\n",
            "80/80 [==============================] - 0s 896us/step - loss: 0.4777 - accuracy: 0.7550\n",
            "Epoch 74/1000\n",
            "80/80 [==============================] - 0s 919us/step - loss: 0.4798 - accuracy: 0.7575\n",
            "Epoch 75/1000\n",
            "80/80 [==============================] - 0s 859us/step - loss: 0.4953 - accuracy: 0.7600\n",
            "Epoch 76/1000\n",
            "80/80 [==============================] - 0s 947us/step - loss: 0.4790 - accuracy: 0.7538\n",
            "Epoch 77/1000\n",
            "80/80 [==============================] - 0s 939us/step - loss: 0.4778 - accuracy: 0.7538\n",
            "Epoch 78/1000\n",
            "80/80 [==============================] - 0s 888us/step - loss: 0.4792 - accuracy: 0.7575\n",
            "Epoch 79/1000\n",
            "80/80 [==============================] - 0s 861us/step - loss: 0.4921 - accuracy: 0.7563\n",
            "Epoch 80/1000\n",
            "80/80 [==============================] - 0s 899us/step - loss: 0.4779 - accuracy: 0.7462\n",
            "Epoch 81/1000\n",
            "80/80 [==============================] - 0s 907us/step - loss: 0.4863 - accuracy: 0.7588\n",
            "Epoch 82/1000\n",
            "80/80 [==============================] - 0s 903us/step - loss: 0.5131 - accuracy: 0.7563\n",
            "Epoch 83/1000\n",
            "80/80 [==============================] - 0s 888us/step - loss: 0.4902 - accuracy: 0.7550\n",
            "Epoch 84/1000\n",
            "80/80 [==============================] - 0s 848us/step - loss: 0.4808 - accuracy: 0.7525\n",
            "Epoch 85/1000\n",
            "80/80 [==============================] - 0s 886us/step - loss: 0.4774 - accuracy: 0.7575\n",
            "Epoch 86/1000\n",
            "80/80 [==============================] - 0s 905us/step - loss: 0.4769 - accuracy: 0.7575\n",
            "Epoch 87/1000\n",
            "80/80 [==============================] - 0s 883us/step - loss: 0.4756 - accuracy: 0.7575\n",
            "Epoch 88/1000\n",
            "80/80 [==============================] - 0s 887us/step - loss: 0.4751 - accuracy: 0.7613\n",
            "Epoch 89/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4748 - accuracy: 0.7600\n",
            "Epoch 90/1000\n",
            "80/80 [==============================] - 0s 985us/step - loss: 0.4742 - accuracy: 0.7613\n",
            "Epoch 91/1000\n",
            "80/80 [==============================] - 0s 969us/step - loss: 0.4732 - accuracy: 0.7563\n",
            "Epoch 92/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4725 - accuracy: 0.7625\n",
            "Epoch 93/1000\n",
            "80/80 [==============================] - 0s 910us/step - loss: 0.5063 - accuracy: 0.7412\n",
            "Epoch 94/1000\n",
            "80/80 [==============================] - 0s 921us/step - loss: 0.5733 - accuracy: 0.6725\n",
            "Epoch 95/1000\n",
            "80/80 [==============================] - 0s 967us/step - loss: 0.5497 - accuracy: 0.7050\n",
            "Epoch 96/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.5286 - accuracy: 0.7113\n",
            "Epoch 97/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.5145 - accuracy: 0.7312\n",
            "Epoch 98/1000\n",
            "80/80 [==============================] - 0s 897us/step - loss: 0.5041 - accuracy: 0.7362\n",
            "Epoch 99/1000\n",
            "80/80 [==============================] - 0s 909us/step - loss: 0.4969 - accuracy: 0.7412\n",
            "Epoch 100/1000\n",
            "80/80 [==============================] - 0s 875us/step - loss: 0.4926 - accuracy: 0.7462\n",
            "Epoch 101/1000\n",
            "80/80 [==============================] - 0s 900us/step - loss: 0.4883 - accuracy: 0.7475\n",
            "Epoch 102/1000\n",
            "80/80 [==============================] - 0s 920us/step - loss: 0.4859 - accuracy: 0.7525\n",
            "Epoch 103/1000\n",
            "80/80 [==============================] - 0s 886us/step - loss: 0.4841 - accuracy: 0.7538\n",
            "Epoch 104/1000\n",
            "80/80 [==============================] - 0s 948us/step - loss: 0.4829 - accuracy: 0.7550\n",
            "Epoch 105/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4817 - accuracy: 0.7513\n",
            "Epoch 106/1000\n",
            "80/80 [==============================] - 0s 984us/step - loss: 0.4807 - accuracy: 0.7500\n",
            "Epoch 107/1000\n",
            "80/80 [==============================] - 0s 986us/step - loss: 0.4801 - accuracy: 0.7500\n",
            "Epoch 108/1000\n",
            "80/80 [==============================] - 0s 978us/step - loss: 0.4794 - accuracy: 0.7563\n",
            "Epoch 109/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4791 - accuracy: 0.7525\n",
            "Epoch 110/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4791 - accuracy: 0.7588\n",
            "Epoch 111/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4784 - accuracy: 0.7538\n",
            "Epoch 112/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4777 - accuracy: 0.7575\n",
            "Epoch 113/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4924 - accuracy: 0.7563\n",
            "Epoch 114/1000\n",
            "80/80 [==============================] - 0s 888us/step - loss: 0.4773 - accuracy: 0.7600\n",
            "Epoch 115/1000\n",
            "80/80 [==============================] - 0s 910us/step - loss: 0.4775 - accuracy: 0.7550\n",
            "Epoch 116/1000\n",
            "80/80 [==============================] - 0s 902us/step - loss: 0.4765 - accuracy: 0.7588\n",
            "Epoch 117/1000\n",
            "80/80 [==============================] - 0s 927us/step - loss: 0.4774 - accuracy: 0.7550\n",
            "Epoch 118/1000\n",
            "80/80 [==============================] - 0s 907us/step - loss: 0.4764 - accuracy: 0.7588\n",
            "Epoch 119/1000\n",
            "80/80 [==============================] - 0s 935us/step - loss: 0.4758 - accuracy: 0.7550\n",
            "Epoch 120/1000\n",
            "80/80 [==============================] - 0s 930us/step - loss: 0.4803 - accuracy: 0.7613\n",
            "Epoch 121/1000\n",
            "80/80 [==============================] - 0s 967us/step - loss: 0.4763 - accuracy: 0.7563\n",
            "Epoch 122/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4757 - accuracy: 0.7538\n",
            "Epoch 123/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4749 - accuracy: 0.7550\n",
            "Epoch 124/1000\n",
            "80/80 [==============================] - 0s 984us/step - loss: 0.4748 - accuracy: 0.7563\n",
            "Epoch 125/1000\n",
            "80/80 [==============================] - 0s 967us/step - loss: 0.4744 - accuracy: 0.7613\n",
            "Epoch 126/1000\n",
            "80/80 [==============================] - 0s 962us/step - loss: 0.4768 - accuracy: 0.7613\n",
            "Epoch 127/1000\n",
            "80/80 [==============================] - 0s 860us/step - loss: 0.4744 - accuracy: 0.7613\n",
            "Epoch 128/1000\n",
            "80/80 [==============================] - 0s 920us/step - loss: 0.4739 - accuracy: 0.7575\n",
            "Epoch 129/1000\n",
            "80/80 [==============================] - 0s 960us/step - loss: 0.4734 - accuracy: 0.7613\n",
            "Epoch 130/1000\n",
            "80/80 [==============================] - 0s 880us/step - loss: 0.4732 - accuracy: 0.7550\n",
            "Epoch 131/1000\n",
            "80/80 [==============================] - 0s 863us/step - loss: 0.4737 - accuracy: 0.7600\n",
            "Epoch 132/1000\n",
            "80/80 [==============================] - 0s 915us/step - loss: 0.4735 - accuracy: 0.7600\n",
            "Epoch 133/1000\n",
            "80/80 [==============================] - 0s 901us/step - loss: 0.4732 - accuracy: 0.7588\n",
            "Epoch 134/1000\n",
            "80/80 [==============================] - 0s 900us/step - loss: 0.4724 - accuracy: 0.7625\n",
            "Epoch 135/1000\n",
            "80/80 [==============================] - 0s 868us/step - loss: 0.4733 - accuracy: 0.7625\n",
            "Epoch 136/1000\n",
            "80/80 [==============================] - 0s 933us/step - loss: 0.4732 - accuracy: 0.7650\n",
            "Epoch 137/1000\n",
            "80/80 [==============================] - 0s 853us/step - loss: 0.4725 - accuracy: 0.7625\n",
            "Epoch 138/1000\n",
            "80/80 [==============================] - 0s 894us/step - loss: 0.4717 - accuracy: 0.7663\n",
            "Epoch 139/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4719 - accuracy: 0.7600\n",
            "Epoch 140/1000\n",
            "80/80 [==============================] - 0s 917us/step - loss: 0.4717 - accuracy: 0.7650\n",
            "Epoch 141/1000\n",
            "80/80 [==============================] - 0s 868us/step - loss: 0.4704 - accuracy: 0.7663\n",
            "Epoch 142/1000\n",
            "80/80 [==============================] - 0s 970us/step - loss: 0.4720 - accuracy: 0.7625\n",
            "Epoch 143/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4709 - accuracy: 0.7700\n",
            "Epoch 144/1000\n",
            "80/80 [==============================] - 0s 956us/step - loss: 0.4714 - accuracy: 0.7638\n",
            "Epoch 145/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4701 - accuracy: 0.7663\n",
            "Epoch 146/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4713 - accuracy: 0.7613\n",
            "Epoch 147/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4698 - accuracy: 0.7675\n",
            "Epoch 148/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4700 - accuracy: 0.7650\n",
            "Epoch 149/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4702 - accuracy: 0.7638\n",
            "Epoch 150/1000\n",
            "80/80 [==============================] - 0s 910us/step - loss: 0.4687 - accuracy: 0.7700\n",
            "Epoch 151/1000\n",
            "80/80 [==============================] - 0s 979us/step - loss: 0.4704 - accuracy: 0.7650\n",
            "Epoch 152/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4691 - accuracy: 0.7675\n",
            "Epoch 153/1000\n",
            "80/80 [==============================] - 0s 889us/step - loss: 0.4699 - accuracy: 0.7663\n",
            "Epoch 154/1000\n",
            "80/80 [==============================] - 0s 887us/step - loss: 0.4685 - accuracy: 0.7675\n",
            "Epoch 155/1000\n",
            "80/80 [==============================] - 0s 915us/step - loss: 0.4688 - accuracy: 0.7688\n",
            "Epoch 156/1000\n",
            "80/80 [==============================] - 0s 964us/step - loss: 0.4671 - accuracy: 0.7675\n",
            "Epoch 157/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4687 - accuracy: 0.7688\n",
            "Epoch 158/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4671 - accuracy: 0.7700\n",
            "Epoch 159/1000\n",
            "80/80 [==============================] - 0s 984us/step - loss: 0.4835 - accuracy: 0.7675\n",
            "Epoch 160/1000\n",
            "80/80 [==============================] - 0s 975us/step - loss: 0.4691 - accuracy: 0.7638\n",
            "Epoch 161/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4743 - accuracy: 0.7725\n",
            "Epoch 162/1000\n",
            "80/80 [==============================] - 0s 891us/step - loss: 0.4700 - accuracy: 0.7638\n",
            "Epoch 163/1000\n",
            "80/80 [==============================] - 0s 980us/step - loss: 0.4659 - accuracy: 0.7688\n",
            "Epoch 164/1000\n",
            "80/80 [==============================] - 0s 936us/step - loss: 0.4652 - accuracy: 0.7663\n",
            "Epoch 165/1000\n",
            "80/80 [==============================] - 0s 987us/step - loss: 0.4661 - accuracy: 0.7700\n",
            "Epoch 166/1000\n",
            "80/80 [==============================] - 0s 931us/step - loss: 0.4659 - accuracy: 0.7675\n",
            "Epoch 167/1000\n",
            "80/80 [==============================] - 0s 960us/step - loss: 0.4646 - accuracy: 0.7688\n",
            "Epoch 168/1000\n",
            "80/80 [==============================] - 0s 952us/step - loss: 0.4666 - accuracy: 0.7738\n",
            "Epoch 169/1000\n",
            "80/80 [==============================] - 0s 961us/step - loss: 0.4634 - accuracy: 0.7675\n",
            "Epoch 170/1000\n",
            "80/80 [==============================] - 0s 908us/step - loss: 0.4650 - accuracy: 0.7638\n",
            "Epoch 171/1000\n",
            "80/80 [==============================] - 0s 930us/step - loss: 0.4644 - accuracy: 0.7663\n",
            "Epoch 172/1000\n",
            "80/80 [==============================] - 0s 920us/step - loss: 0.4664 - accuracy: 0.7713\n",
            "Epoch 173/1000\n",
            "80/80 [==============================] - 0s 911us/step - loss: 0.4659 - accuracy: 0.7625\n",
            "Epoch 174/1000\n",
            "80/80 [==============================] - 0s 909us/step - loss: 0.4638 - accuracy: 0.7700\n",
            "Epoch 175/1000\n",
            "80/80 [==============================] - 0s 967us/step - loss: 0.4638 - accuracy: 0.7675\n",
            "Epoch 176/1000\n",
            "80/80 [==============================] - 0s 935us/step - loss: 0.4639 - accuracy: 0.7638\n",
            "Epoch 177/1000\n",
            "80/80 [==============================] - 0s 897us/step - loss: 0.4653 - accuracy: 0.7625\n",
            "Epoch 178/1000\n",
            "80/80 [==============================] - 0s 896us/step - loss: 0.4640 - accuracy: 0.7725\n",
            "Epoch 179/1000\n",
            "80/80 [==============================] - 0s 908us/step - loss: 0.4658 - accuracy: 0.7675\n",
            "Epoch 180/1000\n",
            "80/80 [==============================] - 0s 917us/step - loss: 0.4674 - accuracy: 0.7738\n",
            "Epoch 181/1000\n",
            "80/80 [==============================] - 0s 884us/step - loss: 0.4651 - accuracy: 0.7625\n",
            "Epoch 182/1000\n",
            "80/80 [==============================] - 0s 940us/step - loss: 0.4635 - accuracy: 0.7700\n",
            "Epoch 183/1000\n",
            "80/80 [==============================] - 0s 914us/step - loss: 0.4645 - accuracy: 0.7663\n",
            "Epoch 184/1000\n",
            "80/80 [==============================] - 0s 944us/step - loss: 0.4627 - accuracy: 0.7663\n",
            "Epoch 185/1000\n",
            "80/80 [==============================] - 0s 899us/step - loss: 0.4640 - accuracy: 0.7663\n",
            "Epoch 186/1000\n",
            "80/80 [==============================] - 0s 925us/step - loss: 0.4626 - accuracy: 0.7700\n",
            "Epoch 187/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4621 - accuracy: 0.7638\n",
            "Epoch 188/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4632 - accuracy: 0.7625\n",
            "Epoch 189/1000\n",
            "80/80 [==============================] - 0s 999us/step - loss: 0.4621 - accuracy: 0.7675\n",
            "Epoch 190/1000\n",
            "80/80 [==============================] - 0s 940us/step - loss: 0.4624 - accuracy: 0.7688\n",
            "Epoch 191/1000\n",
            "80/80 [==============================] - 0s 928us/step - loss: 0.4636 - accuracy: 0.7663\n",
            "Epoch 192/1000\n",
            "80/80 [==============================] - 0s 891us/step - loss: 0.4645 - accuracy: 0.7700\n",
            "Epoch 193/1000\n",
            "80/80 [==============================] - 0s 922us/step - loss: 0.4621 - accuracy: 0.7650\n",
            "Epoch 194/1000\n",
            "80/80 [==============================] - 0s 910us/step - loss: 0.4624 - accuracy: 0.7700\n",
            "Epoch 195/1000\n",
            "80/80 [==============================] - 0s 850us/step - loss: 0.4609 - accuracy: 0.7700\n",
            "Epoch 196/1000\n",
            "80/80 [==============================] - 0s 883us/step - loss: 0.4598 - accuracy: 0.7613\n",
            "Epoch 197/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4636 - accuracy: 0.7650\n",
            "Epoch 198/1000\n",
            "80/80 [==============================] - 0s 924us/step - loss: 0.4860 - accuracy: 0.7600\n",
            "Epoch 199/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4663 - accuracy: 0.7675\n",
            "Epoch 200/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4605 - accuracy: 0.7613\n",
            "Epoch 201/1000\n",
            "80/80 [==============================] - 0s 980us/step - loss: 0.4617 - accuracy: 0.7600\n",
            "Epoch 202/1000\n",
            "80/80 [==============================] - 0s 979us/step - loss: 0.4601 - accuracy: 0.7650\n",
            "Epoch 203/1000\n",
            "80/80 [==============================] - 0s 987us/step - loss: 0.4610 - accuracy: 0.7513\n",
            "Epoch 204/1000\n",
            "80/80 [==============================] - 0s 977us/step - loss: 0.4586 - accuracy: 0.7650\n",
            "Epoch 205/1000\n",
            "80/80 [==============================] - 0s 969us/step - loss: 0.4588 - accuracy: 0.7638\n",
            "Epoch 206/1000\n",
            "80/80 [==============================] - 0s 928us/step - loss: 0.4578 - accuracy: 0.7638\n",
            "Epoch 207/1000\n",
            "80/80 [==============================] - 0s 902us/step - loss: 0.4615 - accuracy: 0.7700\n",
            "Epoch 208/1000\n",
            "80/80 [==============================] - 0s 976us/step - loss: 0.4584 - accuracy: 0.7638\n",
            "Epoch 209/1000\n",
            "80/80 [==============================] - 0s 962us/step - loss: 0.4599 - accuracy: 0.7625\n",
            "Epoch 210/1000\n",
            "80/80 [==============================] - 0s 892us/step - loss: 0.4587 - accuracy: 0.7675\n",
            "Epoch 211/1000\n",
            "80/80 [==============================] - 0s 971us/step - loss: 0.4618 - accuracy: 0.7638\n",
            "Epoch 212/1000\n",
            "80/80 [==============================] - 0s 985us/step - loss: 0.4588 - accuracy: 0.7613\n",
            "Epoch 213/1000\n",
            "80/80 [==============================] - 0s 996us/step - loss: 0.4593 - accuracy: 0.7663\n",
            "Epoch 214/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4597 - accuracy: 0.7613\n",
            "Epoch 215/1000\n",
            "80/80 [==============================] - 0s 1000us/step - loss: 0.4591 - accuracy: 0.7638\n",
            "Epoch 216/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4572 - accuracy: 0.7663\n",
            "Epoch 217/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4582 - accuracy: 0.7650\n",
            "Epoch 218/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4605 - accuracy: 0.7713\n",
            "Epoch 219/1000\n",
            "80/80 [==============================] - 0s 970us/step - loss: 0.4617 - accuracy: 0.7613\n",
            "Epoch 220/1000\n",
            "80/80 [==============================] - 0s 916us/step - loss: 0.4579 - accuracy: 0.7650\n",
            "Epoch 221/1000\n",
            "80/80 [==============================] - 0s 952us/step - loss: 0.4649 - accuracy: 0.7700\n",
            "Epoch 222/1000\n",
            "80/80 [==============================] - 0s 931us/step - loss: 0.4568 - accuracy: 0.7525\n",
            "Epoch 223/1000\n",
            "80/80 [==============================] - 0s 994us/step - loss: 0.4866 - accuracy: 0.7613\n",
            "Epoch 224/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4613 - accuracy: 0.7738\n",
            "Epoch 225/1000\n",
            "80/80 [==============================] - 0s 891us/step - loss: 0.4587 - accuracy: 0.7688\n",
            "Epoch 226/1000\n",
            "80/80 [==============================] - 0s 966us/step - loss: 0.4592 - accuracy: 0.7663\n",
            "Epoch 227/1000\n",
            "80/80 [==============================] - 0s 946us/step - loss: 0.4571 - accuracy: 0.7638\n",
            "Epoch 228/1000\n",
            "80/80 [==============================] - 0s 927us/step - loss: 0.4576 - accuracy: 0.7663\n",
            "Epoch 229/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4605 - accuracy: 0.7650\n",
            "Epoch 230/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4579 - accuracy: 0.7663\n",
            "Epoch 231/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4576 - accuracy: 0.7613\n",
            "Epoch 232/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4573 - accuracy: 0.7650\n",
            "Epoch 233/1000\n",
            "80/80 [==============================] - 0s 882us/step - loss: 0.4570 - accuracy: 0.7675\n",
            "Epoch 234/1000\n",
            "80/80 [==============================] - 0s 945us/step - loss: 0.4577 - accuracy: 0.7638\n",
            "Epoch 235/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4609 - accuracy: 0.7625\n",
            "Epoch 236/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4578 - accuracy: 0.7675\n",
            "Epoch 237/1000\n",
            "80/80 [==============================] - 0s 926us/step - loss: 0.4577 - accuracy: 0.7675\n",
            "Epoch 238/1000\n",
            "80/80 [==============================] - 0s 910us/step - loss: 0.4559 - accuracy: 0.7663\n",
            "Epoch 239/1000\n",
            "80/80 [==============================] - 0s 962us/step - loss: 0.4562 - accuracy: 0.7625\n",
            "Epoch 240/1000\n",
            "80/80 [==============================] - 0s 845us/step - loss: 0.4582 - accuracy: 0.7638\n",
            "Epoch 241/1000\n",
            "80/80 [==============================] - 0s 967us/step - loss: 0.4564 - accuracy: 0.7588\n",
            "Epoch 242/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4591 - accuracy: 0.7663\n",
            "Epoch 243/1000\n",
            "80/80 [==============================] - 0s 991us/step - loss: 0.4605 - accuracy: 0.7650\n",
            "Epoch 244/1000\n",
            "80/80 [==============================] - 0s 933us/step - loss: 0.4585 - accuracy: 0.7613\n",
            "Epoch 245/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4579 - accuracy: 0.7613\n",
            "Epoch 246/1000\n",
            "80/80 [==============================] - 0s 948us/step - loss: 0.4560 - accuracy: 0.7613\n",
            "Epoch 247/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4567 - accuracy: 0.7638\n",
            "Epoch 248/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4589 - accuracy: 0.7650\n",
            "Epoch 249/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4562 - accuracy: 0.7625\n",
            "Epoch 250/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4583 - accuracy: 0.7613\n",
            "Epoch 251/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4584 - accuracy: 0.7600\n",
            "Epoch 252/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4560 - accuracy: 0.7625\n",
            "Epoch 253/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4580 - accuracy: 0.7638\n",
            "Epoch 254/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4565 - accuracy: 0.7625\n",
            "Epoch 255/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4558 - accuracy: 0.7638\n",
            "Epoch 256/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4564 - accuracy: 0.7638\n",
            "Epoch 257/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4571 - accuracy: 0.7638\n",
            "Epoch 258/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4580 - accuracy: 0.7600\n",
            "Epoch 259/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4593 - accuracy: 0.7625\n",
            "Epoch 260/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4551 - accuracy: 0.7588\n",
            "Epoch 261/1000\n",
            "80/80 [==============================] - 0s 924us/step - loss: 0.4723 - accuracy: 0.7663\n",
            "Epoch 262/1000\n",
            "80/80 [==============================] - 0s 970us/step - loss: 0.4588 - accuracy: 0.7613\n",
            "Epoch 263/1000\n",
            "80/80 [==============================] - 0s 971us/step - loss: 0.4556 - accuracy: 0.7613\n",
            "Epoch 264/1000\n",
            "80/80 [==============================] - 0s 970us/step - loss: 0.4598 - accuracy: 0.7638\n",
            "Epoch 265/1000\n",
            "80/80 [==============================] - 0s 922us/step - loss: 0.4549 - accuracy: 0.7613\n",
            "Epoch 266/1000\n",
            "80/80 [==============================] - 0s 922us/step - loss: 0.4561 - accuracy: 0.7575\n",
            "Epoch 267/1000\n",
            "80/80 [==============================] - 0s 937us/step - loss: 0.4550 - accuracy: 0.7575\n",
            "Epoch 268/1000\n",
            "80/80 [==============================] - 0s 970us/step - loss: 0.4593 - accuracy: 0.7588\n",
            "Epoch 269/1000\n",
            "80/80 [==============================] - 0s 939us/step - loss: 0.4582 - accuracy: 0.7575\n",
            "Epoch 270/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4596 - accuracy: 0.7613\n",
            "Epoch 271/1000\n",
            "80/80 [==============================] - 0s 888us/step - loss: 0.4575 - accuracy: 0.7625\n",
            "Epoch 272/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4563 - accuracy: 0.7700\n",
            "Epoch 273/1000\n",
            "80/80 [==============================] - 0s 938us/step - loss: 0.4588 - accuracy: 0.7675\n",
            "Epoch 274/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4557 - accuracy: 0.7700\n",
            "Epoch 275/1000\n",
            "80/80 [==============================] - 0s 895us/step - loss: 0.4567 - accuracy: 0.7663\n",
            "Epoch 276/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4548 - accuracy: 0.7638\n",
            "Epoch 277/1000\n",
            "80/80 [==============================] - 0s 879us/step - loss: 0.4592 - accuracy: 0.7600\n",
            "Epoch 278/1000\n",
            "80/80 [==============================] - 0s 934us/step - loss: 0.4577 - accuracy: 0.7663\n",
            "Epoch 279/1000\n",
            "80/80 [==============================] - 0s 895us/step - loss: 0.4547 - accuracy: 0.7600\n",
            "Epoch 280/1000\n",
            "80/80 [==============================] - 0s 1000us/step - loss: 0.4544 - accuracy: 0.7625\n",
            "Epoch 281/1000\n",
            "80/80 [==============================] - 0s 962us/step - loss: 0.4633 - accuracy: 0.7663\n",
            "Epoch 282/1000\n",
            "80/80 [==============================] - 0s 995us/step - loss: 0.4584 - accuracy: 0.7575\n",
            "Epoch 283/1000\n",
            "80/80 [==============================] - 0s 942us/step - loss: 0.4559 - accuracy: 0.7600\n",
            "Epoch 284/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4558 - accuracy: 0.7538\n",
            "Epoch 285/1000\n",
            "80/80 [==============================] - 0s 948us/step - loss: 0.4699 - accuracy: 0.7600\n",
            "Epoch 286/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4557 - accuracy: 0.7563\n",
            "Epoch 287/1000\n",
            "80/80 [==============================] - 0s 902us/step - loss: 0.4561 - accuracy: 0.7550\n",
            "Epoch 288/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4536 - accuracy: 0.7625\n",
            "Epoch 289/1000\n",
            "80/80 [==============================] - 0s 984us/step - loss: 0.4546 - accuracy: 0.7650\n",
            "Epoch 290/1000\n",
            "80/80 [==============================] - 0s 897us/step - loss: 0.4533 - accuracy: 0.7613\n",
            "Epoch 291/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4557 - accuracy: 0.7638\n",
            "Epoch 292/1000\n",
            "80/80 [==============================] - 0s 958us/step - loss: 0.4540 - accuracy: 0.7650\n",
            "Epoch 293/1000\n",
            "80/80 [==============================] - 0s 923us/step - loss: 0.4562 - accuracy: 0.7625\n",
            "Epoch 294/1000\n",
            "80/80 [==============================] - 0s 927us/step - loss: 0.4568 - accuracy: 0.7625\n",
            "Epoch 295/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4546 - accuracy: 0.7588\n",
            "Epoch 296/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4541 - accuracy: 0.7613\n",
            "Epoch 297/1000\n",
            "80/80 [==============================] - 0s 984us/step - loss: 0.4579 - accuracy: 0.7588\n",
            "Epoch 298/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4534 - accuracy: 0.7725\n",
            "Epoch 299/1000\n",
            "80/80 [==============================] - 0s 925us/step - loss: 0.4560 - accuracy: 0.7613\n",
            "Epoch 300/1000\n",
            "80/80 [==============================] - 0s 947us/step - loss: 0.4544 - accuracy: 0.7675\n",
            "Epoch 301/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4531 - accuracy: 0.7588\n",
            "Epoch 302/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4548 - accuracy: 0.7613\n",
            "Epoch 303/1000\n",
            "80/80 [==============================] - 0s 941us/step - loss: 0.4552 - accuracy: 0.7588\n",
            "Epoch 304/1000\n",
            "80/80 [==============================] - 0s 970us/step - loss: 0.4536 - accuracy: 0.7600\n",
            "Epoch 305/1000\n",
            "80/80 [==============================] - 0s 978us/step - loss: 0.4704 - accuracy: 0.7625\n",
            "Epoch 306/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4560 - accuracy: 0.7650\n",
            "Epoch 307/1000\n",
            "80/80 [==============================] - 0s 883us/step - loss: 0.4559 - accuracy: 0.7588\n",
            "Epoch 308/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4540 - accuracy: 0.7563\n",
            "Epoch 309/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4557 - accuracy: 0.7588\n",
            "Epoch 310/1000\n",
            "80/80 [==============================] - 0s 949us/step - loss: 0.4545 - accuracy: 0.7638\n",
            "Epoch 311/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4542 - accuracy: 0.7600\n",
            "Epoch 312/1000\n",
            "80/80 [==============================] - 0s 976us/step - loss: 0.4539 - accuracy: 0.7588\n",
            "Epoch 313/1000\n",
            "80/80 [==============================] - 0s 990us/step - loss: 0.4546 - accuracy: 0.7588\n",
            "Epoch 314/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4536 - accuracy: 0.7638\n",
            "Epoch 315/1000\n",
            "80/80 [==============================] - 0s 951us/step - loss: 0.4528 - accuracy: 0.7663\n",
            "Epoch 316/1000\n",
            "80/80 [==============================] - 0s 967us/step - loss: 0.4547 - accuracy: 0.7588\n",
            "Epoch 317/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4553 - accuracy: 0.7588\n",
            "Epoch 318/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4530 - accuracy: 0.7600\n",
            "Epoch 319/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4527 - accuracy: 0.7625\n",
            "Epoch 320/1000\n",
            "80/80 [==============================] - 0s 933us/step - loss: 0.4530 - accuracy: 0.7625\n",
            "Epoch 321/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4538 - accuracy: 0.7575\n",
            "Epoch 322/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4538 - accuracy: 0.7625\n",
            "Epoch 323/1000\n",
            "80/80 [==============================] - 0s 948us/step - loss: 0.4536 - accuracy: 0.7600\n",
            "Epoch 324/1000\n",
            "80/80 [==============================] - 0s 964us/step - loss: 0.4545 - accuracy: 0.7563\n",
            "Epoch 325/1000\n",
            "80/80 [==============================] - 0s 943us/step - loss: 0.4536 - accuracy: 0.7688\n",
            "Epoch 326/1000\n",
            "80/80 [==============================] - 0s 907us/step - loss: 0.4520 - accuracy: 0.7650\n",
            "Epoch 327/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4532 - accuracy: 0.7600\n",
            "Epoch 328/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4542 - accuracy: 0.7600\n",
            "Epoch 329/1000\n",
            "80/80 [==============================] - 0s 978us/step - loss: 0.4523 - accuracy: 0.7625\n",
            "Epoch 330/1000\n",
            "80/80 [==============================] - 0s 994us/step - loss: 0.4538 - accuracy: 0.7650\n",
            "Epoch 331/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4528 - accuracy: 0.7575\n",
            "Epoch 332/1000\n",
            "80/80 [==============================] - 0s 936us/step - loss: 0.4543 - accuracy: 0.7600\n",
            "Epoch 333/1000\n",
            "80/80 [==============================] - 0s 934us/step - loss: 0.4509 - accuracy: 0.7650\n",
            "Epoch 334/1000\n",
            "80/80 [==============================] - 0s 969us/step - loss: 0.4591 - accuracy: 0.7613\n",
            "Epoch 335/1000\n",
            "80/80 [==============================] - 0s 902us/step - loss: 0.4572 - accuracy: 0.7600\n",
            "Epoch 336/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4538 - accuracy: 0.7650\n",
            "Epoch 337/1000\n",
            "80/80 [==============================] - 0s 962us/step - loss: 0.4519 - accuracy: 0.7600\n",
            "Epoch 338/1000\n",
            "80/80 [==============================] - 0s 967us/step - loss: 0.4524 - accuracy: 0.7650\n",
            "Epoch 339/1000\n",
            "80/80 [==============================] - 0s 997us/step - loss: 0.4529 - accuracy: 0.7625\n",
            "Epoch 340/1000\n",
            "80/80 [==============================] - 0s 950us/step - loss: 0.4542 - accuracy: 0.7588\n",
            "Epoch 341/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4515 - accuracy: 0.7638\n",
            "Epoch 342/1000\n",
            "80/80 [==============================] - 0s 936us/step - loss: 0.4513 - accuracy: 0.7625\n",
            "Epoch 343/1000\n",
            "80/80 [==============================] - 0s 982us/step - loss: 0.4515 - accuracy: 0.7625\n",
            "Epoch 344/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4537 - accuracy: 0.7625\n",
            "Epoch 345/1000\n",
            "80/80 [==============================] - 0s 930us/step - loss: 0.4749 - accuracy: 0.7613\n",
            "Epoch 346/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4756 - accuracy: 0.7563\n",
            "Epoch 347/1000\n",
            "80/80 [==============================] - 0s 956us/step - loss: 0.4544 - accuracy: 0.7638\n",
            "Epoch 348/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4521 - accuracy: 0.7675\n",
            "Epoch 349/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4511 - accuracy: 0.7638\n",
            "Epoch 350/1000\n",
            "80/80 [==============================] - 0s 953us/step - loss: 0.4518 - accuracy: 0.7613\n",
            "Epoch 351/1000\n",
            "80/80 [==============================] - 0s 997us/step - loss: 0.4520 - accuracy: 0.7650\n",
            "Epoch 352/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4497 - accuracy: 0.7613\n",
            "Epoch 353/1000\n",
            "80/80 [==============================] - 0s 972us/step - loss: 0.4498 - accuracy: 0.7638\n",
            "Epoch 354/1000\n",
            "80/80 [==============================] - 0s 931us/step - loss: 0.4509 - accuracy: 0.7613\n",
            "Epoch 355/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4532 - accuracy: 0.7638\n",
            "Epoch 356/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4497 - accuracy: 0.7625\n",
            "Epoch 357/1000\n",
            "80/80 [==============================] - 0s 928us/step - loss: 0.4499 - accuracy: 0.7738\n",
            "Epoch 358/1000\n",
            "80/80 [==============================] - 0s 969us/step - loss: 0.4513 - accuracy: 0.7638\n",
            "Epoch 359/1000\n",
            "80/80 [==============================] - 0s 934us/step - loss: 0.4517 - accuracy: 0.7638\n",
            "Epoch 360/1000\n",
            "80/80 [==============================] - 0s 919us/step - loss: 0.4580 - accuracy: 0.7575\n",
            "Epoch 361/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4517 - accuracy: 0.7650\n",
            "Epoch 362/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4497 - accuracy: 0.7713\n",
            "Epoch 363/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4498 - accuracy: 0.7713\n",
            "Epoch 364/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4489 - accuracy: 0.7613\n",
            "Epoch 365/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4500 - accuracy: 0.7613\n",
            "Epoch 366/1000\n",
            "80/80 [==============================] - 0s 980us/step - loss: 0.4500 - accuracy: 0.7688\n",
            "Epoch 367/1000\n",
            "80/80 [==============================] - 0s 997us/step - loss: 0.4514 - accuracy: 0.7613\n",
            "Epoch 368/1000\n",
            "80/80 [==============================] - 0s 951us/step - loss: 0.4484 - accuracy: 0.7675\n",
            "Epoch 369/1000\n",
            "80/80 [==============================] - 0s 913us/step - loss: 0.4484 - accuracy: 0.7725\n",
            "Epoch 370/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4481 - accuracy: 0.7650\n",
            "Epoch 371/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4495 - accuracy: 0.7663\n",
            "Epoch 372/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4510 - accuracy: 0.7650\n",
            "Epoch 373/1000\n",
            "80/80 [==============================] - 0s 952us/step - loss: 0.4492 - accuracy: 0.7613\n",
            "Epoch 374/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4508 - accuracy: 0.7638\n",
            "Epoch 375/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4484 - accuracy: 0.7700\n",
            "Epoch 376/1000\n",
            "80/80 [==============================] - 0s 947us/step - loss: 0.4490 - accuracy: 0.7638\n",
            "Epoch 377/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4494 - accuracy: 0.7638\n",
            "Epoch 378/1000\n",
            "80/80 [==============================] - 0s 921us/step - loss: 0.4503 - accuracy: 0.7563\n",
            "Epoch 379/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4501 - accuracy: 0.7638\n",
            "Epoch 380/1000\n",
            "80/80 [==============================] - 0s 956us/step - loss: 0.4482 - accuracy: 0.7663\n",
            "Epoch 381/1000\n",
            "80/80 [==============================] - 0s 946us/step - loss: 0.4504 - accuracy: 0.7688\n",
            "Epoch 382/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4516 - accuracy: 0.7588\n",
            "Epoch 383/1000\n",
            "80/80 [==============================] - 0s 995us/step - loss: 0.4478 - accuracy: 0.7675\n",
            "Epoch 384/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4495 - accuracy: 0.7650\n",
            "Epoch 385/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4492 - accuracy: 0.7625\n",
            "Epoch 386/1000\n",
            "80/80 [==============================] - 0s 969us/step - loss: 0.4524 - accuracy: 0.7650\n",
            "Epoch 387/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4480 - accuracy: 0.7675\n",
            "Epoch 388/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4495 - accuracy: 0.7675\n",
            "Epoch 389/1000\n",
            "80/80 [==============================] - 0s 956us/step - loss: 0.4483 - accuracy: 0.7650\n",
            "Epoch 390/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4512 - accuracy: 0.7675\n",
            "Epoch 391/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4507 - accuracy: 0.7625\n",
            "Epoch 392/1000\n",
            "80/80 [==============================] - 0s 997us/step - loss: 0.4477 - accuracy: 0.7650\n",
            "Epoch 393/1000\n",
            "80/80 [==============================] - 0s 989us/step - loss: 0.4488 - accuracy: 0.7638\n",
            "Epoch 394/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4532 - accuracy: 0.7638\n",
            "Epoch 395/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4496 - accuracy: 0.7638\n",
            "Epoch 396/1000\n",
            "80/80 [==============================] - 0s 951us/step - loss: 0.4548 - accuracy: 0.7600\n",
            "Epoch 397/1000\n",
            "80/80 [==============================] - 0s 950us/step - loss: 0.4482 - accuracy: 0.7625\n",
            "Epoch 398/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4487 - accuracy: 0.7588\n",
            "Epoch 399/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4488 - accuracy: 0.7650\n",
            "Epoch 400/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4502 - accuracy: 0.7675\n",
            "Epoch 401/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4498 - accuracy: 0.7663\n",
            "Epoch 402/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4486 - accuracy: 0.7663\n",
            "Epoch 403/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4488 - accuracy: 0.7663\n",
            "Epoch 404/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4483 - accuracy: 0.7625\n",
            "Epoch 405/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4484 - accuracy: 0.7575\n",
            "Epoch 406/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4489 - accuracy: 0.7713\n",
            "Epoch 407/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4476 - accuracy: 0.7625\n",
            "Epoch 408/1000\n",
            "80/80 [==============================] - 0s 993us/step - loss: 0.5027 - accuracy: 0.7425\n",
            "Epoch 409/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.5178 - accuracy: 0.7513\n",
            "Epoch 410/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4683 - accuracy: 0.7563\n",
            "Epoch 411/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4585 - accuracy: 0.7600\n",
            "Epoch 412/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4546 - accuracy: 0.7588\n",
            "Epoch 413/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4529 - accuracy: 0.7625\n",
            "Epoch 414/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4505 - accuracy: 0.7625\n",
            "Epoch 415/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4490 - accuracy: 0.7663\n",
            "Epoch 416/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4503 - accuracy: 0.7638\n",
            "Epoch 417/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4479 - accuracy: 0.7575\n",
            "Epoch 418/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4477 - accuracy: 0.7700\n",
            "Epoch 419/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4491 - accuracy: 0.7675\n",
            "Epoch 420/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4467 - accuracy: 0.7663\n",
            "Epoch 421/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4462 - accuracy: 0.7663\n",
            "Epoch 422/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4480 - accuracy: 0.7650\n",
            "Epoch 423/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4463 - accuracy: 0.7638\n",
            "Epoch 424/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4452 - accuracy: 0.7638\n",
            "Epoch 425/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4464 - accuracy: 0.7688\n",
            "Epoch 426/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4491 - accuracy: 0.7638\n",
            "Epoch 427/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4471 - accuracy: 0.7588\n",
            "Epoch 428/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4454 - accuracy: 0.7675\n",
            "Epoch 429/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4458 - accuracy: 0.7688\n",
            "Epoch 430/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4469 - accuracy: 0.7725\n",
            "Epoch 431/1000\n",
            "80/80 [==============================] - 0s 980us/step - loss: 0.4469 - accuracy: 0.7688\n",
            "Epoch 432/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4459 - accuracy: 0.7638\n",
            "Epoch 433/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4457 - accuracy: 0.7613\n",
            "Epoch 434/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4471 - accuracy: 0.7675\n",
            "Epoch 435/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4456 - accuracy: 0.7600\n",
            "Epoch 436/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4474 - accuracy: 0.7700\n",
            "Epoch 437/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4451 - accuracy: 0.7688\n",
            "Epoch 438/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4460 - accuracy: 0.7663\n",
            "Epoch 439/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4450 - accuracy: 0.7713\n",
            "Epoch 440/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4472 - accuracy: 0.7675\n",
            "Epoch 441/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4471 - accuracy: 0.7663\n",
            "Epoch 442/1000\n",
            "80/80 [==============================] - 0s 997us/step - loss: 0.4471 - accuracy: 0.7625\n",
            "Epoch 443/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4464 - accuracy: 0.7638\n",
            "Epoch 444/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4493 - accuracy: 0.7700\n",
            "Epoch 445/1000\n",
            "80/80 [==============================] - 0s 968us/step - loss: 0.4453 - accuracy: 0.7675\n",
            "Epoch 446/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4475 - accuracy: 0.7638\n",
            "Epoch 447/1000\n",
            "80/80 [==============================] - 0s 950us/step - loss: 0.4467 - accuracy: 0.7663\n",
            "Epoch 448/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4510 - accuracy: 0.7688\n",
            "Epoch 449/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4463 - accuracy: 0.7650\n",
            "Epoch 450/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4483 - accuracy: 0.7650\n",
            "Epoch 451/1000\n",
            "80/80 [==============================] - 0s 965us/step - loss: 0.4472 - accuracy: 0.7600\n",
            "Epoch 452/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4464 - accuracy: 0.7688\n",
            "Epoch 453/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4466 - accuracy: 0.7625\n",
            "Epoch 454/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4473 - accuracy: 0.7650\n",
            "Epoch 455/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4479 - accuracy: 0.7638\n",
            "Epoch 456/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4463 - accuracy: 0.7688\n",
            "Epoch 457/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4470 - accuracy: 0.7663\n",
            "Epoch 458/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4618 - accuracy: 0.7613\n",
            "Epoch 459/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4493 - accuracy: 0.7638\n",
            "Epoch 460/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4471 - accuracy: 0.7725\n",
            "Epoch 461/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4467 - accuracy: 0.7675\n",
            "Epoch 462/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4461 - accuracy: 0.7663\n",
            "Epoch 463/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4461 - accuracy: 0.7675\n",
            "Epoch 464/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4456 - accuracy: 0.7650\n",
            "Epoch 465/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4446 - accuracy: 0.7700\n",
            "Epoch 466/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4469 - accuracy: 0.7575\n",
            "Epoch 467/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4457 - accuracy: 0.7638\n",
            "Epoch 468/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4453 - accuracy: 0.7663\n",
            "Epoch 469/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4472 - accuracy: 0.7675\n",
            "Epoch 470/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4447 - accuracy: 0.7675\n",
            "Epoch 471/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4460 - accuracy: 0.7600\n",
            "Epoch 472/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4466 - accuracy: 0.7663\n",
            "Epoch 473/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4474 - accuracy: 0.7663\n",
            "Epoch 474/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4465 - accuracy: 0.7663\n",
            "Epoch 475/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4463 - accuracy: 0.7625\n",
            "Epoch 476/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4613 - accuracy: 0.7650\n",
            "Epoch 477/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4477 - accuracy: 0.7625\n",
            "Epoch 478/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4612 - accuracy: 0.7688\n",
            "Epoch 479/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4467 - accuracy: 0.7613\n",
            "Epoch 480/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4473 - accuracy: 0.7638\n",
            "Epoch 481/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4468 - accuracy: 0.7675\n",
            "Epoch 482/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4451 - accuracy: 0.7663\n",
            "Epoch 483/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4463 - accuracy: 0.7663\n",
            "Epoch 484/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4458 - accuracy: 0.7688\n",
            "Epoch 485/1000\n",
            "80/80 [==============================] - 0s 1000us/step - loss: 0.4460 - accuracy: 0.7613\n",
            "Epoch 486/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4456 - accuracy: 0.7625\n",
            "Epoch 487/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4444 - accuracy: 0.7600\n",
            "Epoch 488/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4446 - accuracy: 0.7650\n",
            "Epoch 489/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4451 - accuracy: 0.7688\n",
            "Epoch 490/1000\n",
            "80/80 [==============================] - 0s 951us/step - loss: 0.4440 - accuracy: 0.7713\n",
            "Epoch 491/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4457 - accuracy: 0.7663\n",
            "Epoch 492/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4453 - accuracy: 0.7688\n",
            "Epoch 493/1000\n",
            "80/80 [==============================] - 0s 991us/step - loss: 0.4439 - accuracy: 0.7625\n",
            "Epoch 494/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4482 - accuracy: 0.7713\n",
            "Epoch 495/1000\n",
            "80/80 [==============================] - 0s 990us/step - loss: 0.4457 - accuracy: 0.7625\n",
            "Epoch 496/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4474 - accuracy: 0.7650\n",
            "Epoch 497/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4452 - accuracy: 0.7663\n",
            "Epoch 498/1000\n",
            "80/80 [==============================] - 0s 980us/step - loss: 0.4448 - accuracy: 0.7688\n",
            "Epoch 499/1000\n",
            "80/80 [==============================] - 0s 997us/step - loss: 0.4466 - accuracy: 0.7700\n",
            "Epoch 500/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4481 - accuracy: 0.7613\n",
            "Epoch 501/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4468 - accuracy: 0.7663\n",
            "Epoch 502/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4453 - accuracy: 0.7688\n",
            "Epoch 503/1000\n",
            "80/80 [==============================] - 0s 972us/step - loss: 0.4430 - accuracy: 0.7650\n",
            "Epoch 504/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4448 - accuracy: 0.7638\n",
            "Epoch 505/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4489 - accuracy: 0.7675\n",
            "Epoch 506/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4434 - accuracy: 0.7588\n",
            "Epoch 507/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4472 - accuracy: 0.7700\n",
            "Epoch 508/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4430 - accuracy: 0.7688\n",
            "Epoch 509/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4437 - accuracy: 0.7675\n",
            "Epoch 510/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4436 - accuracy: 0.7663\n",
            "Epoch 511/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4426 - accuracy: 0.7650\n",
            "Epoch 512/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4444 - accuracy: 0.7625\n",
            "Epoch 513/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4441 - accuracy: 0.7625\n",
            "Epoch 514/1000\n",
            "80/80 [==============================] - 0s 972us/step - loss: 0.4457 - accuracy: 0.7638\n",
            "Epoch 515/1000\n",
            "80/80 [==============================] - 0s 974us/step - loss: 0.4442 - accuracy: 0.7625\n",
            "Epoch 516/1000\n",
            "80/80 [==============================] - 0s 958us/step - loss: 0.4436 - accuracy: 0.7750\n",
            "Epoch 517/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4436 - accuracy: 0.7650\n",
            "Epoch 518/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4435 - accuracy: 0.7638\n",
            "Epoch 519/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4425 - accuracy: 0.7688\n",
            "Epoch 520/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4435 - accuracy: 0.7663\n",
            "Epoch 521/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4462 - accuracy: 0.7663\n",
            "Epoch 522/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4428 - accuracy: 0.7650\n",
            "Epoch 523/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4441 - accuracy: 0.7638\n",
            "Epoch 524/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4459 - accuracy: 0.7688\n",
            "Epoch 525/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4439 - accuracy: 0.7638\n",
            "Epoch 526/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4439 - accuracy: 0.7663\n",
            "Epoch 527/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4423 - accuracy: 0.7625\n",
            "Epoch 528/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4422 - accuracy: 0.7663\n",
            "Epoch 529/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4424 - accuracy: 0.7700\n",
            "Epoch 530/1000\n",
            "80/80 [==============================] - 0s 978us/step - loss: 0.4431 - accuracy: 0.7713\n",
            "Epoch 531/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4455 - accuracy: 0.7625\n",
            "Epoch 532/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4426 - accuracy: 0.7613\n",
            "Epoch 533/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4431 - accuracy: 0.7625\n",
            "Epoch 534/1000\n",
            "80/80 [==============================] - 0s 975us/step - loss: 0.4424 - accuracy: 0.7613\n",
            "Epoch 535/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4425 - accuracy: 0.7688\n",
            "Epoch 536/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4418 - accuracy: 0.7600\n",
            "Epoch 537/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4426 - accuracy: 0.7625\n",
            "Epoch 538/1000\n",
            "80/80 [==============================] - 0s 949us/step - loss: 0.4405 - accuracy: 0.7675\n",
            "Epoch 539/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4432 - accuracy: 0.7638\n",
            "Epoch 540/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4407 - accuracy: 0.7713\n",
            "Epoch 541/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4450 - accuracy: 0.7713\n",
            "Epoch 542/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4439 - accuracy: 0.7613\n",
            "Epoch 543/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4411 - accuracy: 0.7650\n",
            "Epoch 544/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4424 - accuracy: 0.7625\n",
            "Epoch 545/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4426 - accuracy: 0.7675\n",
            "Epoch 546/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4427 - accuracy: 0.7650\n",
            "Epoch 547/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4402 - accuracy: 0.7675\n",
            "Epoch 548/1000\n",
            "80/80 [==============================] - 0s 953us/step - loss: 0.4438 - accuracy: 0.7725\n",
            "Epoch 549/1000\n",
            "80/80 [==============================] - 0s 986us/step - loss: 0.4402 - accuracy: 0.7638\n",
            "Epoch 550/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4392 - accuracy: 0.7688\n",
            "Epoch 551/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4390 - accuracy: 0.7688\n",
            "Epoch 552/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4414 - accuracy: 0.7650\n",
            "Epoch 553/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4481 - accuracy: 0.7675\n",
            "Epoch 554/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4417 - accuracy: 0.7650\n",
            "Epoch 555/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4414 - accuracy: 0.7663\n",
            "Epoch 556/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4434 - accuracy: 0.7638\n",
            "Epoch 557/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4424 - accuracy: 0.7650\n",
            "Epoch 558/1000\n",
            "80/80 [==============================] - 0s 1000us/step - loss: 0.4412 - accuracy: 0.7713\n",
            "Epoch 559/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4399 - accuracy: 0.7688\n",
            "Epoch 560/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4419 - accuracy: 0.7700\n",
            "Epoch 561/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4413 - accuracy: 0.7750\n",
            "Epoch 562/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4430 - accuracy: 0.7688\n",
            "Epoch 563/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4578 - accuracy: 0.7700\n",
            "Epoch 564/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4406 - accuracy: 0.7663\n",
            "Epoch 565/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4411 - accuracy: 0.7713\n",
            "Epoch 566/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4403 - accuracy: 0.7700\n",
            "Epoch 567/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4410 - accuracy: 0.7650\n",
            "Epoch 568/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4423 - accuracy: 0.7713\n",
            "Epoch 569/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4396 - accuracy: 0.7688\n",
            "Epoch 570/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4413 - accuracy: 0.7700\n",
            "Epoch 571/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4398 - accuracy: 0.7713\n",
            "Epoch 572/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4398 - accuracy: 0.7625\n",
            "Epoch 573/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4407 - accuracy: 0.7638\n",
            "Epoch 574/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4398 - accuracy: 0.7700\n",
            "Epoch 575/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4410 - accuracy: 0.7675\n",
            "Epoch 576/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4397 - accuracy: 0.7725\n",
            "Epoch 577/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4401 - accuracy: 0.7688\n",
            "Epoch 578/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4403 - accuracy: 0.7663\n",
            "Epoch 579/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4390 - accuracy: 0.7750\n",
            "Epoch 580/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4457 - accuracy: 0.7675\n",
            "Epoch 581/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4408 - accuracy: 0.7738\n",
            "Epoch 582/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4404 - accuracy: 0.7713\n",
            "Epoch 583/1000\n",
            "80/80 [==============================] - 0s 990us/step - loss: 0.4399 - accuracy: 0.7700\n",
            "Epoch 584/1000\n",
            "80/80 [==============================] - 0s 998us/step - loss: 0.4388 - accuracy: 0.7750\n",
            "Epoch 585/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4393 - accuracy: 0.7650\n",
            "Epoch 586/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4408 - accuracy: 0.7675\n",
            "Epoch 587/1000\n",
            "80/80 [==============================] - 0s 994us/step - loss: 0.4560 - accuracy: 0.7713\n",
            "Epoch 588/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4424 - accuracy: 0.7738\n",
            "Epoch 589/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4404 - accuracy: 0.7750\n",
            "Epoch 590/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4409 - accuracy: 0.7663\n",
            "Epoch 591/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4399 - accuracy: 0.7650\n",
            "Epoch 592/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4423 - accuracy: 0.7738\n",
            "Epoch 593/1000\n",
            "80/80 [==============================] - 0s 967us/step - loss: 0.4387 - accuracy: 0.7750\n",
            "Epoch 594/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4381 - accuracy: 0.7738\n",
            "Epoch 595/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4450 - accuracy: 0.7700\n",
            "Epoch 596/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4413 - accuracy: 0.7688\n",
            "Epoch 597/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4393 - accuracy: 0.7738\n",
            "Epoch 598/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4396 - accuracy: 0.7775\n",
            "Epoch 599/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4373 - accuracy: 0.7713\n",
            "Epoch 600/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4377 - accuracy: 0.7675\n",
            "Epoch 601/1000\n",
            "80/80 [==============================] - 0s 990us/step - loss: 0.4387 - accuracy: 0.7738\n",
            "Epoch 602/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4374 - accuracy: 0.7713\n",
            "Epoch 603/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4396 - accuracy: 0.7700\n",
            "Epoch 604/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4400 - accuracy: 0.7650\n",
            "Epoch 605/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4377 - accuracy: 0.7725\n",
            "Epoch 606/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4389 - accuracy: 0.7763\n",
            "Epoch 607/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4381 - accuracy: 0.7738\n",
            "Epoch 608/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4394 - accuracy: 0.7763\n",
            "Epoch 609/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4372 - accuracy: 0.7738\n",
            "Epoch 610/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4384 - accuracy: 0.7713\n",
            "Epoch 611/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4381 - accuracy: 0.7700\n",
            "Epoch 612/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4602 - accuracy: 0.7738\n",
            "Epoch 613/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4452 - accuracy: 0.7663\n",
            "Epoch 614/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4384 - accuracy: 0.7688\n",
            "Epoch 615/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4400 - accuracy: 0.7713\n",
            "Epoch 616/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4372 - accuracy: 0.7713\n",
            "Epoch 617/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4374 - accuracy: 0.7750\n",
            "Epoch 618/1000\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.4371 - accuracy: 0.7725\n",
            "Epoch 619/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4364 - accuracy: 0.7713\n",
            "Epoch 620/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4373 - accuracy: 0.7725\n",
            "Epoch 621/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4372 - accuracy: 0.7725\n",
            "Epoch 622/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4373 - accuracy: 0.7750\n",
            "Epoch 623/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4363 - accuracy: 0.7700\n",
            "Epoch 624/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4370 - accuracy: 0.7713\n",
            "Epoch 625/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4363 - accuracy: 0.7725\n",
            "Epoch 626/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4363 - accuracy: 0.7725\n",
            "Epoch 627/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4357 - accuracy: 0.7725\n",
            "Epoch 628/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4347 - accuracy: 0.7750\n",
            "Epoch 629/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4373 - accuracy: 0.7675\n",
            "Epoch 630/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4377 - accuracy: 0.7738\n",
            "Epoch 631/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4391 - accuracy: 0.7650\n",
            "Epoch 632/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4365 - accuracy: 0.7713\n",
            "Epoch 633/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4369 - accuracy: 0.7800\n",
            "Epoch 634/1000\n",
            "80/80 [==============================] - 0s 995us/step - loss: 0.4392 - accuracy: 0.7763\n",
            "Epoch 635/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4364 - accuracy: 0.7763\n",
            "Epoch 636/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4377 - accuracy: 0.7700\n",
            "Epoch 637/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4365 - accuracy: 0.7725\n",
            "Epoch 638/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4376 - accuracy: 0.7738\n",
            "Epoch 639/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4357 - accuracy: 0.7713\n",
            "Epoch 640/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4346 - accuracy: 0.7738\n",
            "Epoch 641/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4399 - accuracy: 0.7688\n",
            "Epoch 642/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4412 - accuracy: 0.7625\n",
            "Epoch 643/1000\n",
            "80/80 [==============================] - 0s 987us/step - loss: 0.4362 - accuracy: 0.7763\n",
            "Epoch 644/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4357 - accuracy: 0.7650\n",
            "Epoch 645/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4520 - accuracy: 0.7750\n",
            "Epoch 646/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4367 - accuracy: 0.7725\n",
            "Epoch 647/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4347 - accuracy: 0.7763\n",
            "Epoch 648/1000\n",
            "80/80 [==============================] - 0s 954us/step - loss: 0.4382 - accuracy: 0.7738\n",
            "Epoch 649/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4347 - accuracy: 0.7713\n",
            "Epoch 650/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4364 - accuracy: 0.7700\n",
            "Epoch 651/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4356 - accuracy: 0.7738\n",
            "Epoch 652/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4360 - accuracy: 0.7775\n",
            "Epoch 653/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4360 - accuracy: 0.7713\n",
            "Epoch 654/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4370 - accuracy: 0.7738\n",
            "Epoch 655/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4368 - accuracy: 0.7738\n",
            "Epoch 656/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4342 - accuracy: 0.7738\n",
            "Epoch 657/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4355 - accuracy: 0.7725\n",
            "Epoch 658/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4373 - accuracy: 0.7750\n",
            "Epoch 659/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4367 - accuracy: 0.7763\n",
            "Epoch 660/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4354 - accuracy: 0.7725\n",
            "Epoch 661/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4354 - accuracy: 0.7675\n",
            "Epoch 662/1000\n",
            "80/80 [==============================] - 0s 1000us/step - loss: 0.4373 - accuracy: 0.7775\n",
            "Epoch 663/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4360 - accuracy: 0.7713\n",
            "Epoch 664/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4372 - accuracy: 0.7688\n",
            "Epoch 665/1000\n",
            "80/80 [==============================] - 0s 994us/step - loss: 0.4381 - accuracy: 0.7738\n",
            "Epoch 666/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4373 - accuracy: 0.7688\n",
            "Epoch 667/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4357 - accuracy: 0.7750\n",
            "Epoch 668/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4351 - accuracy: 0.7738\n",
            "Epoch 669/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4485 - accuracy: 0.7713\n",
            "Epoch 670/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4353 - accuracy: 0.7750\n",
            "Epoch 671/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4330 - accuracy: 0.7713\n",
            "Epoch 672/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4353 - accuracy: 0.7763\n",
            "Epoch 673/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4385 - accuracy: 0.7713\n",
            "Epoch 674/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4363 - accuracy: 0.7725\n",
            "Epoch 675/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4352 - accuracy: 0.7725\n",
            "Epoch 676/1000\n",
            "80/80 [==============================] - 0s 945us/step - loss: 0.4347 - accuracy: 0.7738\n",
            "Epoch 677/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4334 - accuracy: 0.7788\n",
            "Epoch 678/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4325 - accuracy: 0.7650\n",
            "Epoch 679/1000\n",
            "80/80 [==============================] - 0s 981us/step - loss: 0.4345 - accuracy: 0.7725\n",
            "Epoch 680/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4370 - accuracy: 0.7725\n",
            "Epoch 681/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4376 - accuracy: 0.7675\n",
            "Epoch 682/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4341 - accuracy: 0.7700\n",
            "Epoch 683/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4338 - accuracy: 0.7725\n",
            "Epoch 684/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4347 - accuracy: 0.7750\n",
            "Epoch 685/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4325 - accuracy: 0.7713\n",
            "Epoch 686/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4363 - accuracy: 0.7713\n",
            "Epoch 687/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4498 - accuracy: 0.7700\n",
            "Epoch 688/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4360 - accuracy: 0.7763\n",
            "Epoch 689/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4338 - accuracy: 0.7738\n",
            "Epoch 690/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4359 - accuracy: 0.7788\n",
            "Epoch 691/1000\n",
            "80/80 [==============================] - 0s 979us/step - loss: 0.4343 - accuracy: 0.7750\n",
            "Epoch 692/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4332 - accuracy: 0.7800\n",
            "Epoch 693/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4333 - accuracy: 0.7713\n",
            "Epoch 694/1000\n",
            "80/80 [==============================] - 0s 998us/step - loss: 0.4328 - accuracy: 0.7750\n",
            "Epoch 695/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4339 - accuracy: 0.7663\n",
            "Epoch 696/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4332 - accuracy: 0.7713\n",
            "Epoch 697/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4343 - accuracy: 0.7738\n",
            "Epoch 698/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4342 - accuracy: 0.7725\n",
            "Epoch 699/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4319 - accuracy: 0.7763\n",
            "Epoch 700/1000\n",
            "80/80 [==============================] - 0s 995us/step - loss: 0.4618 - accuracy: 0.7675\n",
            "Epoch 701/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4345 - accuracy: 0.7700\n",
            "Epoch 702/1000\n",
            "80/80 [==============================] - 0s 971us/step - loss: 0.4369 - accuracy: 0.7738\n",
            "Epoch 703/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4348 - accuracy: 0.7688\n",
            "Epoch 704/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4311 - accuracy: 0.7738\n",
            "Epoch 705/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4373 - accuracy: 0.7738\n",
            "Epoch 706/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4328 - accuracy: 0.7763\n",
            "Epoch 707/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4355 - accuracy: 0.7688\n",
            "Epoch 708/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4334 - accuracy: 0.7788\n",
            "Epoch 709/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4341 - accuracy: 0.7700\n",
            "Epoch 710/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4346 - accuracy: 0.7738\n",
            "Epoch 711/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4338 - accuracy: 0.7713\n",
            "Epoch 712/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4339 - accuracy: 0.7700\n",
            "Epoch 713/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4327 - accuracy: 0.7775\n",
            "Epoch 714/1000\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7688\n",
            "Epoch 715/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4357 - accuracy: 0.7763\n",
            "Epoch 716/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4529 - accuracy: 0.7613\n",
            "Epoch 717/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4362 - accuracy: 0.7763\n",
            "Epoch 718/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4325 - accuracy: 0.7750\n",
            "Epoch 719/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4328 - accuracy: 0.7738\n",
            "Epoch 720/1000\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.4326 - accuracy: 0.7775\n",
            "Epoch 721/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4316 - accuracy: 0.7725\n",
            "Epoch 722/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4318 - accuracy: 0.7775\n",
            "Epoch 723/1000\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7763\n",
            "Epoch 724/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4335 - accuracy: 0.7775\n",
            "Epoch 725/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4312 - accuracy: 0.7788\n",
            "Epoch 726/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4316 - accuracy: 0.7800\n",
            "Epoch 727/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4482 - accuracy: 0.7700\n",
            "Epoch 728/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4342 - accuracy: 0.7713\n",
            "Epoch 729/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4304 - accuracy: 0.7750\n",
            "Epoch 730/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4312 - accuracy: 0.7725\n",
            "Epoch 731/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4472 - accuracy: 0.7688\n",
            "Epoch 732/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4352 - accuracy: 0.7700\n",
            "Epoch 733/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4317 - accuracy: 0.7713\n",
            "Epoch 734/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4447 - accuracy: 0.7738\n",
            "Epoch 735/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4364 - accuracy: 0.7713\n",
            "Epoch 736/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4376 - accuracy: 0.7713\n",
            "Epoch 737/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4320 - accuracy: 0.7725\n",
            "Epoch 738/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4305 - accuracy: 0.7763\n",
            "Epoch 739/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4327 - accuracy: 0.7763\n",
            "Epoch 740/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4350 - accuracy: 0.7775\n",
            "Epoch 741/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4308 - accuracy: 0.7763\n",
            "Epoch 742/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4315 - accuracy: 0.7750\n",
            "Epoch 743/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4314 - accuracy: 0.7725\n",
            "Epoch 744/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4318 - accuracy: 0.7725\n",
            "Epoch 745/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4314 - accuracy: 0.7713\n",
            "Epoch 746/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4327 - accuracy: 0.7750\n",
            "Epoch 747/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4312 - accuracy: 0.7750\n",
            "Epoch 748/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4334 - accuracy: 0.7713\n",
            "Epoch 749/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4297 - accuracy: 0.7763\n",
            "Epoch 750/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4331 - accuracy: 0.7725\n",
            "Epoch 751/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4365 - accuracy: 0.7725\n",
            "Epoch 752/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4312 - accuracy: 0.7725\n",
            "Epoch 753/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4448 - accuracy: 0.7713\n",
            "Epoch 754/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4578 - accuracy: 0.7638\n",
            "Epoch 755/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4364 - accuracy: 0.7750\n",
            "Epoch 756/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4331 - accuracy: 0.7725\n",
            "Epoch 757/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4344 - accuracy: 0.7700\n",
            "Epoch 758/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4303 - accuracy: 0.7775\n",
            "Epoch 759/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4303 - accuracy: 0.7750\n",
            "Epoch 760/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4293 - accuracy: 0.7750\n",
            "Epoch 761/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4310 - accuracy: 0.7738\n",
            "Epoch 762/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4308 - accuracy: 0.7725\n",
            "Epoch 763/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.7775\n",
            "Epoch 764/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4303 - accuracy: 0.7713\n",
            "Epoch 765/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4314 - accuracy: 0.7713\n",
            "Epoch 766/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4307 - accuracy: 0.7763\n",
            "Epoch 767/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4287 - accuracy: 0.7763\n",
            "Epoch 768/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4287 - accuracy: 0.7763\n",
            "Epoch 769/1000\n",
            "80/80 [==============================] - 0s 996us/step - loss: 0.4305 - accuracy: 0.7775\n",
            "Epoch 770/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4289 - accuracy: 0.7725\n",
            "Epoch 771/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4318 - accuracy: 0.7700\n",
            "Epoch 772/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4303 - accuracy: 0.7788\n",
            "Epoch 773/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4302 - accuracy: 0.7725\n",
            "Epoch 774/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4332 - accuracy: 0.7763\n",
            "Epoch 775/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4307 - accuracy: 0.7738\n",
            "Epoch 776/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4305 - accuracy: 0.7750\n",
            "Epoch 777/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4309 - accuracy: 0.7775\n",
            "Epoch 778/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4294 - accuracy: 0.7725\n",
            "Epoch 779/1000\n",
            "80/80 [==============================] - 0s 993us/step - loss: 0.4279 - accuracy: 0.7763\n",
            "Epoch 780/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4288 - accuracy: 0.7675\n",
            "Epoch 781/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4291 - accuracy: 0.7763\n",
            "Epoch 782/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4351 - accuracy: 0.7738\n",
            "Epoch 783/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4294 - accuracy: 0.7738\n",
            "Epoch 784/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4298 - accuracy: 0.7738\n",
            "Epoch 785/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4285 - accuracy: 0.7725\n",
            "Epoch 786/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4309 - accuracy: 0.7763\n",
            "Epoch 787/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4288 - accuracy: 0.7775\n",
            "Epoch 788/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4305 - accuracy: 0.7675\n",
            "Epoch 789/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4295 - accuracy: 0.7800\n",
            "Epoch 790/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4319 - accuracy: 0.7738\n",
            "Epoch 791/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4301 - accuracy: 0.7775\n",
            "Epoch 792/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4331 - accuracy: 0.7700\n",
            "Epoch 793/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4310 - accuracy: 0.7738\n",
            "Epoch 794/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4262 - accuracy: 0.7688\n",
            "Epoch 795/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4308 - accuracy: 0.7725\n",
            "Epoch 796/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4303 - accuracy: 0.7725\n",
            "Epoch 797/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4339 - accuracy: 0.7725\n",
            "Epoch 798/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4387 - accuracy: 0.7663\n",
            "Epoch 799/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4304 - accuracy: 0.7700\n",
            "Epoch 800/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4305 - accuracy: 0.7750\n",
            "Epoch 801/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4269 - accuracy: 0.7750\n",
            "Epoch 802/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4310 - accuracy: 0.7750\n",
            "Epoch 803/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4291 - accuracy: 0.7738\n",
            "Epoch 804/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.7750\n",
            "Epoch 805/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4271 - accuracy: 0.7725\n",
            "Epoch 806/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4319 - accuracy: 0.7750\n",
            "Epoch 807/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4288 - accuracy: 0.7713\n",
            "Epoch 808/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4285 - accuracy: 0.7763\n",
            "Epoch 809/1000\n",
            "80/80 [==============================] - 0s 985us/step - loss: 0.4292 - accuracy: 0.7738\n",
            "Epoch 810/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4305 - accuracy: 0.7738\n",
            "Epoch 811/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4285 - accuracy: 0.7763\n",
            "Epoch 812/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4305 - accuracy: 0.7750\n",
            "Epoch 813/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4284 - accuracy: 0.7725\n",
            "Epoch 814/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.7763\n",
            "Epoch 815/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4291 - accuracy: 0.7713\n",
            "Epoch 816/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4287 - accuracy: 0.7700\n",
            "Epoch 817/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4304 - accuracy: 0.7613\n",
            "Epoch 818/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4299 - accuracy: 0.7750\n",
            "Epoch 819/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4269 - accuracy: 0.7713\n",
            "Epoch 820/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4300 - accuracy: 0.7738\n",
            "Epoch 821/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4292 - accuracy: 0.7700\n",
            "Epoch 822/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4326 - accuracy: 0.7700\n",
            "Epoch 823/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.7713\n",
            "Epoch 824/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.7713\n",
            "Epoch 825/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4269 - accuracy: 0.7775\n",
            "Epoch 826/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4267 - accuracy: 0.7725\n",
            "Epoch 827/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4338 - accuracy: 0.7675\n",
            "Epoch 828/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4281 - accuracy: 0.7763\n",
            "Epoch 829/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4283 - accuracy: 0.7688\n",
            "Epoch 830/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4427 - accuracy: 0.7738\n",
            "Epoch 831/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4301 - accuracy: 0.7725\n",
            "Epoch 832/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4271 - accuracy: 0.7775\n",
            "Epoch 833/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4540 - accuracy: 0.7588\n",
            "Epoch 834/1000\n",
            "80/80 [==============================] - 0s 994us/step - loss: 0.4321 - accuracy: 0.7713\n",
            "Epoch 835/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4283 - accuracy: 0.7713\n",
            "Epoch 836/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4305 - accuracy: 0.7763\n",
            "Epoch 837/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4268 - accuracy: 0.7800\n",
            "Epoch 838/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4329 - accuracy: 0.7675\n",
            "Epoch 839/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4271 - accuracy: 0.7750\n",
            "Epoch 840/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.7713\n",
            "Epoch 841/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4264 - accuracy: 0.7725\n",
            "Epoch 842/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4260 - accuracy: 0.7750\n",
            "Epoch 843/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4269 - accuracy: 0.7738\n",
            "Epoch 844/1000\n",
            "80/80 [==============================] - 0s 957us/step - loss: 0.4303 - accuracy: 0.7688\n",
            "Epoch 845/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4283 - accuracy: 0.7713\n",
            "Epoch 846/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4256 - accuracy: 0.7688\n",
            "Epoch 847/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.7725\n",
            "Epoch 848/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4264 - accuracy: 0.7763\n",
            "Epoch 849/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4281 - accuracy: 0.7700\n",
            "Epoch 850/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4289 - accuracy: 0.7725\n",
            "Epoch 851/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.7738\n",
            "Epoch 852/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4279 - accuracy: 0.7738\n",
            "Epoch 853/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4474 - accuracy: 0.7663\n",
            "Epoch 854/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4889 - accuracy: 0.7538\n",
            "Epoch 855/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4473 - accuracy: 0.7575\n",
            "Epoch 856/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4370 - accuracy: 0.7638\n",
            "Epoch 857/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4340 - accuracy: 0.7700\n",
            "Epoch 858/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4325 - accuracy: 0.7688\n",
            "Epoch 859/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4286 - accuracy: 0.7713\n",
            "Epoch 860/1000\n",
            "80/80 [==============================] - 0s 966us/step - loss: 0.4314 - accuracy: 0.7700\n",
            "Epoch 861/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4262 - accuracy: 0.7700\n",
            "Epoch 862/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4264 - accuracy: 0.7725\n",
            "Epoch 863/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.7700\n",
            "Epoch 864/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4254 - accuracy: 0.7750\n",
            "Epoch 865/1000\n",
            "80/80 [==============================] - 0s 999us/step - loss: 0.4255 - accuracy: 0.7663\n",
            "Epoch 866/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4253 - accuracy: 0.7763\n",
            "Epoch 867/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4260 - accuracy: 0.7700\n",
            "Epoch 868/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4238 - accuracy: 0.7775\n",
            "Epoch 869/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4261 - accuracy: 0.7775\n",
            "Epoch 870/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4256 - accuracy: 0.7688\n",
            "Epoch 871/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4254 - accuracy: 0.7725\n",
            "Epoch 872/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4250 - accuracy: 0.7775\n",
            "Epoch 873/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4250 - accuracy: 0.7788\n",
            "Epoch 874/1000\n",
            "80/80 [==============================] - 0s 997us/step - loss: 0.4239 - accuracy: 0.7700\n",
            "Epoch 875/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4242 - accuracy: 0.7750\n",
            "Epoch 876/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4246 - accuracy: 0.7775\n",
            "Epoch 877/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4298 - accuracy: 0.7713\n",
            "Epoch 878/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4248 - accuracy: 0.7750\n",
            "Epoch 879/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4250 - accuracy: 0.7763\n",
            "Epoch 880/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4256 - accuracy: 0.7738\n",
            "Epoch 881/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4399 - accuracy: 0.7713\n",
            "Epoch 882/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4305 - accuracy: 0.7675\n",
            "Epoch 883/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4256 - accuracy: 0.7675\n",
            "Epoch 884/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4251 - accuracy: 0.7688\n",
            "Epoch 885/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4262 - accuracy: 0.7725\n",
            "Epoch 886/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4263 - accuracy: 0.7675\n",
            "Epoch 887/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4251 - accuracy: 0.7713\n",
            "Epoch 888/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4252 - accuracy: 0.7763\n",
            "Epoch 889/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4297 - accuracy: 0.7663\n",
            "Epoch 890/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4284 - accuracy: 0.7650\n",
            "Epoch 891/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4253 - accuracy: 0.7713\n",
            "Epoch 892/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4249 - accuracy: 0.7763\n",
            "Epoch 893/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4253 - accuracy: 0.7688\n",
            "Epoch 894/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4237 - accuracy: 0.7688\n",
            "Epoch 895/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4253 - accuracy: 0.7713\n",
            "Epoch 896/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4287 - accuracy: 0.7763\n",
            "Epoch 897/1000\n",
            "80/80 [==============================] - 0s 989us/step - loss: 0.4259 - accuracy: 0.7675\n",
            "Epoch 898/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.7675\n",
            "Epoch 899/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4265 - accuracy: 0.7688\n",
            "Epoch 900/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4265 - accuracy: 0.7775\n",
            "Epoch 901/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4245 - accuracy: 0.7750\n",
            "Epoch 902/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4259 - accuracy: 0.7713\n",
            "Epoch 903/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4234 - accuracy: 0.7663\n",
            "Epoch 904/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4234 - accuracy: 0.7825\n",
            "Epoch 905/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4253 - accuracy: 0.7675\n",
            "Epoch 906/1000\n",
            "80/80 [==============================] - 0s 982us/step - loss: 0.4270 - accuracy: 0.7700\n",
            "Epoch 907/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4240 - accuracy: 0.7763\n",
            "Epoch 908/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4280 - accuracy: 0.7738\n",
            "Epoch 909/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4213 - accuracy: 0.7750\n",
            "Epoch 910/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.7775\n",
            "Epoch 911/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4265 - accuracy: 0.7688\n",
            "Epoch 912/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4243 - accuracy: 0.7675\n",
            "Epoch 913/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4557 - accuracy: 0.7688\n",
            "Epoch 914/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4270 - accuracy: 0.7700\n",
            "Epoch 915/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.7688\n",
            "Epoch 916/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4230 - accuracy: 0.7713\n",
            "Epoch 917/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4300 - accuracy: 0.7713\n",
            "Epoch 918/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4410 - accuracy: 0.7650\n",
            "Epoch 919/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4265 - accuracy: 0.7675\n",
            "Epoch 920/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4235 - accuracy: 0.7725\n",
            "Epoch 921/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4202 - accuracy: 0.7675\n",
            "Epoch 922/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4248 - accuracy: 0.7688\n",
            "Epoch 923/1000\n",
            "80/80 [==============================] - 0s 970us/step - loss: 0.4252 - accuracy: 0.7763\n",
            "Epoch 924/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4235 - accuracy: 0.7675\n",
            "Epoch 925/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4243 - accuracy: 0.7663\n",
            "Epoch 926/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4233 - accuracy: 0.7713\n",
            "Epoch 927/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4245 - accuracy: 0.7675\n",
            "Epoch 928/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4234 - accuracy: 0.7750\n",
            "Epoch 929/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4247 - accuracy: 0.7675\n",
            "Epoch 930/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4223 - accuracy: 0.7738\n",
            "Epoch 931/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4233 - accuracy: 0.7788\n",
            "Epoch 932/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4227 - accuracy: 0.7700\n",
            "Epoch 933/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4239 - accuracy: 0.7738\n",
            "Epoch 934/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4255 - accuracy: 0.7713\n",
            "Epoch 935/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4258 - accuracy: 0.7700\n",
            "Epoch 936/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4234 - accuracy: 0.7763\n",
            "Epoch 937/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4230 - accuracy: 0.7713\n",
            "Epoch 938/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4234 - accuracy: 0.7788\n",
            "Epoch 939/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4231 - accuracy: 0.7700\n",
            "Epoch 940/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4221 - accuracy: 0.7713\n",
            "Epoch 941/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4239 - accuracy: 0.7725\n",
            "Epoch 942/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4252 - accuracy: 0.7688\n",
            "Epoch 943/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4295 - accuracy: 0.7713\n",
            "Epoch 944/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4223 - accuracy: 0.7713\n",
            "Epoch 945/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4212 - accuracy: 0.7725\n",
            "Epoch 946/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4242 - accuracy: 0.7663\n",
            "Epoch 947/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4228 - accuracy: 0.7675\n",
            "Epoch 948/1000\n",
            "80/80 [==============================] - 0s 982us/step - loss: 0.4212 - accuracy: 0.7700\n",
            "Epoch 949/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4244 - accuracy: 0.7650\n",
            "Epoch 950/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4223 - accuracy: 0.7725\n",
            "Epoch 951/1000\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.7700\n",
            "Epoch 952/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4296 - accuracy: 0.7638\n",
            "Epoch 953/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4241 - accuracy: 0.7688\n",
            "Epoch 954/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4233 - accuracy: 0.7725\n",
            "Epoch 955/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4269 - accuracy: 0.7650\n",
            "Epoch 956/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4345 - accuracy: 0.7750\n",
            "Epoch 957/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4349 - accuracy: 0.7638\n",
            "Epoch 958/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4276 - accuracy: 0.7688\n",
            "Epoch 959/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4270 - accuracy: 0.7650\n",
            "Epoch 960/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4268 - accuracy: 0.7725\n",
            "Epoch 961/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4252 - accuracy: 0.7738\n",
            "Epoch 962/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4224 - accuracy: 0.7713\n",
            "Epoch 963/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4237 - accuracy: 0.7638\n",
            "Epoch 964/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4236 - accuracy: 0.7713\n",
            "Epoch 965/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4243 - accuracy: 0.7738\n",
            "Epoch 966/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4254 - accuracy: 0.7663\n",
            "Epoch 967/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4247 - accuracy: 0.7675\n",
            "Epoch 968/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4232 - accuracy: 0.7725\n",
            "Epoch 969/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4267 - accuracy: 0.7688\n",
            "Epoch 970/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4246 - accuracy: 0.7688\n",
            "Epoch 971/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4237 - accuracy: 0.7688\n",
            "Epoch 972/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4252 - accuracy: 0.7663\n",
            "Epoch 973/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4236 - accuracy: 0.7688\n",
            "Epoch 974/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4226 - accuracy: 0.7788\n",
            "Epoch 975/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4242 - accuracy: 0.7700\n",
            "Epoch 976/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4252 - accuracy: 0.7650\n",
            "Epoch 977/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4295 - accuracy: 0.7650\n",
            "Epoch 978/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4408 - accuracy: 0.7613\n",
            "Epoch 979/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4286 - accuracy: 0.7663\n",
            "Epoch 980/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4252 - accuracy: 0.7725\n",
            "Epoch 981/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4237 - accuracy: 0.7675\n",
            "Epoch 982/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4216 - accuracy: 0.7700\n",
            "Epoch 983/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4234 - accuracy: 0.7688\n",
            "Epoch 984/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4221 - accuracy: 0.7713\n",
            "Epoch 985/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4212 - accuracy: 0.7775\n",
            "Epoch 986/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4215 - accuracy: 0.7675\n",
            "Epoch 987/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4240 - accuracy: 0.7750\n",
            "Epoch 988/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4225 - accuracy: 0.7738\n",
            "Epoch 989/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4224 - accuracy: 0.7663\n",
            "Epoch 990/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4228 - accuracy: 0.7725\n",
            "Epoch 991/1000\n",
            "80/80 [==============================] - 0s 997us/step - loss: 0.4216 - accuracy: 0.7750\n",
            "Epoch 992/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4213 - accuracy: 0.7675\n",
            "Epoch 993/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.7750\n",
            "Epoch 994/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4234 - accuracy: 0.7763\n",
            "Epoch 995/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4221 - accuracy: 0.7738\n",
            "Epoch 996/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4223 - accuracy: 0.7763\n",
            "Epoch 997/1000\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.4236 - accuracy: 0.7775\n",
            "Epoch 998/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4251 - accuracy: 0.7763\n",
            "Epoch 999/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4205 - accuracy: 0.7700\n",
            "Epoch 1000/1000\n",
            "80/80 [==============================] - 0s 1ms/step - loss: 0.4219 - accuracy: 0.7700\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f779e191710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgl6y_FLjcHt"
      },
      "source": [
        "#Realizar previsão e transformar resultado em True e False\n",
        "y_pred = classifier.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJ8fZwlqlkdp",
        "outputId": "8fc828a3-4f7c-45ee-8e88-34f034d3bbb1"
      },
      "source": [
        "#Criar matriz de confusão\n",
        "confusion = confusion_matrix(y_test, y_pred)\n",
        "confusion"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 27,  31],\n",
              "       [ 26, 116]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nb3gSLSwlyhH"
      },
      "source": [
        "# **Faça Você Mesmo** \n",
        "\n",
        "Criar Rede Neural para resolver problema de classificação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Orfwwc0zmlvo"
      },
      "source": [
        "pip install tensorflow -q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3oT8bC-mPJ4"
      },
      "source": [
        "#Instalar Bibliotecas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "vIbt44XRmO6Z",
        "outputId": "d652375d-58ed-4c28-ccec-b873d338e08a"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Data Science com Python Udemy/34.Prática em Python/dados/soybean.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>plant-stand</th>\n",
              "      <th>precip</th>\n",
              "      <th>temp</th>\n",
              "      <th>hail</th>\n",
              "      <th>crop-hist</th>\n",
              "      <th>area-damaged</th>\n",
              "      <th>severity</th>\n",
              "      <th>seed-tmt</th>\n",
              "      <th>germination</th>\n",
              "      <th>plant-growth</th>\n",
              "      <th>leaves</th>\n",
              "      <th>leafspots-halo</th>\n",
              "      <th>leafspots-marg</th>\n",
              "      <th>leafspot-size</th>\n",
              "      <th>leaf-shread</th>\n",
              "      <th>leaf-malf</th>\n",
              "      <th>leaf-mild</th>\n",
              "      <th>stem</th>\n",
              "      <th>lodging</th>\n",
              "      <th>stem-cankers</th>\n",
              "      <th>canker-lesion</th>\n",
              "      <th>fruiting-bodies</th>\n",
              "      <th>external-decay</th>\n",
              "      <th>mycelium</th>\n",
              "      <th>int-discolor</th>\n",
              "      <th>sclerotia</th>\n",
              "      <th>fruit-pods</th>\n",
              "      <th>fruit-spots</th>\n",
              "      <th>seed</th>\n",
              "      <th>mold-growth</th>\n",
              "      <th>seed-discolor</th>\n",
              "      <th>seed-size</th>\n",
              "      <th>shriveling</th>\n",
              "      <th>roots</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>october</td>\n",
              "      <td>normal</td>\n",
              "      <td>gt-norm</td>\n",
              "      <td>norm</td>\n",
              "      <td>yes</td>\n",
              "      <td>same-lst-yr</td>\n",
              "      <td>low-areas</td>\n",
              "      <td>pot-severe</td>\n",
              "      <td>none</td>\n",
              "      <td>90-100</td>\n",
              "      <td>abnorm</td>\n",
              "      <td>abnorm</td>\n",
              "      <td>absent</td>\n",
              "      <td>dna</td>\n",
              "      <td>dna</td>\n",
              "      <td>absent</td>\n",
              "      <td>absent</td>\n",
              "      <td>absent</td>\n",
              "      <td>abnorm</td>\n",
              "      <td>no</td>\n",
              "      <td>above-sec-nde</td>\n",
              "      <td>brown</td>\n",
              "      <td>present</td>\n",
              "      <td>firm-and-dry</td>\n",
              "      <td>absent</td>\n",
              "      <td>none</td>\n",
              "      <td>absent</td>\n",
              "      <td>norm</td>\n",
              "      <td>dna</td>\n",
              "      <td>norm</td>\n",
              "      <td>absent</td>\n",
              "      <td>absent</td>\n",
              "      <td>norm</td>\n",
              "      <td>absent</td>\n",
              "      <td>norm</td>\n",
              "      <td>diaporthe-stem-canker</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>august</td>\n",
              "      <td>normal</td>\n",
              "      <td>gt-norm</td>\n",
              "      <td>norm</td>\n",
              "      <td>yes</td>\n",
              "      <td>same-lst-two-yrs</td>\n",
              "      <td>scattered</td>\n",
              "      <td>severe</td>\n",
              "      <td>fungicide</td>\n",
              "      <td>80-89</td>\n",
              "      <td>abnorm</td>\n",
              "      <td>abnorm</td>\n",
              "      <td>absent</td>\n",
              "      <td>dna</td>\n",
              "      <td>dna</td>\n",
              "      <td>absent</td>\n",
              "      <td>absent</td>\n",
              "      <td>absent</td>\n",
              "      <td>abnorm</td>\n",
              "      <td>yes</td>\n",
              "      <td>above-sec-nde</td>\n",
              "      <td>brown</td>\n",
              "      <td>present</td>\n",
              "      <td>firm-and-dry</td>\n",
              "      <td>absent</td>\n",
              "      <td>none</td>\n",
              "      <td>absent</td>\n",
              "      <td>norm</td>\n",
              "      <td>dna</td>\n",
              "      <td>norm</td>\n",
              "      <td>absent</td>\n",
              "      <td>absent</td>\n",
              "      <td>norm</td>\n",
              "      <td>absent</td>\n",
              "      <td>norm</td>\n",
              "      <td>diaporthe-stem-canker</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>july</td>\n",
              "      <td>normal</td>\n",
              "      <td>gt-norm</td>\n",
              "      <td>norm</td>\n",
              "      <td>yes</td>\n",
              "      <td>same-lst-yr</td>\n",
              "      <td>scattered</td>\n",
              "      <td>severe</td>\n",
              "      <td>fungicide</td>\n",
              "      <td>lt-80</td>\n",
              "      <td>abnorm</td>\n",
              "      <td>abnorm</td>\n",
              "      <td>absent</td>\n",
              "      <td>dna</td>\n",
              "      <td>dna</td>\n",
              "      <td>absent</td>\n",
              "      <td>absent</td>\n",
              "      <td>absent</td>\n",
              "      <td>abnorm</td>\n",
              "      <td>yes</td>\n",
              "      <td>above-sec-nde</td>\n",
              "      <td>dna</td>\n",
              "      <td>present</td>\n",
              "      <td>firm-and-dry</td>\n",
              "      <td>absent</td>\n",
              "      <td>none</td>\n",
              "      <td>absent</td>\n",
              "      <td>norm</td>\n",
              "      <td>dna</td>\n",
              "      <td>norm</td>\n",
              "      <td>absent</td>\n",
              "      <td>absent</td>\n",
              "      <td>norm</td>\n",
              "      <td>absent</td>\n",
              "      <td>norm</td>\n",
              "      <td>diaporthe-stem-canker</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>july</td>\n",
              "      <td>normal</td>\n",
              "      <td>gt-norm</td>\n",
              "      <td>norm</td>\n",
              "      <td>yes</td>\n",
              "      <td>same-lst-yr</td>\n",
              "      <td>scattered</td>\n",
              "      <td>severe</td>\n",
              "      <td>none</td>\n",
              "      <td>80-89</td>\n",
              "      <td>abnorm</td>\n",
              "      <td>abnorm</td>\n",
              "      <td>absent</td>\n",
              "      <td>dna</td>\n",
              "      <td>dna</td>\n",
              "      <td>absent</td>\n",
              "      <td>absent</td>\n",
              "      <td>absent</td>\n",
              "      <td>abnorm</td>\n",
              "      <td>yes</td>\n",
              "      <td>above-sec-nde</td>\n",
              "      <td>dna</td>\n",
              "      <td>present</td>\n",
              "      <td>firm-and-dry</td>\n",
              "      <td>absent</td>\n",
              "      <td>none</td>\n",
              "      <td>absent</td>\n",
              "      <td>norm</td>\n",
              "      <td>dna</td>\n",
              "      <td>norm</td>\n",
              "      <td>absent</td>\n",
              "      <td>absent</td>\n",
              "      <td>norm</td>\n",
              "      <td>absent</td>\n",
              "      <td>norm</td>\n",
              "      <td>diaporthe-stem-canker</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>october</td>\n",
              "      <td>normal</td>\n",
              "      <td>gt-norm</td>\n",
              "      <td>norm</td>\n",
              "      <td>yes</td>\n",
              "      <td>same-lst-two-yrs</td>\n",
              "      <td>scattered</td>\n",
              "      <td>pot-severe</td>\n",
              "      <td>none</td>\n",
              "      <td>lt-80</td>\n",
              "      <td>abnorm</td>\n",
              "      <td>abnorm</td>\n",
              "      <td>absent</td>\n",
              "      <td>dna</td>\n",
              "      <td>dna</td>\n",
              "      <td>absent</td>\n",
              "      <td>absent</td>\n",
              "      <td>absent</td>\n",
              "      <td>abnorm</td>\n",
              "      <td>yes</td>\n",
              "      <td>above-sec-nde</td>\n",
              "      <td>brown</td>\n",
              "      <td>present</td>\n",
              "      <td>firm-and-dry</td>\n",
              "      <td>absent</td>\n",
              "      <td>none</td>\n",
              "      <td>absent</td>\n",
              "      <td>norm</td>\n",
              "      <td>dna</td>\n",
              "      <td>norm</td>\n",
              "      <td>absent</td>\n",
              "      <td>absent</td>\n",
              "      <td>norm</td>\n",
              "      <td>absent</td>\n",
              "      <td>norm</td>\n",
              "      <td>diaporthe-stem-canker</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      date plant-stand   precip  ... shriveling roots                  class\n",
              "0  october      normal  gt-norm  ...     absent  norm  diaporthe-stem-canker\n",
              "1   august      normal  gt-norm  ...     absent  norm  diaporthe-stem-canker\n",
              "2     july      normal  gt-norm  ...     absent  norm  diaporthe-stem-canker\n",
              "3     july      normal  gt-norm  ...     absent  norm  diaporthe-stem-canker\n",
              "4  october      normal  gt-norm  ...     absent  norm  diaporthe-stem-canker\n",
              "\n",
              "[5 rows x 36 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 564
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YrwTKY43IER"
      },
      "source": [
        "## **Estudo das variáveis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mv-X_HVn5-DR",
        "outputId": "5332d599-b1b2-484b-b78c-a016444bdcf7"
      },
      "source": [
        "#Ver tamanho do dataset\n",
        "print(\"Entradas: {}\".format(df.shape[0]))\n",
        "print(\"Variáveis: {}\".format(df.shape[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Entradas: 683\n",
            "Variáveis: 36\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGFjxrYBCl5t"
      },
      "source": [
        "#Separar classe do dataset\n",
        "y = df['class']\n",
        "df = df.drop(['class'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzF-UsQ1RvVj"
      },
      "source": [
        "#Realizar LabelEncoder nas variáveis\n",
        "for i in range (0,35):\n",
        "  LbEncoder = LabelEncoder()\n",
        "  df[df.columns[i]] = LbEncoder.fit_transform(df[df.columns[i]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-svghyr9UDXj"
      },
      "source": [
        "#dividir dataset de treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(df,y, test_size = 0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FZrXhOJVbFp",
        "outputId": "ec4ad99c-bcdb-448a-be91-8822a37fd099"
      },
      "source": [
        "#Instanciar e treinar modelo\n",
        "modelo = RandomForestClassifier(n_estimators=100)\n",
        "modelo.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 582
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDmgc7LAVsmx"
      },
      "source": [
        "#Realizar previsões\n",
        "y_pred = modelo.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4X2v-4-oVxTx",
        "outputId": "289be082-678a-4bfe-9f54-d82864faf923"
      },
      "source": [
        "confusao = confusion_matrix(y_test, y_pred)\n",
        "confusao"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 7,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0],\n",
              "       [ 0, 27,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0],\n",
              "       [ 0,  0, 11,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0],\n",
              "       [ 0,  0,  0,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0],\n",
              "       [ 0,  0,  0,  0,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0],\n",
              "       [ 0,  0,  0,  0,  0, 28,  0,  0,  0,  0,  0,  0,  2,  0,  0,  0,\n",
              "         0,  0,  0],\n",
              "       [ 0,  0,  0,  0,  0,  0, 12,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  6,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  6,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  4,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  4,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  5,  0,  0,  0,  0,\n",
              "         0,  0,  0],\n",
              "       [ 0,  6,  0,  0,  0,  2,  0,  0,  0,  0,  0,  0, 19,  0,  0,  0,\n",
              "         0,  0,  0],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  2,  0,  0,\n",
              "         0,  0,  0],\n",
              "       [ 0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  8,  0,\n",
              "         0,  0,  0],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 31,\n",
              "         0,  0,  0],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         7,  0,  0],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  7,  0],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  3]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 584
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpKdRPT3WkYK",
        "outputId": "d2e64f03-d307-47ba-9358-145b66dd6124"
      },
      "source": [
        "taxa_acerto = accuracy_score(y_test, y_pred)\n",
        "taxa_acerto"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9463414634146341"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 585
        }
      ]
    }
  ]
}